{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#4차원 배열\n",
    "x = np.random.rand(10,1,28,28) #무작위 데이터 생성\n",
    "# 높이 28, 너비 28, 채널 1 데이터가 10개\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape #첫번째 데이터 접근"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1].shape #두번째"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51371083, 0.35800149, 0.24079921, 0.37872887, 0.40402875,\n",
       "        0.68816978, 0.30016913, 0.76649811, 0.54009021, 0.92801779,\n",
       "        0.61153888, 0.28179706, 0.59910368, 0.12963275, 0.9572865 ,\n",
       "        0.43776238, 0.19869377, 0.83987469, 0.13520144, 0.35377187,\n",
       "        0.61030115, 0.86553381, 0.78320731, 0.09460511, 0.83534998,\n",
       "        0.51941251, 0.19473494, 0.290306  ],\n",
       "       [0.73361715, 0.40490227, 0.3789102 , 0.18772639, 0.42159421,\n",
       "        0.70135201, 0.50182932, 0.63398792, 0.20430146, 0.89318488,\n",
       "        0.14732729, 0.89563844, 0.23689246, 0.07027921, 0.88004209,\n",
       "        0.39874171, 0.1431217 , 0.44781777, 0.91189994, 0.44714037,\n",
       "        0.87139784, 0.86219895, 0.52266258, 0.77971402, 0.84085699,\n",
       "        0.97727418, 0.47737255, 0.34574269],\n",
       "       [0.69349358, 0.31509509, 0.92326599, 0.29957771, 0.42312944,\n",
       "        0.34637452, 0.0756164 , 0.35669253, 0.16396924, 0.93613396,\n",
       "        0.50775669, 0.59786476, 0.18048923, 0.97879256, 0.58163263,\n",
       "        0.96784288, 0.39556782, 0.47250762, 0.99935973, 0.52784805,\n",
       "        0.33015215, 0.84804244, 0.76646165, 0.33030674, 0.92736485,\n",
       "        0.77881861, 0.73192375, 0.07067032],\n",
       "       [0.44826891, 0.59918356, 0.32035155, 0.03563809, 0.98010422,\n",
       "        0.06674357, 0.1906086 , 0.81918304, 0.94006399, 0.16909374,\n",
       "        0.54615347, 0.1824294 , 0.82177394, 0.69383894, 0.22713465,\n",
       "        0.44240259, 0.14107715, 0.14053836, 0.45054299, 0.56508758,\n",
       "        0.52742745, 0.15842684, 0.57855234, 0.65641084, 0.44852145,\n",
       "        0.09413655, 0.76973793, 0.2456018 ],\n",
       "       [0.16302551, 0.76416822, 0.94577754, 0.57178966, 0.31889365,\n",
       "        0.05596563, 0.45071279, 0.92327915, 0.01508123, 0.86268893,\n",
       "        0.35563381, 0.12125581, 0.73159927, 0.00811348, 0.64909459,\n",
       "        0.5243919 , 0.55973246, 0.23582666, 0.87366396, 0.51467983,\n",
       "        0.55576525, 0.54582865, 0.69729465, 0.74905312, 0.92737433,\n",
       "        0.0450325 , 0.85911561, 0.05226673],\n",
       "       [0.93451899, 0.65495423, 0.42941176, 0.49040114, 0.72619784,\n",
       "        0.39045887, 0.6074964 , 0.04651947, 0.83292056, 0.91842061,\n",
       "        0.99201449, 0.28790198, 0.1106099 , 0.03198733, 0.72603601,\n",
       "        0.22988356, 0.96933005, 0.61318936, 0.63978134, 0.70195741,\n",
       "        0.0880697 , 0.0325152 , 0.09319952, 0.37566752, 0.99531014,\n",
       "        0.78502431, 0.64045627, 0.28548991],\n",
       "       [0.0773484 , 0.77383512, 0.28403406, 0.24377158, 0.94937662,\n",
       "        0.40627686, 0.64905744, 0.27373461, 0.61889368, 0.53381378,\n",
       "        0.63435689, 0.3488885 , 0.43235835, 0.76387192, 0.2265703 ,\n",
       "        0.71005133, 0.44873017, 0.84280641, 0.05507148, 0.36244062,\n",
       "        0.4210819 , 0.67462457, 0.95697306, 0.5491473 , 0.26933565,\n",
       "        0.37855869, 0.53160839, 0.99848824],\n",
       "       [0.70917091, 0.26206359, 0.27601348, 0.04386836, 0.22558081,\n",
       "        0.27304096, 0.29807733, 0.26394129, 0.91895188, 0.66344439,\n",
       "        0.74957137, 0.54521364, 0.32794793, 0.11219799, 0.04008528,\n",
       "        0.34015768, 0.58208995, 0.89270354, 0.48864186, 0.61990687,\n",
       "        0.4374878 , 0.15670972, 0.28163066, 0.63706099, 0.28151501,\n",
       "        0.20864515, 0.55017436, 0.70999911],\n",
       "       [0.97548179, 0.27272925, 0.01675016, 0.85965097, 0.04744236,\n",
       "        0.03800376, 0.38944404, 0.87782233, 0.12758247, 0.50577596,\n",
       "        0.34018625, 0.71290258, 0.98286321, 0.27635554, 0.27923163,\n",
       "        0.6834287 , 0.99516417, 0.6427267 , 0.66800231, 0.14636175,\n",
       "        0.53687417, 0.91157754, 0.87161082, 0.93425474, 0.57448981,\n",
       "        0.58106079, 0.74794526, 0.96657664],\n",
       "       [0.6612173 , 0.90291295, 0.54811913, 0.93408429, 0.06014726,\n",
       "        0.75593576, 0.96735019, 0.84980638, 0.7297455 , 0.74933566,\n",
       "        0.7121975 , 0.92423979, 0.73058713, 0.28203679, 0.09819802,\n",
       "        0.6135263 , 0.85211343, 0.01456188, 0.14196792, 0.66887235,\n",
       "        0.27499258, 0.24059824, 0.17578172, 0.42310224, 0.00778445,\n",
       "        0.37300264, 0.21420258, 0.24592699],\n",
       "       [0.36550673, 0.39051408, 0.54191537, 0.70630259, 0.9590066 ,\n",
       "        0.16421024, 0.73716159, 0.48007773, 0.82367406, 0.64067998,\n",
       "        0.44185019, 0.62582332, 0.55099851, 0.5257211 , 0.10742539,\n",
       "        0.9155788 , 0.46175131, 0.39182451, 0.28754438, 0.82021401,\n",
       "        0.24137219, 0.99972113, 0.80495374, 0.58596619, 0.50372018,\n",
       "        0.18232155, 0.82792319, 0.63184186],\n",
       "       [0.03595077, 0.51544779, 0.53291429, 0.88412508, 0.98308074,\n",
       "        0.24152006, 0.52815264, 0.57594826, 0.0893611 , 0.12918688,\n",
       "        0.19590949, 0.84375907, 0.77539393, 0.55485535, 0.79201639,\n",
       "        0.67315813, 0.08864323, 0.93300526, 0.42900598, 0.7498582 ,\n",
       "        0.81892963, 0.7841729 , 0.18222128, 0.43012207, 0.90948768,\n",
       "        0.22029288, 0.13825826, 0.81065314],\n",
       "       [0.83556018, 0.356002  , 0.09071827, 0.60207953, 0.52986601,\n",
       "        0.0904113 , 0.13585095, 0.61657163, 0.49921193, 0.07690587,\n",
       "        0.77420035, 0.58454479, 0.41284339, 0.40818326, 0.72839002,\n",
       "        0.34929458, 0.4049922 , 0.18869531, 0.08210546, 0.87925529,\n",
       "        0.01466679, 0.2208171 , 0.04963993, 0.33789526, 0.41119205,\n",
       "        0.43376254, 0.36324321, 0.67430999],\n",
       "       [0.77355977, 0.14243701, 0.36567334, 0.52001202, 0.7208237 ,\n",
       "        0.72924381, 0.78380333, 0.35852429, 0.5067786 , 0.06364536,\n",
       "        0.43210426, 0.7548941 , 0.88975397, 0.53114327, 0.14085837,\n",
       "        0.11065714, 0.63980134, 0.63892056, 0.73112824, 0.36502575,\n",
       "        0.35669786, 0.86938169, 0.29983688, 0.7050228 , 0.6613363 ,\n",
       "        0.6914276 , 0.40554304, 0.1291073 ],\n",
       "       [0.04171903, 0.84443375, 0.98929179, 0.58311632, 0.24516957,\n",
       "        0.82951545, 0.26911878, 0.99576837, 0.23875149, 0.84916769,\n",
       "        0.70560556, 0.02113913, 0.40082332, 0.74939287, 0.14289427,\n",
       "        0.3389095 , 0.9621494 , 0.86226443, 0.87838451, 0.35110128,\n",
       "        0.53098142, 0.17408683, 0.78961256, 0.60369602, 0.31420892,\n",
       "        0.65714129, 0.82524837, 0.96063552],\n",
       "       [0.16588118, 0.91851226, 0.11102899, 0.65604359, 0.00252164,\n",
       "        0.88536913, 0.30570528, 0.4701667 , 0.01154177, 0.93396372,\n",
       "        0.76453331, 0.27418458, 0.38996259, 0.61877984, 0.83917134,\n",
       "        0.92048188, 0.89240843, 0.02399268, 0.28000535, 0.50427726,\n",
       "        0.59610604, 0.19040507, 0.38663087, 0.04911053, 0.25153381,\n",
       "        0.29482453, 0.52481466, 0.14917872],\n",
       "       [0.52721988, 0.52691938, 0.40084153, 0.78258017, 0.49713587,\n",
       "        0.3158008 , 0.29941105, 0.35351133, 0.19242483, 0.51923048,\n",
       "        0.41627672, 0.51051344, 0.85178836, 0.65167076, 0.88092372,\n",
       "        0.50739128, 0.88715828, 0.32933036, 0.20744385, 0.48162093,\n",
       "        0.79126351, 0.72041606, 0.47601263, 0.11094234, 0.19869686,\n",
       "        0.44262227, 0.82719979, 0.61571713],\n",
       "       [0.23042658, 0.42024808, 0.40528803, 0.16327253, 0.94597001,\n",
       "        0.06593925, 0.377346  , 0.78497187, 0.5335956 , 0.35607002,\n",
       "        0.63051271, 0.47293354, 0.2484734 , 0.09517598, 0.62185948,\n",
       "        0.31335008, 0.73037159, 0.27829301, 0.30592307, 0.13316432,\n",
       "        0.93635948, 0.48297528, 0.86492961, 0.76549168, 0.85772235,\n",
       "        0.41579453, 0.61852221, 0.84661854],\n",
       "       [0.19549768, 0.11201674, 0.60593972, 0.73282091, 0.00308539,\n",
       "        0.07693307, 0.21361679, 0.20353606, 0.11512973, 0.80412951,\n",
       "        0.32776559, 0.36439253, 0.73757413, 0.99634318, 0.58570831,\n",
       "        0.95444107, 0.64406829, 0.54510753, 0.41701133, 0.77285055,\n",
       "        0.79133811, 0.88238492, 0.63262029, 0.90965477, 0.02415835,\n",
       "        0.95889251, 0.35030523, 0.37249006],\n",
       "       [0.92585437, 0.0786676 , 0.66545095, 0.84565751, 0.14927023,\n",
       "        0.58240573, 0.11964118, 0.72797342, 0.54638101, 0.59919189,\n",
       "        0.12830489, 0.19915608, 0.02264636, 0.07484898, 0.6860942 ,\n",
       "        0.48112665, 0.93323923, 0.35619387, 0.11013337, 0.27983501,\n",
       "        0.45699535, 0.92058161, 0.00222828, 0.68589471, 0.85311624,\n",
       "        0.25969471, 0.80675713, 0.95240181],\n",
       "       [0.99570505, 0.53697748, 0.40465602, 0.00697943, 0.45849842,\n",
       "        0.13806092, 0.11332935, 0.8256739 , 0.23431549, 0.38348702,\n",
       "        0.57894708, 0.61160788, 0.47430387, 0.02317842, 0.54719814,\n",
       "        0.07186365, 0.54234523, 0.71841857, 0.61138877, 0.11664017,\n",
       "        0.1281382 , 0.35314392, 0.07121238, 0.97105598, 0.27694873,\n",
       "        0.18132997, 0.40387519, 0.45935661],\n",
       "       [0.87862841, 0.75410314, 0.33173905, 0.85979444, 0.75834703,\n",
       "        0.32310681, 0.76132167, 0.69736327, 0.32388648, 0.61816939,\n",
       "        0.45574739, 0.78099656, 0.76570329, 0.03638447, 0.44738106,\n",
       "        0.30674755, 0.56865927, 0.44362454, 0.37526905, 0.95403516,\n",
       "        0.01474587, 0.00266803, 0.36478683, 0.16949048, 0.23363283,\n",
       "        0.97475234, 0.1807076 , 0.40184222],\n",
       "       [0.02636504, 0.30422312, 0.67908223, 0.46686293, 0.90728427,\n",
       "        0.14964153, 0.98164625, 0.53955754, 0.19214741, 0.91478755,\n",
       "        0.59792185, 0.78183233, 0.42567875, 0.85094403, 0.84556573,\n",
       "        0.85558925, 0.01945872, 0.18932399, 0.56357757, 0.41155215,\n",
       "        0.59029365, 0.85475505, 0.01028828, 0.30426315, 0.68959217,\n",
       "        0.31033872, 0.33977211, 0.56148724],\n",
       "       [0.5660447 , 0.06413781, 0.07974326, 0.47887757, 0.36673619,\n",
       "        0.43302455, 0.32109861, 0.68032404, 0.93667042, 0.17909113,\n",
       "        0.75611901, 0.54818189, 0.93988551, 0.16574765, 0.70761201,\n",
       "        0.05738883, 0.08209676, 0.85625339, 0.88689078, 0.97547281,\n",
       "        0.8646109 , 0.67833058, 0.433053  , 0.88610905, 0.6308947 ,\n",
       "        0.69934154, 0.30914147, 0.12522749],\n",
       "       [0.85674963, 0.98291033, 0.06432516, 0.53187755, 0.86087181,\n",
       "        0.67807689, 0.38345334, 0.19199635, 0.66952098, 0.89454684,\n",
       "        0.42419004, 0.68797601, 0.38873241, 0.93766046, 0.1838056 ,\n",
       "        0.20914853, 0.28396304, 0.89963392, 0.91236546, 0.55758603,\n",
       "        0.70687106, 0.42839706, 0.36716757, 0.30245866, 0.86016798,\n",
       "        0.87426025, 0.65840972, 0.45934507],\n",
       "       [0.81272539, 0.45129796, 0.37235873, 0.03489006, 0.03085736,\n",
       "        0.34668974, 0.17401798, 0.95933427, 0.61706577, 0.65215668,\n",
       "        0.13048123, 0.38462893, 0.34173482, 0.3498014 , 0.48954457,\n",
       "        0.89449873, 0.34437355, 0.96296429, 0.57976023, 0.70370908,\n",
       "        0.97838625, 0.84772134, 0.56041598, 0.85021193, 0.97974617,\n",
       "        0.02786432, 0.63328061, 0.51179805],\n",
       "       [0.06782433, 0.19009022, 0.90523695, 0.70309599, 0.78829356,\n",
       "        0.92662006, 0.25860856, 0.8599855 , 0.64435517, 0.12586231,\n",
       "        0.82110977, 0.01918013, 0.47489795, 0.4709403 , 0.48030274,\n",
       "        0.98141415, 0.90543378, 0.9323358 , 0.09076117, 0.48308632,\n",
       "        0.9680795 , 0.12156022, 0.70488238, 0.21446101, 0.7737229 ,\n",
       "        0.40836384, 0.79434862, 0.86271191],\n",
       "       [0.02480332, 0.94441379, 0.12687943, 0.74260005, 0.55158859,\n",
       "        0.19601592, 0.74102168, 0.482269  , 0.3893689 , 0.25461046,\n",
       "        0.82750113, 0.15163861, 0.36743986, 0.69086929, 0.99918683,\n",
       "        0.6344386 , 0.14236305, 0.24248305, 0.44570383, 0.25854966,\n",
       "        0.87270263, 0.0947708 , 0.44075663, 0.54925159, 0.82410981,\n",
       "        0.55688631, 0.53684376, 0.90321985]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0] # or x[0][0] 첫 채널의 공간데이터 접근"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 75)\n"
     ]
    }
   ],
   "source": [
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"다수의 이미지를 입력받아 2차원 배열로 변환한다(평탄화).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : 4차원 배열 형태의 입력 데이터(이미지 수, 채널 수, 높이, 너비)\n",
    "    filter_h : 필터의 높이\n",
    "    filter_w : 필터의 너비\n",
    "    stride : 스트라이드\n",
    "    pad : 패딩\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    col : 2차원 배열\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "    return col\n",
    "\n",
    "x1 = np.random.rand(1,3,7,7) #데이터 수, 채널 수 , 높이, 너비\n",
    "col1 = im2col(x1, 5,5 ,stride=1, pad = 0)\n",
    "print(col1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 75)\n"
     ]
    }
   ],
   "source": [
    "x2 = np.random.rand(10,3,7,7) \n",
    "col2 = im2col(x2, 5, 5 ,stride=1, pad = 0)\n",
    "print(col2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W #가중치\n",
    "        self.b = b #편향\n",
    "        self.stride = stride #스트라이드\n",
    "        self.pad = pad #패딩\n",
    "    \n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = int(1 + (W + 2*self.pad - FW) / self.stride)\n",
    "        \n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN, -1).T #필터 전개\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        \n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0,3,1,2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"(im2col과 반대) 2차원 배열을 입력받아 다수의 이미지 묶음으로 변환한다.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    col : 2차원 배열(입력 데이터)\n",
    "    input_shape : 원래 이미지 데이터의 형상（예：(10, 1, 28, 28)）\n",
    "    filter_h : 필터의 높이\n",
    "    filter_w : 필터의 너비\n",
    "    stride : 스트라이드\n",
    "    pad : 패딩\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    img : 변환된 이미지들\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "\n",
    "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "\n",
    "    return img[:, :, pad:H + pad, pad:W + pad]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "        \n",
    "        # 전개 1\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h * self.pool_w)\n",
    "        \n",
    "        #최댓값 2\n",
    "        out = np.max(col, axis=1)\n",
    "        \n",
    "        #성형 3\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0,3,1,2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvNet:\n",
    "    def __init__(self, input_dim=(1, 28, 28), #입력데이터 (채널수, 높이, 너비)의 차원\n",
    "                 conv_param = {'filter_num':30, 'filter_size':5,'pad':0, 'stride':1}, #합성곱 계층의 하이퍼 파라미터\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad ) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "        #초기화 인수로 주어진 합성곱 계층의 하이퍼파라미터를 딕셔너리에서 꺼낸다\n",
    "        #합성곱의 출력 크기를 계산\n",
    "        \n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "        \n",
    "        #매개변수들을 params 딕셔너리에 저장한다.\n",
    "        #1번층의 합성곱 계층의 가중치를 W1, 편향을 b1이라는 키로 저장\n",
    "        #2번째 층의 완전연결 계층의 가중치와 편향을 W2와 b2 마지막 3번째 층의 완전연결 계층의 가중치와 편향을 W3과 b3라는 키로 각각 저장\n",
    "        \n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'],self.params['b1'],conv_param['stride'],conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h = 2, pool_w = 2, stride = 2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'],self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'],self.params['b3'])\n",
    "        \n",
    "        #OrderedDict인 Layers에 계층들을 차례로 추가한다.\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "        #마지막인 소맥은 별도 변수에 저장한다.\n",
    "        \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "            \n",
    "        return x\n",
    "        \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        #pro\n",
    "        self.loss(x, t)\n",
    "        \n",
    "        #back\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "            \n",
    "        #결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'] = self.layers['Conv1'].dW\n",
    "        grads['b1'] = self.layers['Conv1'].db\n",
    "        grads['W2'] = self.layers['Affine1'].dW\n",
    "        grads['b2'] = self.layers['Affine1'].db\n",
    "        grads['W3'] = self.layers['Affine2'].dW\n",
    "        grads['b3'] = self.layers['Affine2'].db\n",
    "        \n",
    "        return grads\n",
    "        \n",
    "        \n",
    "        #accuracy까지 구현이 되어야 본문내용이 돌아가는 듯 한데\n",
    "        #일단 아래꺼로 복붙해서 돌려보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class SimpleConvNet:\n",
    "    \"\"\"단순한 합성곱 신경망\n",
    "    \n",
    "    conv - relu - pool - affine - relu - affine - softmax\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : 입력 크기（MNIST의 경우엔 784）\n",
    "    hidden_size_list : 각 은닉층의 뉴런 수를 담은 리스트（e.g. [100, 100, 100]）\n",
    "    output_size : 출력 크기（MNIST의 경우엔 10）\n",
    "    activation : 활성화 함수 - 'relu' 혹은 'sigmoid'\n",
    "    weight_init_std : 가중치의 표준편차 지정（e.g. 0.01）\n",
    "        'relu'나 'he'로 지정하면 'He 초깃값'으로 설정\n",
    "        'sigmoid'나 'xavier'로 지정하면 'Xavier 초깃값'으로 설정\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"손실 함수를 구한다.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다（수치미분）.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다(오차역전파법).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.299805046952363\n",
      "=== epoch:1, train acc:0.271, test acc:0.23 ===\n",
      "train loss:2.2965192176010483\n",
      "train loss:2.2920471236042714\n",
      "train loss:2.2881062553988394\n",
      "train loss:2.276986683356829\n",
      "train loss:2.2597923010460557\n",
      "train loss:2.2513260521498726\n",
      "train loss:2.263858462742898\n",
      "train loss:2.229904944338904\n",
      "train loss:2.2123056850634963\n",
      "train loss:2.1498356150213898\n",
      "train loss:2.111830672138248\n",
      "train loss:2.113224384066506\n",
      "train loss:2.0126581341532326\n",
      "train loss:1.9869703053611263\n",
      "train loss:1.9859166319440034\n",
      "train loss:1.8589936155022706\n",
      "train loss:1.8039313698275072\n",
      "train loss:1.745354971978733\n",
      "train loss:1.6576452948765592\n",
      "train loss:1.6394035942169267\n",
      "train loss:1.499972753529964\n",
      "train loss:1.36727654637779\n",
      "train loss:1.4455343743096263\n",
      "train loss:1.3040739482218147\n",
      "train loss:1.3137178754327303\n",
      "train loss:1.064488945679791\n",
      "train loss:1.029563116679493\n",
      "train loss:1.0034375419599981\n",
      "train loss:0.9599427810167522\n",
      "train loss:0.7586425042219078\n",
      "train loss:0.8497498190746491\n",
      "train loss:0.7901428126246028\n",
      "train loss:0.754619568501236\n",
      "train loss:0.7130024786815139\n",
      "train loss:0.6752567954542771\n",
      "train loss:0.7635078148155295\n",
      "train loss:0.6477997774210777\n",
      "train loss:0.6207140247832293\n",
      "train loss:0.5909101989013236\n",
      "train loss:0.7046782450222223\n",
      "train loss:0.6168677152134205\n",
      "train loss:0.4837086587490474\n",
      "train loss:0.5682593162265934\n",
      "train loss:0.5048070886938372\n",
      "train loss:0.4201470539762917\n",
      "train loss:0.6131478427833061\n",
      "train loss:0.4938678203270523\n",
      "train loss:0.6017360418885729\n",
      "train loss:0.3907506578004395\n",
      "train loss:0.6155561597265521\n",
      "train loss:0.5361392548631929\n",
      "train loss:0.6395581283744274\n",
      "train loss:0.5065098450151694\n",
      "train loss:0.5490951519729709\n",
      "train loss:0.5558315221379565\n",
      "train loss:0.5152108939146889\n",
      "train loss:0.4370055589480843\n",
      "train loss:0.46433931182784444\n",
      "train loss:0.4784632436819743\n",
      "train loss:0.6189664993422997\n",
      "train loss:0.3802638834396064\n",
      "train loss:0.5419177895564338\n",
      "train loss:0.4596909324175929\n",
      "train loss:0.4095206055120789\n",
      "train loss:0.45429798252578757\n",
      "train loss:0.5204641812937721\n",
      "train loss:0.6299457317823753\n",
      "train loss:0.4625946839832081\n",
      "train loss:0.48304948804869946\n",
      "train loss:0.566763239231541\n",
      "train loss:0.47446876960600176\n",
      "train loss:0.4162200135606489\n",
      "train loss:0.5860398084428955\n",
      "train loss:0.4072449279364112\n",
      "train loss:0.4229388894004364\n",
      "train loss:0.5788670686237506\n",
      "train loss:0.5822126446326639\n",
      "train loss:0.3649622211567186\n",
      "train loss:0.5517799918172056\n",
      "train loss:0.40388001988134475\n",
      "train loss:0.48779909382001563\n",
      "train loss:0.39079770489157084\n",
      "train loss:0.6032363319903478\n",
      "train loss:0.413121800046574\n",
      "train loss:0.5436157223304658\n",
      "train loss:0.4856140163192188\n",
      "train loss:0.32880152037322286\n",
      "train loss:0.4364904463039205\n",
      "train loss:0.4470998045938851\n",
      "train loss:0.3721200749535922\n",
      "train loss:0.42275717670176527\n",
      "train loss:0.43577147668564037\n",
      "train loss:0.40753660873021574\n",
      "train loss:0.5080263616711252\n",
      "train loss:0.36399152506443483\n",
      "train loss:0.38450365266577274\n",
      "train loss:0.24346814782228868\n",
      "train loss:0.3808212423247533\n",
      "train loss:0.43789769337501755\n",
      "train loss:0.4033979453728017\n",
      "train loss:0.24303047937140082\n",
      "train loss:0.41253873504244654\n",
      "train loss:0.3172485219572623\n",
      "train loss:0.23692265149941596\n",
      "train loss:0.5033133333554367\n",
      "train loss:0.3055748385255722\n",
      "train loss:0.32005160970122676\n",
      "train loss:0.31865703204706947\n",
      "train loss:0.49821561126023167\n",
      "train loss:0.48455542135362756\n",
      "train loss:0.42564962217809205\n",
      "train loss:0.4501091196446633\n",
      "train loss:0.2638432321726576\n",
      "train loss:0.3627189030744739\n",
      "train loss:0.27828162903169973\n",
      "train loss:0.4423057451023329\n",
      "train loss:0.40048917597371286\n",
      "train loss:0.3275306550540337\n",
      "train loss:0.38784173175108266\n",
      "train loss:0.24709297926512805\n",
      "train loss:0.3259959659820968\n",
      "train loss:0.21483081923321656\n",
      "train loss:0.22173706212286745\n",
      "train loss:0.4277221292253731\n",
      "train loss:0.2781035347022282\n",
      "train loss:0.3617530847976396\n",
      "train loss:0.3888879711052469\n",
      "train loss:0.2561791428902698\n",
      "train loss:0.5539031791739943\n",
      "train loss:0.3231963433157114\n",
      "train loss:0.18568148555215697\n",
      "train loss:0.4131786817318425\n",
      "train loss:0.26879985248324717\n",
      "train loss:0.20238822963881387\n",
      "train loss:0.29281584030756636\n",
      "train loss:0.39032426985606933\n",
      "train loss:0.3995053479656103\n",
      "train loss:0.5157498285470239\n",
      "train loss:0.24496354697187825\n",
      "train loss:0.3493549296762206\n",
      "train loss:0.37478061891148406\n",
      "train loss:0.3496735477759726\n",
      "train loss:0.33499438433669987\n",
      "train loss:0.3780866048227087\n",
      "train loss:0.40825109055735714\n",
      "train loss:0.49073005729793495\n",
      "train loss:0.347139349583091\n",
      "train loss:0.22076560975804027\n",
      "train loss:0.48390974395673103\n",
      "train loss:0.3864308831984489\n",
      "train loss:0.37866395897909283\n",
      "train loss:0.3900319390154939\n",
      "train loss:0.328614467453922\n",
      "train loss:0.5032097705977455\n",
      "train loss:0.3792112605506938\n",
      "train loss:0.36905170317923447\n",
      "train loss:0.30259031156284466\n",
      "train loss:0.39173940052449835\n",
      "train loss:0.2877959003118308\n",
      "train loss:0.26180619756877105\n",
      "train loss:0.5608423450975534\n",
      "train loss:0.25968147607130715\n",
      "train loss:0.40756265769153116\n",
      "train loss:0.38155460148463455\n",
      "train loss:0.32550182543906186\n",
      "train loss:0.3088422226280695\n",
      "train loss:0.3853950243707979\n",
      "train loss:0.5144991578375897\n",
      "train loss:0.4121970153576381\n",
      "train loss:0.4052459550994889\n",
      "train loss:0.34563458345639786\n",
      "train loss:0.31382492700373604\n",
      "train loss:0.30061026124002327\n",
      "train loss:0.26145617901220347\n",
      "train loss:0.4035599039978858\n",
      "train loss:0.17410669008559032\n",
      "train loss:0.21102285611126448\n",
      "train loss:0.3829801296069064\n",
      "train loss:0.3610164537083659\n",
      "train loss:0.22884596880409414\n",
      "train loss:0.4978362002068258\n",
      "train loss:0.22520289121455533\n",
      "train loss:0.25673490233552143\n",
      "train loss:0.3505463288043358\n",
      "train loss:0.24566721491534857\n",
      "train loss:0.2711175785129462\n",
      "train loss:0.3567846029235877\n",
      "train loss:0.20902984159935886\n",
      "train loss:0.27437327899597014\n",
      "train loss:0.27221106361346026\n",
      "train loss:0.43501715000495794\n",
      "train loss:0.214018044509885\n",
      "train loss:0.18057576197699793\n",
      "train loss:0.2939257929367126\n",
      "train loss:0.23169123539823844\n",
      "train loss:0.20907116207906742\n",
      "train loss:0.25676166772654874\n",
      "train loss:0.18162007125569798\n",
      "train loss:0.4248143665812673\n",
      "train loss:0.27734036580445864\n",
      "train loss:0.3755594886378703\n",
      "train loss:0.17913451257087423\n",
      "train loss:0.28912488111665335\n",
      "train loss:0.4541266783600088\n",
      "train loss:0.44212237262021103\n",
      "train loss:0.3018678063472028\n",
      "train loss:0.3991481866381198\n",
      "train loss:0.22617912469669446\n",
      "train loss:0.20987485144519302\n",
      "train loss:0.3421586821440609\n",
      "train loss:0.18160716939781577\n",
      "train loss:0.4722393085502471\n",
      "train loss:0.26637839636587\n",
      "train loss:0.31440741827461466\n",
      "train loss:0.3048202389901781\n",
      "train loss:0.27545237256684946\n",
      "train loss:0.39715173362467454\n",
      "train loss:0.3752439411679432\n",
      "train loss:0.32041495523523056\n",
      "train loss:0.2557085452828172\n",
      "train loss:0.23132876666708796\n",
      "train loss:0.3412304163006122\n",
      "train loss:0.24292074728286842\n",
      "train loss:0.1764055221723207\n",
      "train loss:0.2626212611528002\n",
      "train loss:0.28013849832867815\n",
      "train loss:0.2469667214959882\n",
      "train loss:0.12500404091440467\n",
      "train loss:0.27773836221305587\n",
      "train loss:0.2628164042048659\n",
      "train loss:0.1939987053837694\n",
      "train loss:0.1794052284978438\n",
      "train loss:0.2669274041385869\n",
      "train loss:0.27798637780791424\n",
      "train loss:0.23953740272540014\n",
      "train loss:0.35011119547176145\n",
      "train loss:0.2836917611814475\n",
      "train loss:0.2760992712142506\n",
      "train loss:0.5093171922201875\n",
      "train loss:0.3067266112355193\n",
      "train loss:0.32367453179181\n",
      "train loss:0.21537531193705894\n",
      "train loss:0.14651180677508166\n",
      "train loss:0.24349210414813494\n",
      "train loss:0.32512624104567517\n",
      "train loss:0.24550088674644044\n",
      "train loss:0.293524034750477\n",
      "train loss:0.3573167738931978\n",
      "train loss:0.2912846775186793\n",
      "train loss:0.22899121338264916\n",
      "train loss:0.5218977939836321\n",
      "train loss:0.3052171783611753\n",
      "train loss:0.25604576206889473\n",
      "train loss:0.23326857315932586\n",
      "train loss:0.3341277436137883\n",
      "train loss:0.3709746031992113\n",
      "train loss:0.13366975017572386\n",
      "train loss:0.24919059307359878\n",
      "train loss:0.27753900501301815\n",
      "train loss:0.2644146405518946\n",
      "train loss:0.3193667177873403\n",
      "train loss:0.27192637630036026\n",
      "train loss:0.19624475589992293\n",
      "train loss:0.17020807614061884\n",
      "train loss:0.11448682158432509\n",
      "train loss:0.23955973341170164\n",
      "train loss:0.24391558269683863\n",
      "train loss:0.16137876208165686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.2058270436019939\n",
      "train loss:0.19825561749174972\n",
      "train loss:0.29330156384682043\n",
      "train loss:0.34773555583138516\n",
      "train loss:0.10452243324600545\n",
      "train loss:0.2741963212266048\n",
      "train loss:0.3298969416948625\n",
      "train loss:0.14598167043919896\n",
      "train loss:0.21705583961707908\n",
      "train loss:0.16433066046173714\n",
      "train loss:0.23069786560725591\n",
      "train loss:0.10295095566877838\n",
      "train loss:0.2258056925749701\n",
      "train loss:0.2520255762411054\n",
      "train loss:0.12928212838548425\n",
      "train loss:0.30530743171776686\n",
      "train loss:0.2611395986379545\n",
      "train loss:0.18672057702948944\n",
      "train loss:0.18582097963419264\n",
      "train loss:0.3770955210222475\n",
      "train loss:0.1813839337955966\n",
      "train loss:0.20930190139686328\n",
      "train loss:0.2199316869563019\n",
      "train loss:0.16736682110571457\n",
      "train loss:0.22662250018637384\n",
      "train loss:0.15521186332868392\n",
      "train loss:0.2711712023563332\n",
      "train loss:0.2410258514649286\n",
      "train loss:0.11454090255007246\n",
      "train loss:0.14140795134925702\n",
      "train loss:0.18406841886492237\n",
      "train loss:0.18456269469044634\n",
      "train loss:0.3140178287724646\n",
      "train loss:0.2312145631995038\n",
      "train loss:0.22372747928499642\n",
      "train loss:0.15954738179431702\n",
      "train loss:0.16368979099198863\n",
      "train loss:0.25220102205208034\n",
      "train loss:0.2820372224296936\n",
      "train loss:0.13989148030259616\n",
      "train loss:0.11824400153703016\n",
      "train loss:0.3235702910797842\n",
      "train loss:0.2798433404157544\n",
      "train loss:0.3722810707688035\n",
      "train loss:0.2135212367485343\n",
      "train loss:0.38313624596610174\n",
      "train loss:0.31693794413582355\n",
      "train loss:0.1290696498148027\n",
      "train loss:0.214764255022026\n",
      "train loss:0.3299617192862133\n",
      "train loss:0.21592236299795023\n",
      "train loss:0.2145355748647513\n",
      "train loss:0.27141689417572035\n",
      "train loss:0.28720167025393245\n",
      "train loss:0.3371081593847037\n",
      "train loss:0.19990714585115707\n",
      "train loss:0.1681607073441456\n",
      "train loss:0.14461142221257076\n",
      "train loss:0.17212750345334044\n",
      "train loss:0.21631275704042466\n",
      "train loss:0.3298377749474915\n",
      "train loss:0.2719155993773122\n",
      "train loss:0.1935958105636043\n",
      "train loss:0.24063969443578234\n",
      "train loss:0.16514249213272658\n",
      "train loss:0.238349121181194\n",
      "train loss:0.13182486072417188\n",
      "train loss:0.24458443434758187\n",
      "train loss:0.24709576187160592\n",
      "train loss:0.42661341982210893\n",
      "train loss:0.10511939833432599\n",
      "train loss:0.24422942189808017\n",
      "train loss:0.30298389994385755\n",
      "train loss:0.19349268563684136\n",
      "train loss:0.12197440668507264\n",
      "train loss:0.1825518548493565\n",
      "train loss:0.16797721600363175\n",
      "train loss:0.2538869372571051\n",
      "train loss:0.2617694637123028\n",
      "train loss:0.24516552781135814\n",
      "train loss:0.3967629792606213\n",
      "train loss:0.27858937917939575\n",
      "train loss:0.33046074497208666\n",
      "train loss:0.2682252351032407\n",
      "train loss:0.3473336265241602\n",
      "train loss:0.29590917414077444\n",
      "train loss:0.22776803272568003\n",
      "train loss:0.14015006457401838\n",
      "train loss:0.1807259358188984\n",
      "train loss:0.17355774498173834\n",
      "train loss:0.15405099659605906\n",
      "train loss:0.16516786118505472\n",
      "train loss:0.27979941303573463\n",
      "train loss:0.2198108552282677\n",
      "train loss:0.3215218966720885\n",
      "train loss:0.15153723380067463\n",
      "train loss:0.11342664421090833\n",
      "train loss:0.3346730860946565\n",
      "train loss:0.19497031695063227\n",
      "train loss:0.07654335985410614\n",
      "train loss:0.1595037322881459\n",
      "train loss:0.24134616928381183\n",
      "train loss:0.1344262154732691\n",
      "train loss:0.20497368556857296\n",
      "train loss:0.24925239939984575\n",
      "train loss:0.16781142645079267\n",
      "train loss:0.14111759529009646\n",
      "train loss:0.21683891659351612\n",
      "train loss:0.2223982233786814\n",
      "train loss:0.18425574368212763\n",
      "train loss:0.2752022464681245\n",
      "train loss:0.19524785640467995\n",
      "train loss:0.09789379201100794\n",
      "train loss:0.23120282099485392\n",
      "train loss:0.22389187994585463\n",
      "train loss:0.13085495360506189\n",
      "train loss:0.20621054596877875\n",
      "train loss:0.2027608903073955\n",
      "train loss:0.2649559046170108\n",
      "train loss:0.14633896236922195\n",
      "train loss:0.20777280597317094\n",
      "train loss:0.2811753914381393\n",
      "train loss:0.17201925461015402\n",
      "train loss:0.17825250011476396\n",
      "train loss:0.20080569663487427\n",
      "train loss:0.1952505501290592\n",
      "train loss:0.10388921424316391\n",
      "train loss:0.44611307713911263\n",
      "train loss:0.11550427651146591\n",
      "train loss:0.20342728442942037\n",
      "train loss:0.10270794453846069\n",
      "train loss:0.2539978724397736\n",
      "train loss:0.27866903609759125\n",
      "train loss:0.16291379895043778\n",
      "train loss:0.14240172269814677\n",
      "train loss:0.2168752230126134\n",
      "train loss:0.24048459709322373\n",
      "train loss:0.131591645151139\n",
      "train loss:0.11555543521505879\n",
      "train loss:0.16993000637759625\n",
      "train loss:0.154598286319231\n",
      "train loss:0.10210131747980032\n",
      "train loss:0.14839723068534225\n",
      "train loss:0.161921210958965\n",
      "train loss:0.16343496099435154\n",
      "train loss:0.15119988849613406\n",
      "train loss:0.19579675109787598\n",
      "train loss:0.26651380393531154\n",
      "train loss:0.2589678670225515\n",
      "train loss:0.16540058149773582\n",
      "train loss:0.21365040122803414\n",
      "train loss:0.1965444923576126\n",
      "train loss:0.13157318615541785\n",
      "train loss:0.21011280409885408\n",
      "train loss:0.11981693076435342\n",
      "train loss:0.22730787376269496\n",
      "train loss:0.2475908838843729\n",
      "train loss:0.25546750818758185\n",
      "train loss:0.15411580714051706\n",
      "train loss:0.07264097446352029\n",
      "train loss:0.2719913521643768\n",
      "train loss:0.12928103640594915\n",
      "train loss:0.15488858784495355\n",
      "train loss:0.18430653764009136\n",
      "train loss:0.19465295968506896\n",
      "train loss:0.12016219920761319\n",
      "train loss:0.18269943944588582\n",
      "train loss:0.32590522670694855\n",
      "train loss:0.1054961609132989\n",
      "train loss:0.2508271361827072\n",
      "train loss:0.16325469112485802\n",
      "train loss:0.15723418078420504\n",
      "train loss:0.13220264299798737\n",
      "train loss:0.1590061935744951\n",
      "train loss:0.12682100653427347\n",
      "train loss:0.1704644178474437\n",
      "train loss:0.14949678952435666\n",
      "train loss:0.21899643521338683\n",
      "train loss:0.15145885736982095\n",
      "train loss:0.16339681759949584\n",
      "train loss:0.10810921882575658\n",
      "train loss:0.17043501566640779\n",
      "train loss:0.13503837502083796\n",
      "train loss:0.12281574821952639\n",
      "train loss:0.23066372185343262\n",
      "train loss:0.20327045780134412\n",
      "train loss:0.15692593236322894\n",
      "train loss:0.24507449414237836\n",
      "train loss:0.1959378676723908\n",
      "train loss:0.09590001100079107\n",
      "train loss:0.22247262105602592\n",
      "train loss:0.18244869864606117\n",
      "train loss:0.09204475048071377\n",
      "train loss:0.10700465974442538\n",
      "train loss:0.3071764346614882\n",
      "train loss:0.11736376577769547\n",
      "train loss:0.22899831335745346\n",
      "train loss:0.16916065587560047\n",
      "train loss:0.2494627775028305\n",
      "train loss:0.0892057521584158\n",
      "train loss:0.32035114064597914\n",
      "train loss:0.17950663429484068\n",
      "train loss:0.1835971719471594\n",
      "train loss:0.18835620383929308\n",
      "train loss:0.1899847213128728\n",
      "train loss:0.12643086105979393\n",
      "train loss:0.23505924713758014\n",
      "train loss:0.14636606563280982\n",
      "train loss:0.1982525056847507\n",
      "train loss:0.0993978075411777\n",
      "train loss:0.17830475060061157\n",
      "train loss:0.13209585027105278\n",
      "train loss:0.252567506904384\n",
      "train loss:0.21630125590653762\n",
      "train loss:0.17149110960671954\n",
      "train loss:0.15761354319819695\n",
      "train loss:0.21185992976203585\n",
      "train loss:0.26243342456681484\n",
      "train loss:0.2168034114010239\n",
      "train loss:0.15796818371252883\n",
      "train loss:0.18158706048337062\n",
      "train loss:0.15576312876515616\n",
      "train loss:0.13833944535553755\n",
      "train loss:0.10830257429993452\n",
      "train loss:0.17505481823636043\n",
      "train loss:0.21663468777339875\n",
      "train loss:0.1827619437979627\n",
      "train loss:0.14319566201783943\n",
      "train loss:0.11913749711834334\n",
      "train loss:0.06943690460068282\n",
      "train loss:0.17703690432594069\n",
      "train loss:0.15300279762086835\n",
      "train loss:0.1540179870470634\n",
      "train loss:0.11436862939146641\n",
      "train loss:0.14281866294787832\n",
      "train loss:0.08444686355913106\n",
      "train loss:0.21977770473780592\n",
      "train loss:0.25580589302995105\n",
      "train loss:0.10806558379683988\n",
      "train loss:0.1316084483357036\n",
      "train loss:0.18004309165978008\n",
      "train loss:0.11753419574466713\n",
      "train loss:0.10870587598103866\n",
      "train loss:0.20895914990968723\n",
      "train loss:0.09192414914698853\n",
      "train loss:0.1228316564246174\n",
      "train loss:0.15686208302609914\n",
      "train loss:0.17559748380626644\n",
      "train loss:0.11578662480066824\n",
      "train loss:0.13472454885806\n",
      "train loss:0.11409449831902091\n",
      "train loss:0.1971607767545877\n",
      "train loss:0.08302756417866963\n",
      "train loss:0.17582248626752534\n",
      "train loss:0.18499715556501517\n",
      "train loss:0.19113836661223066\n",
      "train loss:0.09403729865888448\n",
      "train loss:0.2981185308363458\n",
      "train loss:0.07056026782501762\n",
      "train loss:0.14870515822255015\n",
      "train loss:0.16108418176019906\n",
      "train loss:0.26177156101558263\n",
      "train loss:0.2356779906390985\n",
      "train loss:0.17786953177320822\n",
      "train loss:0.08628230869720338\n",
      "train loss:0.1397800555714538\n",
      "train loss:0.07327439280355316\n",
      "train loss:0.22611024284622863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.28492841692004006\n",
      "train loss:0.2738082599639055\n",
      "train loss:0.1151313728082935\n",
      "train loss:0.18478357221620864\n",
      "train loss:0.1387914836028244\n",
      "train loss:0.17978990094188307\n",
      "train loss:0.1813231460981294\n",
      "train loss:0.17403033048195937\n",
      "train loss:0.15610285223917533\n",
      "train loss:0.12066607206775412\n",
      "train loss:0.2019810386794095\n",
      "train loss:0.09017610221589817\n",
      "train loss:0.07679466766062623\n",
      "train loss:0.10023686122574936\n",
      "train loss:0.16685833363888058\n",
      "train loss:0.11840277866959015\n",
      "train loss:0.10503956593908745\n",
      "train loss:0.28410868564487696\n",
      "train loss:0.11216983066340573\n",
      "train loss:0.13138035205703782\n",
      "train loss:0.12103771199738977\n",
      "train loss:0.19820893497321884\n",
      "train loss:0.08180544747701181\n",
      "train loss:0.24677496175844912\n",
      "train loss:0.22355420752745858\n",
      "train loss:0.15493049608343512\n",
      "train loss:0.20404231506873985\n",
      "train loss:0.15604543816725389\n",
      "train loss:0.16806289240343614\n",
      "train loss:0.19869295220592037\n",
      "train loss:0.11998717201735218\n",
      "train loss:0.18868166287697805\n",
      "train loss:0.06417674404011878\n",
      "train loss:0.0896126382803832\n",
      "train loss:0.16795862535369416\n",
      "train loss:0.12958481189431237\n",
      "train loss:0.24118712401522596\n",
      "train loss:0.10851606017159503\n",
      "train loss:0.1489802216577214\n",
      "train loss:0.06182135440754279\n",
      "train loss:0.1172530939316877\n",
      "train loss:0.16765887443581587\n",
      "train loss:0.09390083376965958\n",
      "train loss:0.17613171125610333\n",
      "train loss:0.05526784200781806\n",
      "train loss:0.1957891650762849\n",
      "train loss:0.13928916906482458\n",
      "train loss:0.08927903341343027\n",
      "train loss:0.14386937064126065\n",
      "train loss:0.1657446638809093\n",
      "train loss:0.2137179535752531\n",
      "train loss:0.13471949322120336\n",
      "train loss:0.12683412568730704\n",
      "train loss:0.11017716161345589\n",
      "train loss:0.11601178970246709\n",
      "train loss:0.0994681780847729\n",
      "train loss:0.1803836411738478\n",
      "train loss:0.16870596489836942\n",
      "train loss:0.05961608584625175\n",
      "train loss:0.14112549576500671\n",
      "train loss:0.05427828733443345\n",
      "train loss:0.1534703379957495\n",
      "train loss:0.17786595948340622\n",
      "train loss:0.16875669332811222\n",
      "=== epoch:2, train acc:0.96, test acc:0.956 ===\n",
      "train loss:0.09214883200886993\n",
      "train loss:0.047406594040250445\n",
      "train loss:0.12386043908151213\n",
      "train loss:0.16172396498711183\n",
      "train loss:0.13457039189892828\n",
      "train loss:0.13867567793692756\n",
      "train loss:0.18782053923358508\n",
      "train loss:0.1543068781701459\n",
      "train loss:0.17310280889416088\n",
      "train loss:0.06825709395272511\n",
      "train loss:0.11491882748881657\n",
      "train loss:0.07469236318539044\n",
      "train loss:0.19311170294023794\n",
      "train loss:0.06964460960216004\n",
      "train loss:0.17065864342386466\n",
      "train loss:0.09365191134158418\n",
      "train loss:0.1171741452045238\n",
      "train loss:0.1622641576089129\n",
      "train loss:0.10538832407576852\n",
      "train loss:0.16117584295039078\n",
      "train loss:0.1796572100448962\n",
      "train loss:0.10079636448701183\n",
      "train loss:0.18605562545027354\n",
      "train loss:0.1478572314325717\n",
      "train loss:0.13886241912385636\n",
      "train loss:0.14095827073322328\n",
      "train loss:0.16537821995345706\n",
      "train loss:0.17673921520843777\n",
      "train loss:0.05019181952282424\n",
      "train loss:0.11462024705310746\n",
      "train loss:0.05838226744504342\n",
      "train loss:0.08904463143873112\n",
      "train loss:0.12829207923576255\n",
      "train loss:0.06780453953266899\n",
      "train loss:0.17455332229410817\n",
      "train loss:0.11070458384374747\n",
      "train loss:0.08180598888314344\n",
      "train loss:0.044835108823148236\n",
      "train loss:0.08418879340074362\n",
      "train loss:0.08618612336760362\n",
      "train loss:0.12591987782221115\n",
      "train loss:0.12358395703985434\n",
      "train loss:0.09240901357714909\n",
      "train loss:0.06212766432062247\n",
      "train loss:0.09821034548630868\n",
      "train loss:0.10054043869813116\n",
      "train loss:0.08713555544309293\n",
      "train loss:0.08004350731908742\n",
      "train loss:0.14869627270931335\n",
      "train loss:0.10295809291026872\n",
      "train loss:0.10594660845497153\n",
      "train loss:0.1266023545772479\n",
      "train loss:0.14986691974390612\n",
      "train loss:0.0758647196554238\n",
      "train loss:0.06845746574434218\n",
      "train loss:0.13875678394528135\n",
      "train loss:0.11567484753783822\n",
      "train loss:0.0819555996140166\n",
      "train loss:0.10333792705626546\n",
      "train loss:0.12505882996789883\n",
      "train loss:0.07983612607171006\n",
      "train loss:0.08208922575845312\n",
      "train loss:0.14814708565037862\n",
      "train loss:0.09522748925938024\n",
      "train loss:0.1461658146690624\n",
      "train loss:0.08533569196783204\n",
      "train loss:0.135753931601962\n",
      "train loss:0.17188548703964485\n",
      "train loss:0.10730710577480332\n",
      "train loss:0.1562395071363962\n",
      "train loss:0.3066633902618489\n",
      "train loss:0.10490422181875024\n",
      "train loss:0.0929737654469537\n",
      "train loss:0.12604173987520592\n",
      "train loss:0.06280649673730465\n",
      "train loss:0.10342562444661668\n",
      "train loss:0.10917710096710165\n",
      "train loss:0.0649088451080618\n",
      "train loss:0.1399303104526697\n",
      "train loss:0.15846205624149803\n",
      "train loss:0.2316914721744675\n",
      "train loss:0.12466355695460933\n",
      "train loss:0.13622500762895126\n",
      "train loss:0.05209105434623054\n",
      "train loss:0.10239991475830468\n",
      "train loss:0.0736868062208057\n",
      "train loss:0.09022945772008244\n",
      "train loss:0.11702541949147284\n",
      "train loss:0.2174876670988443\n",
      "train loss:0.08882818639128418\n",
      "train loss:0.06637505767159652\n",
      "train loss:0.19825034184928644\n",
      "train loss:0.08395435227524521\n",
      "train loss:0.12451749210397799\n",
      "train loss:0.23416678240028677\n",
      "train loss:0.12588786505398414\n",
      "train loss:0.19811283077537653\n",
      "train loss:0.17075160261596017\n",
      "train loss:0.160190196223962\n",
      "train loss:0.08482189099083526\n",
      "train loss:0.0755281020079512\n",
      "train loss:0.14934844484227175\n",
      "train loss:0.14504743534237247\n",
      "train loss:0.04406324718069962\n",
      "train loss:0.04423549477015541\n",
      "train loss:0.05990129205915198\n",
      "train loss:0.10955996179816882\n",
      "train loss:0.1081914536519029\n",
      "train loss:0.08889918809300477\n",
      "train loss:0.09880889282465745\n",
      "train loss:0.08913011595971693\n",
      "train loss:0.14330719711751472\n",
      "train loss:0.14379384937382128\n",
      "train loss:0.12811753647660823\n",
      "train loss:0.11382898049760337\n",
      "train loss:0.13203593498739788\n",
      "train loss:0.043262117128775764\n",
      "train loss:0.0982643333957228\n",
      "train loss:0.10837151392590672\n",
      "train loss:0.20794437551104772\n",
      "train loss:0.09714084789626064\n",
      "train loss:0.1776385520654417\n",
      "train loss:0.07427431763551272\n",
      "train loss:0.20479618878216346\n",
      "train loss:0.07339432392241052\n",
      "train loss:0.07422942467882247\n",
      "train loss:0.09976788859364366\n",
      "train loss:0.11940206616938186\n",
      "train loss:0.07976900414480703\n",
      "train loss:0.0807265830588176\n",
      "train loss:0.1623873645627105\n",
      "train loss:0.08924184588867007\n",
      "train loss:0.18941294822892707\n",
      "train loss:0.06885910826614255\n",
      "train loss:0.0898012359749398\n",
      "train loss:0.11343867418935702\n",
      "train loss:0.0927537322676089\n",
      "train loss:0.08569675880787411\n",
      "train loss:0.08222118526191863\n",
      "train loss:0.08068813956395783\n",
      "train loss:0.08947838592158015\n",
      "train loss:0.22907397979606045\n",
      "train loss:0.07645104566591242\n",
      "train loss:0.17763699768906163\n",
      "train loss:0.08395539504012371\n",
      "train loss:0.11805338459107903\n",
      "train loss:0.08283834055424194\n",
      "train loss:0.14104421127545214\n",
      "train loss:0.04723223416033872\n",
      "train loss:0.19933407906556344\n",
      "train loss:0.13275528810838172\n",
      "train loss:0.14820467960298578\n",
      "train loss:0.07000467181596975\n",
      "train loss:0.19235334107426325\n",
      "train loss:0.14527838759509126\n",
      "train loss:0.03620030803718169\n",
      "train loss:0.1468880451840383\n",
      "train loss:0.08861201682459079\n",
      "train loss:0.18255216260309381\n",
      "train loss:0.10342422675449937\n",
      "train loss:0.13154035272206113\n",
      "train loss:0.08059016310374548\n",
      "train loss:0.087733057812242\n",
      "train loss:0.10331622985748029\n",
      "train loss:0.05068334935662225\n",
      "train loss:0.19630971005763925\n",
      "train loss:0.11981010215111766\n",
      "train loss:0.14268565705584674\n",
      "train loss:0.17935353868525186\n",
      "train loss:0.09139444585617001\n",
      "train loss:0.09370402675315408\n",
      "train loss:0.059801532742099234\n",
      "train loss:0.18104269746238275\n",
      "train loss:0.09735040995548379\n",
      "train loss:0.13124112741018887\n",
      "train loss:0.0886057124026211\n",
      "train loss:0.12766222203244937\n",
      "train loss:0.20035474547789278\n",
      "train loss:0.06451182789902898\n",
      "train loss:0.14181240335861506\n",
      "train loss:0.32611371253838556\n",
      "train loss:0.16707334950020186\n",
      "train loss:0.07161971675276654\n",
      "train loss:0.13201814739765896\n",
      "train loss:0.06689397180875724\n",
      "train loss:0.07774082815999998\n",
      "train loss:0.11966813383680654\n",
      "train loss:0.081966013790557\n",
      "train loss:0.23736523215403715\n",
      "train loss:0.1503905656051602\n",
      "train loss:0.11417487047469306\n",
      "train loss:0.11507716364628744\n",
      "train loss:0.15794993932656992\n",
      "train loss:0.08322934306089382\n",
      "train loss:0.09764229612323286\n",
      "train loss:0.14301104256927327\n",
      "train loss:0.22380242825876492\n",
      "train loss:0.16462348483197042\n",
      "train loss:0.1238502535781632\n",
      "train loss:0.15668341350262419\n",
      "train loss:0.0751744172763679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.061944393092430425\n",
      "train loss:0.06869240433722001\n",
      "train loss:0.11290213357688873\n",
      "train loss:0.06385739302133113\n",
      "train loss:0.16659627773754135\n",
      "train loss:0.06474369641143257\n",
      "train loss:0.06803033512412886\n",
      "train loss:0.19307296564954865\n",
      "train loss:0.08295326431216533\n",
      "train loss:0.07579353385990406\n",
      "train loss:0.1476800801085475\n",
      "train loss:0.13636647461603263\n",
      "train loss:0.14319730069067757\n",
      "train loss:0.1922698644493697\n",
      "train loss:0.22625439180287304\n",
      "train loss:0.11677980691591594\n",
      "train loss:0.09962017877945599\n",
      "train loss:0.13459471615129356\n",
      "train loss:0.12550274650955903\n",
      "train loss:0.10169631746439865\n",
      "train loss:0.1018621138851974\n",
      "train loss:0.13309159056277556\n",
      "train loss:0.0916919468659367\n",
      "train loss:0.03812131602290263\n",
      "train loss:0.1341561307405928\n",
      "train loss:0.08482744875640619\n",
      "train loss:0.22413828979620654\n",
      "train loss:0.15326100088519728\n",
      "train loss:0.05323673786620293\n",
      "train loss:0.056362809024925076\n",
      "train loss:0.03578235908514653\n",
      "train loss:0.18993195711928565\n",
      "train loss:0.08384504548698934\n",
      "train loss:0.06081831346291123\n",
      "train loss:0.1750416211039175\n",
      "train loss:0.050556529863998965\n",
      "train loss:0.1574394422969128\n",
      "train loss:0.17967629773378402\n",
      "train loss:0.08457967385993997\n",
      "train loss:0.06969301310993398\n",
      "train loss:0.1048906986855797\n",
      "train loss:0.08333275215876608\n",
      "train loss:0.10064151693712883\n",
      "train loss:0.05884749601135567\n",
      "train loss:0.0443261209918392\n",
      "train loss:0.1322763762162752\n",
      "train loss:0.1263900200293625\n",
      "train loss:0.06502952490316638\n",
      "train loss:0.17457965070712372\n",
      "train loss:0.06779043275796465\n",
      "train loss:0.03968635745959487\n",
      "train loss:0.14895491694861396\n",
      "train loss:0.03215443707750142\n",
      "train loss:0.08492008740399783\n",
      "train loss:0.18357583333239358\n",
      "train loss:0.07462710447348248\n",
      "train loss:0.17206888786583271\n",
      "train loss:0.09552908530657919\n",
      "train loss:0.07262121050240916\n",
      "train loss:0.06719130015681074\n",
      "train loss:0.0784511863202651\n",
      "train loss:0.14118731133260712\n",
      "train loss:0.06473023929201957\n",
      "train loss:0.06614998663716416\n",
      "train loss:0.11487805375032484\n",
      "train loss:0.1895921677328325\n",
      "train loss:0.09373837267231931\n",
      "train loss:0.12390603318087542\n",
      "train loss:0.08855799323161398\n",
      "train loss:0.05449672523200209\n",
      "train loss:0.12327503579682077\n",
      "train loss:0.0804418267617414\n",
      "train loss:0.06602134341262272\n",
      "train loss:0.0896015299678875\n",
      "train loss:0.2277993405868299\n",
      "train loss:0.11824622253081016\n",
      "train loss:0.13334870634098434\n",
      "train loss:0.12216528155279253\n",
      "train loss:0.0848200131262382\n",
      "train loss:0.12828881359175096\n",
      "train loss:0.0637371830815125\n",
      "train loss:0.13173606168907553\n",
      "train loss:0.1127618822997949\n",
      "train loss:0.061475827605384815\n",
      "train loss:0.052263431039216365\n",
      "train loss:0.04858282099248798\n",
      "train loss:0.07727975636703963\n",
      "train loss:0.07985681933993331\n",
      "train loss:0.08116309528185832\n",
      "train loss:0.193158238973528\n",
      "train loss:0.046029331460048804\n",
      "train loss:0.0665058368210639\n",
      "train loss:0.06489359099952811\n",
      "train loss:0.10328714145272073\n",
      "train loss:0.14209076565125295\n",
      "train loss:0.04921650145063325\n",
      "train loss:0.07659331916555112\n",
      "train loss:0.16248334141211257\n",
      "train loss:0.10604426739431157\n",
      "train loss:0.14027400897604136\n",
      "train loss:0.09819409558802468\n",
      "train loss:0.1324296972897763\n",
      "train loss:0.13771811417849034\n",
      "train loss:0.12971395749075224\n",
      "train loss:0.10155922859512366\n",
      "train loss:0.07428577219296709\n",
      "train loss:0.09044148107400335\n",
      "train loss:0.08531924867918621\n",
      "train loss:0.061168433121270877\n",
      "train loss:0.14236752880068307\n",
      "train loss:0.03136623861164412\n",
      "train loss:0.0746463927182237\n",
      "train loss:0.11382696541654357\n",
      "train loss:0.034751154435455574\n",
      "train loss:0.06693158858352248\n",
      "train loss:0.04798652438402875\n",
      "train loss:0.12982057905678734\n",
      "train loss:0.06302521140765471\n",
      "train loss:0.10038607230083618\n",
      "train loss:0.07577416738900725\n",
      "train loss:0.12246606985528928\n",
      "train loss:0.04502590392463996\n",
      "train loss:0.10323386838573965\n",
      "train loss:0.09929655221303538\n",
      "train loss:0.08482221568158414\n",
      "train loss:0.08103466357576079\n",
      "train loss:0.09340231208775808\n",
      "train loss:0.04777903627449624\n",
      "train loss:0.12621812733934315\n",
      "train loss:0.0509805552356617\n",
      "train loss:0.05487911180033586\n",
      "train loss:0.09280823876503445\n",
      "train loss:0.04388292011515664\n",
      "train loss:0.06988948320904996\n",
      "train loss:0.05686166293143067\n",
      "train loss:0.05545828421408549\n",
      "train loss:0.1577193625660212\n",
      "train loss:0.085635829395092\n",
      "train loss:0.09455698984527397\n",
      "train loss:0.09074046143974289\n",
      "train loss:0.08870847689699002\n",
      "train loss:0.09985418524845725\n",
      "train loss:0.0660973507434408\n",
      "train loss:0.09718025975054491\n",
      "train loss:0.07258340505231994\n",
      "train loss:0.09266082552185288\n",
      "train loss:0.04889704558030931\n",
      "train loss:0.056554585212314136\n",
      "train loss:0.09229253234780792\n",
      "train loss:0.06845605413639712\n",
      "train loss:0.04653244186507167\n",
      "train loss:0.03655995975306505\n",
      "train loss:0.150412814585623\n",
      "train loss:0.1913928231516975\n",
      "train loss:0.1253957484767723\n",
      "train loss:0.05723577257346158\n",
      "train loss:0.06862092955151172\n",
      "train loss:0.02468113337911599\n",
      "train loss:0.07603361321492297\n",
      "train loss:0.047531733337188256\n",
      "train loss:0.057814593385787906\n",
      "train loss:0.13261798405275657\n",
      "train loss:0.02273087831818386\n",
      "train loss:0.09495916773604256\n",
      "train loss:0.09849016922302069\n",
      "train loss:0.037373739821733504\n",
      "train loss:0.08893387238520094\n",
      "train loss:0.08614874485567718\n",
      "train loss:0.07572302008803673\n",
      "train loss:0.09536615101829307\n",
      "train loss:0.0552296555855979\n",
      "train loss:0.03703608362990188\n",
      "train loss:0.10086292519768665\n",
      "train loss:0.09260925297452843\n",
      "train loss:0.1323996127463324\n",
      "train loss:0.10167870398600705\n",
      "train loss:0.0442154832257952\n",
      "train loss:0.025812042357548578\n",
      "train loss:0.07700844281226323\n",
      "train loss:0.1356001857282211\n",
      "train loss:0.0654528663726189\n",
      "train loss:0.12190788584054751\n",
      "train loss:0.061935820658441505\n",
      "train loss:0.12597621757050542\n",
      "train loss:0.03499307306376922\n",
      "train loss:0.05447399486973614\n",
      "train loss:0.030311319587970353\n",
      "train loss:0.06962643277008417\n",
      "train loss:0.09151091732980303\n",
      "train loss:0.03384819799222245\n",
      "train loss:0.10303771535415132\n",
      "train loss:0.09865228916162774\n",
      "train loss:0.07717418395837056\n",
      "train loss:0.12140421353128206\n",
      "train loss:0.04637543165199221\n",
      "train loss:0.06838831345435843\n",
      "train loss:0.05299396059892736\n",
      "train loss:0.07222551038714531\n",
      "train loss:0.18896499100985875\n",
      "train loss:0.2076672826853264\n",
      "train loss:0.07585588637956117\n",
      "train loss:0.04547235257914943\n",
      "train loss:0.08700386591757377\n",
      "train loss:0.1088033256909526\n",
      "train loss:0.01851479750264548\n",
      "train loss:0.045531822492785194\n",
      "train loss:0.10507316785260055\n",
      "train loss:0.07659674904205353\n",
      "train loss:0.06597140123579517\n",
      "train loss:0.051528861620029905\n",
      "train loss:0.043612608730032185\n",
      "train loss:0.09344112453474487\n",
      "train loss:0.07641233791766902\n",
      "train loss:0.030649009997612595\n",
      "train loss:0.038116975389578686\n",
      "train loss:0.05013618992952609\n",
      "train loss:0.021915098332953895\n",
      "train loss:0.21628860948275963\n",
      "train loss:0.03084476186709826\n",
      "train loss:0.04403226518557396\n",
      "train loss:0.10742044754214661\n",
      "train loss:0.08552984055607608\n",
      "train loss:0.11200492476475789\n",
      "train loss:0.09045430087179658\n",
      "train loss:0.029795410382511857\n",
      "train loss:0.13987407116508024\n",
      "train loss:0.03505053836553278\n",
      "train loss:0.13890615096615747\n",
      "train loss:0.17830713895169256\n",
      "train loss:0.05497559225229647\n",
      "train loss:0.06664771554671636\n",
      "train loss:0.0459894309612425\n",
      "train loss:0.026246717041060387\n",
      "train loss:0.10681369899981245\n",
      "train loss:0.07705499838721629\n",
      "train loss:0.06984582095547635\n",
      "train loss:0.047288555618210444\n",
      "train loss:0.0688059238751778\n",
      "train loss:0.11657763415390336\n",
      "train loss:0.08300179554762878\n",
      "train loss:0.09966244480161315\n",
      "train loss:0.01693941121106686\n",
      "train loss:0.09783045961157956\n",
      "train loss:0.04187554111105895\n",
      "train loss:0.1067484161724126\n",
      "train loss:0.07894079700962946\n",
      "train loss:0.08212860130218928\n",
      "train loss:0.08803192460419113\n",
      "train loss:0.17730523395561512\n",
      "train loss:0.13993712524149401\n",
      "train loss:0.07816372186103777\n",
      "train loss:0.05529018226333126\n",
      "train loss:0.06470281462425076\n",
      "train loss:0.06713076575565911\n",
      "train loss:0.0739482168090583\n",
      "train loss:0.11512971313899835\n",
      "train loss:0.1247086843336613\n",
      "train loss:0.03945534262538362\n",
      "train loss:0.11429869019066136\n",
      "train loss:0.03700411345647126\n",
      "train loss:0.09613233641763566\n",
      "train loss:0.12585839296341628\n",
      "train loss:0.10178523951255261\n",
      "train loss:0.03813872974833541\n",
      "train loss:0.10511241930356484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.15034118643430738\n",
      "train loss:0.05721376673036672\n",
      "train loss:0.08928986804263703\n",
      "train loss:0.116273992619488\n",
      "train loss:0.05026265787739119\n",
      "train loss:0.0917473941448762\n",
      "train loss:0.039973314573577466\n",
      "train loss:0.12487615197648338\n",
      "train loss:0.13834529598684214\n",
      "train loss:0.09951408448338464\n",
      "train loss:0.13418880655966944\n",
      "train loss:0.04927470007467201\n",
      "train loss:0.0415353527508674\n",
      "train loss:0.05401915167651669\n",
      "train loss:0.10787767243719752\n",
      "train loss:0.06739350479269145\n",
      "train loss:0.12590152314442457\n",
      "train loss:0.12847652369330273\n",
      "train loss:0.034631262700795334\n",
      "train loss:0.1156608885320604\n",
      "train loss:0.07619891178731893\n",
      "train loss:0.033131454640771996\n",
      "train loss:0.03309687996513978\n",
      "train loss:0.08510642468779314\n",
      "train loss:0.12778450008261927\n",
      "train loss:0.034577868224136596\n",
      "train loss:0.0244893797573018\n",
      "train loss:0.11172112486661122\n",
      "train loss:0.03350194590791248\n",
      "train loss:0.07231990869825732\n",
      "train loss:0.1299583520635891\n",
      "train loss:0.08211769040981626\n",
      "train loss:0.01853243341130796\n",
      "train loss:0.05660834252202663\n",
      "train loss:0.07487522410752664\n",
      "train loss:0.09869030768718097\n",
      "train loss:0.12761675300347938\n",
      "train loss:0.06001773344505702\n",
      "train loss:0.04907794154622034\n",
      "train loss:0.06924772195924875\n",
      "train loss:0.1423450847480663\n",
      "train loss:0.05763442701237698\n",
      "train loss:0.05132262245611855\n",
      "train loss:0.045597502844223176\n",
      "train loss:0.06268371223465559\n",
      "train loss:0.11600295043371839\n",
      "train loss:0.05474251987116164\n",
      "train loss:0.040283259567435385\n",
      "train loss:0.04252946525191133\n",
      "train loss:0.08071744316285073\n",
      "train loss:0.04917274658304534\n",
      "train loss:0.08981754186757168\n",
      "train loss:0.029816217143536754\n",
      "train loss:0.06692488862169617\n",
      "train loss:0.09787393885361158\n",
      "train loss:0.11170942058069552\n",
      "train loss:0.030728912333073632\n",
      "train loss:0.07872302087714171\n",
      "train loss:0.08618128212769316\n",
      "train loss:0.07138514251592751\n",
      "train loss:0.07549366157155446\n",
      "train loss:0.04459753720284639\n",
      "train loss:0.03516514222445107\n",
      "train loss:0.02695411301187411\n",
      "train loss:0.21332329345785303\n",
      "train loss:0.04813480347067044\n",
      "train loss:0.13935518066048622\n",
      "train loss:0.11179683190016544\n",
      "train loss:0.09453455298122558\n",
      "train loss:0.10486448357877168\n",
      "train loss:0.07611494943298072\n",
      "train loss:0.08611291039529409\n",
      "train loss:0.08813418057710325\n",
      "train loss:0.12003071726116833\n",
      "train loss:0.03767633121902691\n",
      "train loss:0.11248039522389046\n",
      "train loss:0.06975898473150116\n",
      "train loss:0.06359910029154411\n",
      "train loss:0.10744812318575077\n",
      "train loss:0.048178300459361466\n",
      "train loss:0.05871294629539545\n",
      "train loss:0.06840939224412354\n",
      "train loss:0.11769714092975071\n",
      "train loss:0.05574019097303759\n",
      "train loss:0.062337491075754335\n",
      "train loss:0.031480635840065135\n",
      "train loss:0.11032002776588891\n",
      "train loss:0.05488252459661875\n",
      "train loss:0.02327240679929935\n",
      "train loss:0.19965454472923305\n",
      "train loss:0.2501861073476032\n",
      "train loss:0.10323392823439387\n",
      "train loss:0.01666058203409739\n",
      "train loss:0.061803153183537775\n",
      "train loss:0.03518278561097346\n",
      "train loss:0.08995091768929289\n",
      "train loss:0.07227361327154994\n",
      "train loss:0.06829296931586215\n",
      "train loss:0.017487731544713205\n",
      "train loss:0.05823840452920809\n",
      "train loss:0.07483956640191874\n",
      "train loss:0.08579206170901604\n",
      "train loss:0.11802264601223678\n",
      "train loss:0.06664541473251993\n",
      "train loss:0.07551699724811434\n",
      "train loss:0.04702789910674848\n",
      "train loss:0.055809721063236645\n",
      "train loss:0.02505764744386603\n",
      "train loss:0.029206952512173118\n",
      "train loss:0.036735388690862604\n",
      "train loss:0.13770447004034098\n",
      "train loss:0.06213814174962019\n",
      "train loss:0.048145121573596635\n",
      "train loss:0.06006347352807529\n",
      "train loss:0.06495403315672825\n",
      "train loss:0.06297535344141053\n",
      "train loss:0.018503612885877506\n",
      "train loss:0.03072844335670906\n",
      "train loss:0.04895481004995636\n",
      "train loss:0.059824084974716855\n",
      "train loss:0.10069943781826708\n",
      "train loss:0.05995999648086014\n",
      "train loss:0.0513177722066275\n",
      "train loss:0.07051158193479595\n",
      "train loss:0.029080406104296477\n",
      "train loss:0.09666335201083838\n",
      "train loss:0.0615545694573916\n",
      "train loss:0.15541502714796002\n",
      "train loss:0.06973965380754998\n",
      "train loss:0.04497581576550893\n",
      "train loss:0.08278793719794386\n",
      "train loss:0.09180023387771966\n",
      "train loss:0.07061237109984318\n",
      "train loss:0.03554563977343294\n",
      "=== epoch:3, train acc:0.974, test acc:0.978 ===\n",
      "train loss:0.035983318577475956\n",
      "train loss:0.07133886681091148\n",
      "train loss:0.08250422119769354\n",
      "train loss:0.044284388981048466\n",
      "train loss:0.08429109031009985\n",
      "train loss:0.02271293673017522\n",
      "train loss:0.016399801473589853\n",
      "train loss:0.13109747363559973\n",
      "train loss:0.08940560329984393\n",
      "train loss:0.04543465151348459\n",
      "train loss:0.04089509578179003\n",
      "train loss:0.043642280041035736\n",
      "train loss:0.021369503388143543\n",
      "train loss:0.047274207518769894\n",
      "train loss:0.03271089408429565\n",
      "train loss:0.03419462926337948\n",
      "train loss:0.04920122549403509\n",
      "train loss:0.10869398438277483\n",
      "train loss:0.1289672780220717\n",
      "train loss:0.05989166374000905\n",
      "train loss:0.10358137113934635\n",
      "train loss:0.06422768978612911\n",
      "train loss:0.04065104634645458\n",
      "train loss:0.03496548212748431\n",
      "train loss:0.02689760463633792\n",
      "train loss:0.0985774285083664\n",
      "train loss:0.14675678286538477\n",
      "train loss:0.041507908267976686\n",
      "train loss:0.06577097758702447\n",
      "train loss:0.16973628794392287\n",
      "train loss:0.04520030643469788\n",
      "train loss:0.11747203714316459\n",
      "train loss:0.04913164119127977\n",
      "train loss:0.05400763444473565\n",
      "train loss:0.05083988193167831\n",
      "train loss:0.04088023729692141\n",
      "train loss:0.05722698603512838\n",
      "train loss:0.06958464188025922\n",
      "train loss:0.059154915361549244\n",
      "train loss:0.13831511241296623\n",
      "train loss:0.15581988518574666\n",
      "train loss:0.03412525102396033\n",
      "train loss:0.059374585085809235\n",
      "train loss:0.10505605941331946\n",
      "train loss:0.12014782644830349\n",
      "train loss:0.06932702710240736\n",
      "train loss:0.0953907296552568\n",
      "train loss:0.1408650787808812\n",
      "train loss:0.09153107324557361\n",
      "train loss:0.04091718552738811\n",
      "train loss:0.08242714669878604\n",
      "train loss:0.07143917449260244\n",
      "train loss:0.05428043423636501\n",
      "train loss:0.06281302641457419\n",
      "train loss:0.037511624062729475\n",
      "train loss:0.040879821461269346\n",
      "train loss:0.030358632359034785\n",
      "train loss:0.047650841578724325\n",
      "train loss:0.054604557662885606\n",
      "train loss:0.04985202556890439\n",
      "train loss:0.02135705082577506\n",
      "train loss:0.03647335631171572\n",
      "train loss:0.07152430471509627\n",
      "train loss:0.06648665791789667\n",
      "train loss:0.04350955952097192\n",
      "train loss:0.02454697190212864\n",
      "train loss:0.07465409539703476\n",
      "train loss:0.12193720457578956\n",
      "train loss:0.041939936833860776\n",
      "train loss:0.0323707826858338\n",
      "train loss:0.028427057325649364\n",
      "train loss:0.06063509008395918\n",
      "train loss:0.12400479369787311\n",
      "train loss:0.027316152319547666\n",
      "train loss:0.06056348010632607\n",
      "train loss:0.04763558047415065\n",
      "train loss:0.02882421948242683\n",
      "train loss:0.03820235444043094\n",
      "train loss:0.07495234174579861\n",
      "train loss:0.11768156126774136\n",
      "train loss:0.07201723620227582\n",
      "train loss:0.0368381151727697\n",
      "train loss:0.01989797749911413\n",
      "train loss:0.11998205617395637\n",
      "train loss:0.09024419723051137\n",
      "train loss:0.043708156815932625\n",
      "train loss:0.13420868496024735\n",
      "train loss:0.10890040415021625\n",
      "train loss:0.04693120617014741\n",
      "train loss:0.0942819485130731\n",
      "train loss:0.08690495961310042\n",
      "train loss:0.08186966683000378\n",
      "train loss:0.04783176267183196\n",
      "train loss:0.06282918931199089\n",
      "train loss:0.06500680151313845\n",
      "train loss:0.04080142280074688\n",
      "train loss:0.03778572376182851\n",
      "train loss:0.1181290983561389\n",
      "train loss:0.07504769402879448\n",
      "train loss:0.05322482793029851\n",
      "train loss:0.06677156631476305\n",
      "train loss:0.031913518352004\n",
      "train loss:0.041179079149028776\n",
      "train loss:0.03754871733077454\n",
      "train loss:0.062086503729470055\n",
      "train loss:0.0790437356666738\n",
      "train loss:0.03922419535522975\n",
      "train loss:0.032038463859214814\n",
      "train loss:0.03415200474901501\n",
      "train loss:0.06073130494652737\n",
      "train loss:0.07917306940990318\n",
      "train loss:0.12516333401222632\n",
      "train loss:0.043729715696711614\n",
      "train loss:0.07861138265721816\n",
      "train loss:0.07058978263655251\n",
      "train loss:0.025462697609589403\n",
      "train loss:0.07401078431999276\n",
      "train loss:0.07483141051340177\n",
      "train loss:0.05587577552433325\n",
      "train loss:0.1172501493141966\n",
      "train loss:0.09951188151012631\n",
      "train loss:0.04167554720892939\n",
      "train loss:0.04258757554871341\n",
      "train loss:0.08376352777736903\n",
      "train loss:0.030001503382700447\n",
      "train loss:0.08580139668180443\n",
      "train loss:0.024713600702357348\n",
      "train loss:0.11730663371354258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.028414740323191853\n",
      "train loss:0.053265085123740584\n",
      "train loss:0.04812816081055708\n",
      "train loss:0.12159130626914949\n",
      "train loss:0.07180547803084145\n",
      "train loss:0.09746103648133843\n",
      "train loss:0.06618129512550833\n",
      "train loss:0.020768866259450763\n",
      "train loss:0.03746978835003287\n",
      "train loss:0.05977472754500027\n",
      "train loss:0.04124835324886274\n",
      "train loss:0.04156066283522266\n",
      "train loss:0.029006854498684596\n",
      "train loss:0.036823282666592426\n",
      "train loss:0.11750848913080542\n",
      "train loss:0.028372639982896023\n",
      "train loss:0.06820296073859942\n",
      "train loss:0.027175767535977755\n",
      "train loss:0.08708789565328416\n",
      "train loss:0.09687630183684547\n",
      "train loss:0.05650384976161124\n",
      "train loss:0.03234304508621911\n",
      "train loss:0.07679799920261388\n",
      "train loss:0.08818642847464359\n",
      "train loss:0.0232849497379143\n",
      "train loss:0.10675585418337141\n",
      "train loss:0.03074306597373068\n",
      "train loss:0.0785403726083279\n",
      "train loss:0.01912514857771923\n",
      "train loss:0.021221864760322354\n",
      "train loss:0.058626610329375176\n",
      "train loss:0.09000684910591646\n",
      "train loss:0.02229805139054513\n",
      "train loss:0.025774350462817678\n",
      "train loss:0.05527741805827848\n",
      "train loss:0.04185501245724676\n",
      "train loss:0.06437669087118661\n",
      "train loss:0.02635324506918619\n",
      "train loss:0.057495240191396985\n",
      "train loss:0.04091689977304938\n",
      "train loss:0.0394595163694815\n",
      "train loss:0.05891755425823595\n",
      "train loss:0.07798503153055614\n",
      "train loss:0.07814120613281127\n",
      "train loss:0.0810808681348008\n",
      "train loss:0.03429281774640952\n",
      "train loss:0.07054676626330092\n",
      "train loss:0.03252325847724923\n",
      "train loss:0.03230595873975884\n",
      "train loss:0.028142533607378284\n",
      "train loss:0.08903880805314458\n",
      "train loss:0.19528399744479588\n",
      "train loss:0.08750992430077019\n",
      "train loss:0.07135832630012955\n",
      "train loss:0.05274434287447205\n",
      "train loss:0.02941822700061699\n",
      "train loss:0.015114762651313634\n",
      "train loss:0.09196175650818506\n",
      "train loss:0.02209236663852991\n",
      "train loss:0.10257026950962547\n",
      "train loss:0.05340329226102854\n",
      "train loss:0.013344448694952266\n",
      "train loss:0.05888420714940085\n",
      "train loss:0.15220182738082721\n",
      "train loss:0.0199854120370388\n",
      "train loss:0.026793924222054778\n",
      "train loss:0.05874684534212597\n",
      "train loss:0.020725166719722035\n",
      "train loss:0.01569829603517521\n",
      "train loss:0.05211855131325482\n",
      "train loss:0.04317081004212503\n",
      "train loss:0.05035921537542368\n",
      "train loss:0.0485070224205433\n",
      "train loss:0.04738158124366649\n",
      "train loss:0.10094844187683409\n",
      "train loss:0.06316165423936097\n",
      "train loss:0.0782215791904525\n",
      "train loss:0.026454582629081517\n",
      "train loss:0.05427188747049046\n",
      "train loss:0.017126614050770782\n",
      "train loss:0.05101185398585751\n",
      "train loss:0.03128836369051623\n",
      "train loss:0.05638840113947835\n",
      "train loss:0.05012713405493077\n",
      "train loss:0.06320421823138528\n",
      "train loss:0.045618898177924035\n",
      "train loss:0.05448912335718756\n",
      "train loss:0.014718259954163003\n",
      "train loss:0.05467945035387514\n",
      "train loss:0.045651651191052973\n",
      "train loss:0.01373459801555139\n",
      "train loss:0.021430978766631862\n",
      "train loss:0.0521074505257134\n",
      "train loss:0.02227157801991706\n",
      "train loss:0.047786061621158414\n",
      "train loss:0.02644680927327186\n",
      "train loss:0.04145467183578711\n",
      "train loss:0.10704219115274466\n",
      "train loss:0.05763386477996391\n",
      "train loss:0.04414937384797027\n",
      "train loss:0.03419937138924545\n",
      "train loss:0.04035858882984256\n",
      "train loss:0.022499928966338012\n",
      "train loss:0.07803159808692747\n",
      "train loss:0.05741702375749394\n",
      "train loss:0.08730983095912424\n",
      "train loss:0.09005764529683459\n",
      "train loss:0.043546998712208566\n",
      "train loss:0.03050872243714921\n",
      "train loss:0.06774800374382414\n",
      "train loss:0.1170468427341371\n",
      "train loss:0.07323183994887918\n",
      "train loss:0.03964496162897953\n",
      "train loss:0.14264597181388805\n",
      "train loss:0.04580014029538835\n",
      "train loss:0.05770361091549353\n",
      "train loss:0.11505421998645214\n",
      "train loss:0.09832970672747915\n",
      "train loss:0.02071064620495181\n",
      "train loss:0.03044728700532654\n",
      "train loss:0.05905614779942084\n",
      "train loss:0.030121657552976407\n",
      "train loss:0.05607354650771604\n",
      "train loss:0.03475684418787943\n",
      "train loss:0.04975978437409877\n",
      "train loss:0.028603768824513553\n",
      "train loss:0.07523477904541753\n",
      "train loss:0.02846342690323822\n",
      "train loss:0.0542229172648881\n",
      "train loss:0.028948340827022082\n",
      "train loss:0.04388152588876771\n",
      "train loss:0.08677789135995324\n",
      "train loss:0.04613577882788107\n",
      "train loss:0.07399619070301763\n",
      "train loss:0.037968433660346836\n",
      "train loss:0.03846115031648669\n",
      "train loss:0.08018052950916348\n",
      "train loss:0.10967093701871736\n",
      "train loss:0.025349683557086052\n",
      "train loss:0.07925372258515095\n",
      "train loss:0.024181456872124397\n",
      "train loss:0.03199265102296715\n",
      "train loss:0.04219236192427931\n",
      "train loss:0.04291518308853995\n",
      "train loss:0.021542107911456814\n",
      "train loss:0.042321460539045334\n",
      "train loss:0.035818120012359234\n",
      "train loss:0.023682134507288607\n",
      "train loss:0.06821020578014159\n",
      "train loss:0.0427560102224963\n",
      "train loss:0.017493413171931597\n",
      "train loss:0.07448557255965693\n",
      "train loss:0.05776991836170081\n",
      "train loss:0.059747165275492786\n",
      "train loss:0.04559535346253692\n",
      "train loss:0.03551264600876035\n",
      "train loss:0.04393001836343655\n",
      "train loss:0.06171329070037016\n",
      "train loss:0.03094609874598304\n",
      "train loss:0.011527000105514334\n",
      "train loss:0.0829130844396775\n",
      "train loss:0.022545815136799267\n",
      "train loss:0.02339219841169896\n",
      "train loss:0.10522886114658486\n",
      "train loss:0.040116854599731175\n",
      "train loss:0.0637063075549234\n",
      "train loss:0.02281441912633113\n",
      "train loss:0.05600227252676229\n",
      "train loss:0.04796634851485532\n",
      "train loss:0.029258150780818885\n",
      "train loss:0.04250493059192645\n",
      "train loss:0.008779396093627753\n",
      "train loss:0.014602275167240672\n",
      "train loss:0.021176884399610612\n",
      "train loss:0.04465311140661814\n",
      "train loss:0.02652380264233209\n",
      "train loss:0.05056466149767368\n",
      "train loss:0.11855712854536243\n",
      "train loss:0.03179295698712099\n",
      "train loss:0.053809220203389206\n",
      "train loss:0.07649818741152861\n",
      "train loss:0.03965002937665858\n",
      "train loss:0.027674936128617173\n",
      "train loss:0.06540416062479733\n",
      "train loss:0.023454219678714357\n",
      "train loss:0.041375862183112656\n",
      "train loss:0.014722689719045914\n",
      "train loss:0.0599177324872534\n",
      "train loss:0.03908080948542922\n",
      "train loss:0.09437417275328018\n",
      "train loss:0.02506025051271198\n",
      "train loss:0.04506216912320876\n",
      "train loss:0.03434183833108377\n",
      "train loss:0.02732716855492809\n",
      "train loss:0.033795453937699005\n",
      "train loss:0.03660050503786263\n",
      "train loss:0.019997791267633683\n",
      "train loss:0.032418106957276406\n",
      "train loss:0.034013674122013254\n",
      "train loss:0.028878141535603138\n",
      "train loss:0.05380673431177179\n",
      "train loss:0.06296065771286904\n",
      "train loss:0.08558822640613861\n",
      "train loss:0.12086793152921238\n",
      "train loss:0.010409960540909037\n",
      "train loss:0.027153821474594556\n",
      "train loss:0.034468366737032664\n",
      "train loss:0.05279433023993557\n",
      "train loss:0.06218770054550662\n",
      "train loss:0.025904427297362153\n",
      "train loss:0.03144801115829944\n",
      "train loss:0.0394911823373913\n",
      "train loss:0.015466750336067703\n",
      "train loss:0.010791881383946194\n",
      "train loss:0.041762075409503205\n",
      "train loss:0.05621638830210049\n",
      "train loss:0.013793438660162805\n",
      "train loss:0.025899286053402335\n",
      "train loss:0.030311229391235938\n",
      "train loss:0.03267976774121827\n",
      "train loss:0.05808969508890399\n",
      "train loss:0.1234976805989121\n",
      "train loss:0.02611932270016142\n",
      "train loss:0.030976524259696814\n",
      "train loss:0.09398279502463186\n",
      "train loss:0.06547372893688584\n",
      "train loss:0.028736788731406667\n",
      "train loss:0.1356448425708477\n",
      "train loss:0.023484493850314557\n",
      "train loss:0.1599691001070938\n",
      "train loss:0.02290730326447734\n",
      "train loss:0.054324939025174615\n",
      "train loss:0.04456066561675723\n",
      "train loss:0.1873580840277202\n",
      "train loss:0.03142662540554585\n",
      "train loss:0.04201229039242019\n",
      "train loss:0.03294289568271513\n",
      "train loss:0.10590773925708748\n",
      "train loss:0.02449305897249395\n",
      "train loss:0.03206467767476827\n",
      "train loss:0.07048918533890138\n",
      "train loss:0.04043267502044319\n",
      "train loss:0.0889356094639705\n",
      "train loss:0.04766152623261496\n",
      "train loss:0.05565436113339164\n",
      "train loss:0.07002305577991519\n",
      "train loss:0.028534148615780863\n",
      "train loss:0.049932458129324064\n",
      "train loss:0.05823412404786598\n",
      "train loss:0.0477709338998885\n",
      "train loss:0.06617338286490408\n",
      "train loss:0.05416353374717957\n",
      "train loss:0.048451272938093544\n",
      "train loss:0.037261465484095466\n",
      "train loss:0.0313838335430111\n",
      "train loss:0.027929713392397863\n",
      "train loss:0.043683347991644667\n",
      "train loss:0.09060516916587032\n",
      "train loss:0.04299734681853802\n",
      "train loss:0.08739449488153961\n",
      "train loss:0.07616404904159241\n",
      "train loss:0.04066840876903931\n",
      "train loss:0.03207649229702191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.10145035565332595\n",
      "train loss:0.01575533478595518\n",
      "train loss:0.06005032848916726\n",
      "train loss:0.02804233065454522\n",
      "train loss:0.04902114652346817\n",
      "train loss:0.045258164176010224\n",
      "train loss:0.05035787332768621\n",
      "train loss:0.020314613342292988\n",
      "train loss:0.08940661515125385\n",
      "train loss:0.0564384368668525\n",
      "train loss:0.09023490998676205\n",
      "train loss:0.05268623654684824\n",
      "train loss:0.20641978080085366\n",
      "train loss:0.08329345210102294\n",
      "train loss:0.04054420570407797\n",
      "train loss:0.019880176682441672\n",
      "train loss:0.03535099759160695\n",
      "train loss:0.1272541028944693\n",
      "train loss:0.038992915655067524\n",
      "train loss:0.02759787062462705\n",
      "train loss:0.06925206955483436\n",
      "train loss:0.07223083829521307\n",
      "train loss:0.09470915093299298\n",
      "train loss:0.08996860527672972\n",
      "train loss:0.016350785605376776\n",
      "train loss:0.019038182244022216\n",
      "train loss:0.060361491498791636\n",
      "train loss:0.07639872409227579\n",
      "train loss:0.07139855557878695\n",
      "train loss:0.07059507184898607\n",
      "train loss:0.034711004739311234\n",
      "train loss:0.0282416417523845\n",
      "train loss:0.028257233937332645\n",
      "train loss:0.025464491564005147\n",
      "train loss:0.0323327473219566\n",
      "train loss:0.045766249177514554\n",
      "train loss:0.039444003303466396\n",
      "train loss:0.07195980635743701\n",
      "train loss:0.12963850026354537\n",
      "train loss:0.038992941694395745\n",
      "train loss:0.03828525791374232\n",
      "train loss:0.1129737585734623\n",
      "train loss:0.07538087242651283\n",
      "train loss:0.03859724516254882\n",
      "train loss:0.028828140671467047\n",
      "train loss:0.04541880277285681\n",
      "train loss:0.012436357922705232\n",
      "train loss:0.07566902199352998\n",
      "train loss:0.027012716754986864\n",
      "train loss:0.02192286051579901\n",
      "train loss:0.046364276025783156\n",
      "train loss:0.11725602377677789\n",
      "train loss:0.06810669790428735\n",
      "train loss:0.05562939967815453\n",
      "train loss:0.05271606570736302\n",
      "train loss:0.02819633459474607\n",
      "train loss:0.013863258973113657\n",
      "train loss:0.11609758115072306\n",
      "train loss:0.010583814495076964\n",
      "train loss:0.10052054848185636\n",
      "train loss:0.08213167824555652\n",
      "train loss:0.012735925604533764\n",
      "train loss:0.08368342291653902\n",
      "train loss:0.026767973579947833\n",
      "train loss:0.03703641383773352\n",
      "train loss:0.04856804156124522\n",
      "train loss:0.020805807902798887\n",
      "train loss:0.14353771708952337\n",
      "train loss:0.08474485018738308\n",
      "train loss:0.13117028060224686\n",
      "train loss:0.049010816682649255\n",
      "train loss:0.01797004434980619\n",
      "train loss:0.036751223663072666\n",
      "train loss:0.03639628531026184\n",
      "train loss:0.033169944529320976\n",
      "train loss:0.0707164308629631\n",
      "train loss:0.03424667219055724\n",
      "train loss:0.018009940085420912\n",
      "train loss:0.09960006548806793\n",
      "train loss:0.09629826395353007\n",
      "train loss:0.06860294891129853\n",
      "train loss:0.04362410896376093\n",
      "train loss:0.0961394531479474\n",
      "train loss:0.017541808309608116\n",
      "train loss:0.025697387183436952\n",
      "train loss:0.04844196184824181\n",
      "train loss:0.026937418400561856\n",
      "train loss:0.09010082094641839\n",
      "train loss:0.018849672135637728\n",
      "train loss:0.029991560944377223\n",
      "train loss:0.07562181437261832\n",
      "train loss:0.1603557809219514\n",
      "train loss:0.08201898047988262\n",
      "train loss:0.06019013471760849\n",
      "train loss:0.07313829189019744\n",
      "train loss:0.047772115406322035\n",
      "train loss:0.05051797080174936\n",
      "train loss:0.04801681217112411\n",
      "train loss:0.05636881490723098\n",
      "train loss:0.06942139212399857\n",
      "train loss:0.08044669108286914\n",
      "train loss:0.13654497339972754\n",
      "train loss:0.012625005203439184\n",
      "train loss:0.026824124943121305\n",
      "train loss:0.08488909457817602\n",
      "train loss:0.030740993516041\n",
      "train loss:0.09437019156557022\n",
      "train loss:0.05600015004646571\n",
      "train loss:0.05941795281766069\n",
      "train loss:0.07215921114727993\n",
      "train loss:0.056479041682829495\n",
      "train loss:0.014122320309327363\n",
      "train loss:0.06841346604496397\n",
      "train loss:0.18536306935339986\n",
      "train loss:0.0491135138949321\n",
      "train loss:0.10009799359876331\n",
      "train loss:0.0363438303096913\n",
      "train loss:0.052096885907856064\n",
      "train loss:0.013018077597314062\n",
      "train loss:0.08813066945400826\n",
      "train loss:0.06481419800031699\n",
      "train loss:0.07115448438254561\n",
      "train loss:0.01563566257744277\n",
      "train loss:0.09247243957589005\n",
      "train loss:0.06372705709614851\n",
      "train loss:0.10216108957281904\n",
      "train loss:0.06807010097756114\n",
      "train loss:0.022831827618606672\n",
      "train loss:0.09363940547178971\n",
      "train loss:0.06763480425441737\n",
      "train loss:0.060121507684168074\n",
      "train loss:0.029474973742295102\n",
      "train loss:0.0659951540939349\n",
      "train loss:0.050960437619369296\n",
      "train loss:0.01597415127644939\n",
      "train loss:0.06392232307545818\n",
      "train loss:0.04609144384641616\n",
      "train loss:0.06648799490701436\n",
      "train loss:0.014792735420030291\n",
      "train loss:0.030852256064601114\n",
      "train loss:0.06204737801115679\n",
      "train loss:0.028001578355104945\n",
      "train loss:0.05438801922354381\n",
      "train loss:0.053357011908955004\n",
      "train loss:0.02243023727590832\n",
      "train loss:0.017217886155616396\n",
      "train loss:0.039302435980409854\n",
      "train loss:0.028511041906664335\n",
      "train loss:0.01577202175642729\n",
      "train loss:0.09323530994764934\n",
      "train loss:0.04584757917073058\n",
      "train loss:0.023379267989046104\n",
      "train loss:0.05713174875355075\n",
      "train loss:0.04396488015212083\n",
      "train loss:0.03588781774087221\n",
      "train loss:0.044312561429446146\n",
      "train loss:0.01996201226308056\n",
      "train loss:0.018110066175402163\n",
      "train loss:0.08763124708681186\n",
      "train loss:0.07049574054310356\n",
      "train loss:0.008561037020325995\n",
      "train loss:0.07586156777693832\n",
      "train loss:0.052879242757223714\n",
      "train loss:0.047288022210866136\n",
      "train loss:0.08408589063850838\n",
      "train loss:0.06827516562972374\n",
      "train loss:0.03580333840716517\n",
      "train loss:0.02957273528909521\n",
      "train loss:0.008727037716087703\n",
      "train loss:0.027365798017425943\n",
      "train loss:0.015176055771853674\n",
      "train loss:0.026971211200327073\n",
      "train loss:0.038892273889253155\n",
      "train loss:0.023134799667987243\n",
      "train loss:0.04223104937325155\n",
      "train loss:0.014281081316052078\n",
      "train loss:0.04235727909808876\n",
      "train loss:0.09694390702789589\n",
      "train loss:0.015155776499832069\n",
      "train loss:0.028394860879254274\n",
      "train loss:0.014047695333223085\n",
      "train loss:0.019206119496711457\n",
      "train loss:0.06386191065319839\n",
      "train loss:0.06761729838120142\n",
      "train loss:0.06254484282897331\n",
      "train loss:0.019074305416403824\n",
      "train loss:0.016988862854360517\n",
      "train loss:0.025450290195271234\n",
      "train loss:0.067164228196299\n",
      "train loss:0.057530715508220025\n",
      "train loss:0.06174123117890648\n",
      "train loss:0.0216344156843608\n",
      "train loss:0.039282441392522544\n",
      "train loss:0.18665443387823633\n",
      "train loss:0.04250651430344012\n",
      "train loss:0.05452579094894003\n",
      "train loss:0.013645885014368505\n",
      "train loss:0.09718345140708219\n",
      "train loss:0.029260797442423474\n",
      "train loss:0.042272923963301796\n",
      "train loss:0.010064855962475236\n",
      "train loss:0.036817502884727266\n",
      "train loss:0.07194764591932196\n",
      "train loss:0.034618409066589015\n",
      "train loss:0.055352814648590626\n",
      "train loss:0.02089855011819268\n",
      "train loss:0.02963913122706886\n",
      "train loss:0.03907603720639405\n",
      "train loss:0.04945389787289406\n",
      "=== epoch:4, train acc:0.984, test acc:0.979 ===\n",
      "train loss:0.026804385901547042\n",
      "train loss:0.017180531672143732\n",
      "train loss:0.019562501317819458\n",
      "train loss:0.045175805316143444\n",
      "train loss:0.09098615151432138\n",
      "train loss:0.017876955063400236\n",
      "train loss:0.06349532559013932\n",
      "train loss:0.023761516829654307\n",
      "train loss:0.016746412193671942\n",
      "train loss:0.05664718793420364\n",
      "train loss:0.02671358627144547\n",
      "train loss:0.06488515060373055\n",
      "train loss:0.02466089537421069\n",
      "train loss:0.043926560873812505\n",
      "train loss:0.029349898268920302\n",
      "train loss:0.09267559005488733\n",
      "train loss:0.018623493725247374\n",
      "train loss:0.011814225205085526\n",
      "train loss:0.01905606790630912\n",
      "train loss:0.06904939951033989\n",
      "train loss:0.04427503094005544\n",
      "train loss:0.0334972406930996\n",
      "train loss:0.027809344428622765\n",
      "train loss:0.08051030503833961\n",
      "train loss:0.06394173554562316\n",
      "train loss:0.01909366431031065\n",
      "train loss:0.04640465756826315\n",
      "train loss:0.0422505022703879\n",
      "train loss:0.023054428900552378\n",
      "train loss:0.034128074144058405\n",
      "train loss:0.04581934464359046\n",
      "train loss:0.029660355135204677\n",
      "train loss:0.03814198017839131\n",
      "train loss:0.14025384446550626\n",
      "train loss:0.02086720649078674\n",
      "train loss:0.08764127751586924\n",
      "train loss:0.09941824850786304\n",
      "train loss:0.023199789975593625\n",
      "train loss:0.021644053526394612\n",
      "train loss:0.06569208283734629\n",
      "train loss:0.06663575151184359\n",
      "train loss:0.020745896616201444\n",
      "train loss:0.08914613633414087\n",
      "train loss:0.021767024449941944\n",
      "train loss:0.02374643082056429\n",
      "train loss:0.015892584660936078\n",
      "train loss:0.06667724029198743\n",
      "train loss:0.014633401726847859\n",
      "train loss:0.0172865116197908\n",
      "train loss:0.020098626466793234\n",
      "train loss:0.05001485626484734\n",
      "train loss:0.030889728969699035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.11213313369156594\n",
      "train loss:0.008690477988186871\n",
      "train loss:0.03409659816686634\n",
      "train loss:0.08895027046128497\n",
      "train loss:0.028155036699995906\n",
      "train loss:0.03993601567299466\n",
      "train loss:0.02718335579816586\n",
      "train loss:0.041347035282755254\n",
      "train loss:0.04817721703629089\n",
      "train loss:0.06861145538353225\n",
      "train loss:0.1095768849857668\n",
      "train loss:0.04520023312684874\n",
      "train loss:0.027107916730028898\n",
      "train loss:0.07962271316031667\n",
      "train loss:0.07828296769471088\n",
      "train loss:0.022876320382183297\n",
      "train loss:0.028952772841415793\n",
      "train loss:0.01375263759646642\n",
      "train loss:0.010057610820315992\n",
      "train loss:0.0633743024984108\n",
      "train loss:0.012374953851359078\n",
      "train loss:0.023834423578866178\n",
      "train loss:0.03394502649556738\n",
      "train loss:0.051495283377191656\n",
      "train loss:0.05188487417649866\n",
      "train loss:0.013359673861191513\n",
      "train loss:0.055577855718491484\n",
      "train loss:0.11191364076273005\n",
      "train loss:0.06434212259048191\n",
      "train loss:0.02648382901271318\n",
      "train loss:0.0027137856795285582\n",
      "train loss:0.04085062852164548\n",
      "train loss:0.11094351552186359\n",
      "train loss:0.020860130435068992\n",
      "train loss:0.005645982003845311\n",
      "train loss:0.052619995333572825\n",
      "train loss:0.018504763900813737\n",
      "train loss:0.05319585641377248\n",
      "train loss:0.02170297562248398\n",
      "train loss:0.033177464615261436\n",
      "train loss:0.049269812253613085\n",
      "train loss:0.046944540803344405\n",
      "train loss:0.0808326833902911\n",
      "train loss:0.01653345625541881\n",
      "train loss:0.03999893073922592\n",
      "train loss:0.09578390934762547\n",
      "train loss:0.05140720678539135\n",
      "train loss:0.020176668316584646\n",
      "train loss:0.05424522812472227\n",
      "train loss:0.08116703735856802\n",
      "train loss:0.035399388283656893\n",
      "train loss:0.030440175646879765\n",
      "train loss:0.021807176205722825\n",
      "train loss:0.07656601562640243\n",
      "train loss:0.029778096984789938\n",
      "train loss:0.03261392503389548\n",
      "train loss:0.04030612554802691\n",
      "train loss:0.09578534711704112\n",
      "train loss:0.03115951809268277\n",
      "train loss:0.021304143206836965\n",
      "train loss:0.039137695568430914\n",
      "train loss:0.03007357026302523\n",
      "train loss:0.04550671226631896\n",
      "train loss:0.03451041007055037\n",
      "train loss:0.018948265811683768\n",
      "train loss:0.02064296200696271\n",
      "train loss:0.02417903866317173\n",
      "train loss:0.010225825874118875\n",
      "train loss:0.025006372442065095\n",
      "train loss:0.005124316467482793\n",
      "train loss:0.055301853316466996\n",
      "train loss:0.07163118554140824\n",
      "train loss:0.09316479455089523\n",
      "train loss:0.028134059072585482\n",
      "train loss:0.022210538475187926\n",
      "train loss:0.07146362668696685\n",
      "train loss:0.023138093468953416\n",
      "train loss:0.016420776717828878\n",
      "train loss:0.055744775784149166\n",
      "train loss:0.013037153046653564\n",
      "train loss:0.03194358382415448\n",
      "train loss:0.022692873476830275\n",
      "train loss:0.035058146391106514\n",
      "train loss:0.03247315312208352\n",
      "train loss:0.04476066269758734\n",
      "train loss:0.011196614890137666\n",
      "train loss:0.02981841541667139\n",
      "train loss:0.02984831296100186\n",
      "train loss:0.03915560603740771\n",
      "train loss:0.0276578935582566\n",
      "train loss:0.021475699581714983\n",
      "train loss:0.07167227548628724\n",
      "train loss:0.016681999233720622\n",
      "train loss:0.03864638700714996\n",
      "train loss:0.08308797488631592\n",
      "train loss:0.06427424632460005\n",
      "train loss:0.03449381612272977\n",
      "train loss:0.03563318803063867\n",
      "train loss:0.009630097163035648\n",
      "train loss:0.016758375888586915\n",
      "train loss:0.04547596936591351\n",
      "train loss:0.029984162203248555\n",
      "train loss:0.011473648156747937\n",
      "train loss:0.05412986663391115\n",
      "train loss:0.021313380782123713\n",
      "train loss:0.016399757412491615\n",
      "train loss:0.02076744195269602\n",
      "train loss:0.027842955055684224\n",
      "train loss:0.016181336107034663\n",
      "train loss:0.016002347503185157\n",
      "train loss:0.04895447787306337\n",
      "train loss:0.03471636021888671\n",
      "train loss:0.036125719405990145\n",
      "train loss:0.03626563825373975\n",
      "train loss:0.07865017468969197\n",
      "train loss:0.04603711311945203\n",
      "train loss:0.12026323969349512\n",
      "train loss:0.03276664840275527\n",
      "train loss:0.02779940447992024\n",
      "train loss:0.02401221266646276\n",
      "train loss:0.037229985710518776\n",
      "train loss:0.18058137563562465\n",
      "train loss:0.026923536608345153\n",
      "train loss:0.050084294021460696\n",
      "train loss:0.09696986361627837\n",
      "train loss:0.09340459360014007\n",
      "train loss:0.05655551182819251\n",
      "train loss:0.018753181338238844\n",
      "train loss:0.0057765514426412114\n",
      "train loss:0.04306585723621323\n",
      "train loss:0.0408160242093451\n",
      "train loss:0.027910918115073676\n",
      "train loss:0.05830519531863585\n",
      "train loss:0.020245603653005987\n",
      "train loss:0.014025704656038696\n",
      "train loss:0.03441204201560173\n",
      "train loss:0.05238001168340051\n",
      "train loss:0.03641141884633791\n",
      "train loss:0.09837742362313522\n",
      "train loss:0.08096028938100618\n",
      "train loss:0.036250258128834395\n",
      "train loss:0.04001169990399793\n",
      "train loss:0.09398671428312716\n",
      "train loss:0.12766684640434892\n",
      "train loss:0.04716327632927922\n",
      "train loss:0.037863421135241805\n",
      "train loss:0.0335704376271561\n",
      "train loss:0.015133950662925364\n",
      "train loss:0.04840861766770533\n",
      "train loss:0.10190406377398746\n",
      "train loss:0.06803582841882388\n",
      "train loss:0.0784764458941706\n",
      "train loss:0.030097237140792172\n",
      "train loss:0.05151608223603978\n",
      "train loss:0.044059772141682066\n",
      "train loss:0.027064757816599765\n",
      "train loss:0.006763156402855037\n",
      "train loss:0.02021727445027358\n",
      "train loss:0.01397594613627039\n",
      "train loss:0.0382914937419931\n",
      "train loss:0.02066450033845046\n",
      "train loss:0.04921332048700765\n",
      "train loss:0.07243297334343206\n",
      "train loss:0.0465635085201874\n",
      "train loss:0.038004627819123275\n",
      "train loss:0.037006932723447634\n",
      "train loss:0.02496110552352123\n",
      "train loss:0.05746240508908729\n",
      "train loss:0.04741999870480376\n",
      "train loss:0.022107955647797762\n",
      "train loss:0.12738028277927474\n",
      "train loss:0.01872779749304464\n",
      "train loss:0.031240134926898363\n",
      "train loss:0.015344255121922983\n",
      "train loss:0.022103869486192404\n",
      "train loss:0.04710871109894378\n",
      "train loss:0.018624486129016855\n",
      "train loss:0.029308607547810252\n",
      "train loss:0.02930425274451729\n",
      "train loss:0.026818469151175372\n",
      "train loss:0.021639289186751585\n",
      "train loss:0.02887436662697409\n",
      "train loss:0.03407350654930463\n",
      "train loss:0.040915171263745546\n",
      "train loss:0.008509362582340346\n",
      "train loss:0.030846103526103362\n",
      "train loss:0.02015853166078304\n",
      "train loss:0.026864344597276518\n",
      "train loss:0.05481189875319041\n",
      "train loss:0.005310100192576003\n",
      "train loss:0.01078963169641358\n",
      "train loss:0.005674210661937308\n",
      "train loss:0.04695749396930901\n",
      "train loss:0.016168785198382944\n",
      "train loss:0.013365491095088042\n",
      "train loss:0.015827447408073084\n",
      "train loss:0.030173535053238266\n",
      "train loss:0.07087321742455419\n",
      "train loss:0.07825494074439744\n",
      "train loss:0.0665404827388378\n",
      "train loss:0.037624647625080686\n",
      "train loss:0.05867195079432989\n",
      "train loss:0.01730708979378888\n",
      "train loss:0.016371453953297255\n",
      "train loss:0.014049433831546743\n",
      "train loss:0.04704092299234461\n",
      "train loss:0.03950454626569177\n",
      "train loss:0.013417910186858301\n",
      "train loss:0.06493498272262292\n",
      "train loss:0.04052009915502665\n",
      "train loss:0.01477438926214422\n",
      "train loss:0.030479982665594332\n",
      "train loss:0.03970964689398472\n",
      "train loss:0.03778118824023501\n",
      "train loss:0.00625184884006995\n",
      "train loss:0.022753812220329125\n",
      "train loss:0.03753810242648694\n",
      "train loss:0.009441794490423394\n",
      "train loss:0.014883594445102804\n",
      "train loss:0.056134608244043045\n",
      "train loss:0.014673561869879424\n",
      "train loss:0.046163496988064254\n",
      "train loss:0.010577643362181652\n",
      "train loss:0.0074702378010218\n",
      "train loss:0.026015146052199126\n",
      "train loss:0.0280595358722339\n",
      "train loss:0.005872758730173656\n",
      "train loss:0.0043473804414156155\n",
      "train loss:0.05119888052354218\n",
      "train loss:0.043209117854390765\n",
      "train loss:0.06136838197959252\n",
      "train loss:0.017306560474299678\n",
      "train loss:0.008226686811547436\n",
      "train loss:0.014138218005451645\n",
      "train loss:0.036280309712727894\n",
      "train loss:0.012077672901919826\n",
      "train loss:0.0908559523310878\n",
      "train loss:0.05804666291064735\n",
      "train loss:0.06156192759051894\n",
      "train loss:0.012601558088734796\n",
      "train loss:0.07373461584872336\n",
      "train loss:0.0569918788420917\n",
      "train loss:0.012361448937327189\n",
      "train loss:0.007153963689821277\n",
      "train loss:0.0544291828281359\n",
      "train loss:0.0753073065969693\n",
      "train loss:0.04112821016755702\n",
      "train loss:0.027796346637302415\n",
      "train loss:0.021069108879943666\n",
      "train loss:0.00722525959200033\n",
      "train loss:0.05994721338079863\n",
      "train loss:0.1588067195815807\n",
      "train loss:0.04019515384020126\n",
      "train loss:0.03668846470312625\n",
      "train loss:0.013899038140250784\n",
      "train loss:0.00903109578891652\n",
      "train loss:0.021281542145914236\n",
      "train loss:0.025970213031842264\n",
      "train loss:0.03314765184830994\n",
      "train loss:0.07468121584945654\n",
      "train loss:0.037836303773183484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.049817362373258386\n",
      "train loss:0.08519354216200721\n",
      "train loss:0.05744054413113652\n",
      "train loss:0.031320082393893396\n",
      "train loss:0.009027844116857824\n",
      "train loss:0.01638811360713607\n",
      "train loss:0.016613653485917836\n",
      "train loss:0.035155962449756634\n",
      "train loss:0.02846354928183463\n",
      "train loss:0.05543384008152314\n",
      "train loss:0.028171866037491694\n",
      "train loss:0.06765945504460959\n",
      "train loss:0.019798252317475184\n",
      "train loss:0.012647829060987744\n",
      "train loss:0.02357460518232297\n",
      "train loss:0.006228451640092008\n",
      "train loss:0.029191771878537946\n",
      "train loss:0.019563377623499842\n",
      "train loss:0.12884336819441713\n",
      "train loss:0.00931424375192293\n",
      "train loss:0.009937179105056173\n",
      "train loss:0.111376645779945\n",
      "train loss:0.017375817581264455\n",
      "train loss:0.015406861442897943\n",
      "train loss:0.012727439910931917\n",
      "train loss:0.030959465059481238\n",
      "train loss:0.018550135038273092\n",
      "train loss:0.023261449620230676\n",
      "train loss:0.03161202343678906\n",
      "train loss:0.051991294496945874\n",
      "train loss:0.07424091270910868\n",
      "train loss:0.02567236589004234\n",
      "train loss:0.035572077216646715\n",
      "train loss:0.028449925848712462\n",
      "train loss:0.033178011536688624\n",
      "train loss:0.07591899660969112\n",
      "train loss:0.019746759457969137\n",
      "train loss:0.05051489684114723\n",
      "train loss:0.04852518048220648\n",
      "train loss:0.03882341398001322\n",
      "train loss:0.07885945064183864\n",
      "train loss:0.09778556679390134\n",
      "train loss:0.045557448653828686\n",
      "train loss:0.07308417826921483\n",
      "train loss:0.010399780230255208\n",
      "train loss:0.049726539286011506\n",
      "train loss:0.09235739690174789\n",
      "train loss:0.04151935952806801\n",
      "train loss:0.04600758760347503\n",
      "train loss:0.020644973271226417\n",
      "train loss:0.011512749622897922\n",
      "train loss:0.03446099355855906\n",
      "train loss:0.020678034722801084\n",
      "train loss:0.016971505885877525\n",
      "train loss:0.041488239680381546\n",
      "train loss:0.03405361245701473\n",
      "train loss:0.047065875086275744\n",
      "train loss:0.04132941336793928\n",
      "train loss:0.05324337672337242\n",
      "train loss:0.02187995023037838\n",
      "train loss:0.02287011277257089\n",
      "train loss:0.04656775224649909\n",
      "train loss:0.02659989659974173\n",
      "train loss:0.032281992176933325\n",
      "train loss:0.033397377622842624\n",
      "train loss:0.01980042933423124\n",
      "train loss:0.04355022770030558\n",
      "train loss:0.021465589204685716\n",
      "train loss:0.05140025439617845\n",
      "train loss:0.02467959109545039\n",
      "train loss:0.05182280790562218\n",
      "train loss:0.04431793362007414\n",
      "train loss:0.03927232524735218\n",
      "train loss:0.009910867482639809\n",
      "train loss:0.0528781917771779\n",
      "train loss:0.02164869460231333\n",
      "train loss:0.031102713456741468\n",
      "train loss:0.0074171541209530735\n",
      "train loss:0.014544670098923853\n",
      "train loss:0.06269782535793925\n",
      "train loss:0.024522564701463013\n",
      "train loss:0.023915141899700666\n",
      "train loss:0.015729446459544487\n",
      "train loss:0.010422650414978878\n",
      "train loss:0.07742056200327614\n",
      "train loss:0.029263881364721547\n",
      "train loss:0.036455954996680515\n",
      "train loss:0.033397738278352594\n",
      "train loss:0.03489893590114482\n",
      "train loss:0.00700229579287812\n",
      "train loss:0.06025197432541361\n",
      "train loss:0.12258807957596451\n",
      "train loss:0.04581978660241455\n",
      "train loss:0.04304350725291327\n",
      "train loss:0.021729001403097113\n",
      "train loss:0.05938530773351375\n",
      "train loss:0.035738269276455896\n",
      "train loss:0.05209161183899327\n",
      "train loss:0.03774252205582543\n",
      "train loss:0.052015144318300816\n",
      "train loss:0.03979188848905548\n",
      "train loss:0.054235735381101706\n",
      "train loss:0.07735490967429212\n",
      "train loss:0.025596463646665173\n",
      "train loss:0.00474452526136968\n",
      "train loss:0.020826108767172943\n",
      "train loss:0.015820608251468766\n",
      "train loss:0.024937968730394906\n",
      "train loss:0.0764961350483524\n",
      "train loss:0.015514431009150995\n",
      "train loss:0.011614796250734251\n",
      "train loss:0.03716375039355234\n",
      "train loss:0.0308446794862134\n",
      "train loss:0.010039278890335951\n",
      "train loss:0.035960016533327886\n",
      "train loss:0.026473583361747606\n",
      "train loss:0.033315133071695244\n",
      "train loss:0.018111992304506344\n",
      "train loss:0.045786002908915394\n",
      "train loss:0.029202921129324894\n",
      "train loss:0.0988728634395905\n",
      "train loss:0.018068131348997422\n",
      "train loss:0.03570788483409769\n",
      "train loss:0.007579327048444664\n",
      "train loss:0.04270968130098616\n",
      "train loss:0.05737416811001286\n",
      "train loss:0.09012416426180966\n",
      "train loss:0.005134350008247472\n",
      "train loss:0.024017647630069274\n",
      "train loss:0.05060406901678028\n",
      "train loss:0.04986896664758114\n",
      "train loss:0.043582248009181104\n",
      "train loss:0.015452090404453582\n",
      "train loss:0.04288967471904723\n",
      "train loss:0.03860471406788591\n",
      "train loss:0.03849367657324399\n",
      "train loss:0.024000802592426047\n",
      "train loss:0.02080263981472955\n",
      "train loss:0.060589682645086136\n",
      "train loss:0.03768842632940737\n",
      "train loss:0.05314016350290509\n",
      "train loss:0.018435358139258243\n",
      "train loss:0.04185419270167239\n",
      "train loss:0.12885184085122234\n",
      "train loss:0.04628306486478218\n",
      "train loss:0.021809687054904235\n",
      "train loss:0.02048771727079037\n",
      "train loss:0.010017695380230675\n",
      "train loss:0.015129240644669573\n",
      "train loss:0.04166660392945328\n",
      "train loss:0.011837942005446087\n",
      "train loss:0.010279250156692477\n",
      "train loss:0.025704404771169035\n",
      "train loss:0.018514215896056167\n",
      "train loss:0.0707096749972024\n",
      "train loss:0.031319793163417\n",
      "train loss:0.01511115817505847\n",
      "train loss:0.02043709976198673\n",
      "train loss:0.025732777249212423\n",
      "train loss:0.03184998161260623\n",
      "train loss:0.027207833009062755\n",
      "train loss:0.009659282071476746\n",
      "train loss:0.08494528462849807\n",
      "train loss:0.03643874263230308\n",
      "train loss:0.009629615562163806\n",
      "train loss:0.01872250690372216\n",
      "train loss:0.03487159284491466\n",
      "train loss:0.026097909214537206\n",
      "train loss:0.046137394372864564\n",
      "train loss:0.03832750799533325\n",
      "train loss:0.03698320183814144\n",
      "train loss:0.013094904688274636\n",
      "train loss:0.023754874082140703\n",
      "train loss:0.014852794966160605\n",
      "train loss:0.10215312374075987\n",
      "train loss:0.05341728472919673\n",
      "train loss:0.0110923956093135\n",
      "train loss:0.020070962957441915\n",
      "train loss:0.027604893547602476\n",
      "train loss:0.045868187091483305\n",
      "train loss:0.018741820579931717\n",
      "train loss:0.0134985871224152\n",
      "train loss:0.050067228887850285\n",
      "train loss:0.061578014097864425\n",
      "train loss:0.023306450466507228\n",
      "train loss:0.042513423750057976\n",
      "train loss:0.011504130642249642\n",
      "train loss:0.009436329931837\n",
      "train loss:0.0875955567957374\n",
      "train loss:0.012240102126724954\n",
      "train loss:0.031106564416863495\n",
      "train loss:0.04200492893888531\n",
      "train loss:0.11953977390205557\n",
      "train loss:0.028507134252185828\n",
      "train loss:0.022156422450762738\n",
      "train loss:0.0709026394715527\n",
      "train loss:0.06659893028996827\n",
      "train loss:0.05379092733934842\n",
      "train loss:0.040282795710349865\n",
      "train loss:0.022162769137226816\n",
      "train loss:0.08664385624270243\n",
      "train loss:0.04449969287991867\n",
      "train loss:0.0414856279369597\n",
      "train loss:0.11285736843388364\n",
      "train loss:0.08310883645127323\n",
      "train loss:0.011806048463263906\n",
      "train loss:0.02324406155939667\n",
      "train loss:0.03202959633383199\n",
      "train loss:0.03486092000024545\n",
      "train loss:0.058515838962756035\n",
      "train loss:0.04639295976595676\n",
      "train loss:0.011486310949510234\n",
      "train loss:0.03746637248716319\n",
      "train loss:0.028185246354042275\n",
      "train loss:0.01853279365187107\n",
      "train loss:0.06767199912274932\n",
      "train loss:0.025764824438508593\n",
      "train loss:0.013379973406431666\n",
      "train loss:0.027439744704744088\n",
      "train loss:0.01611628820876191\n",
      "train loss:0.016213768874522614\n",
      "train loss:0.016654124333727968\n",
      "train loss:0.020861382896548854\n",
      "train loss:0.04497290591267618\n",
      "train loss:0.04246400280637662\n",
      "train loss:0.005870813755781572\n",
      "train loss:0.007636803487647125\n",
      "train loss:0.06680616724076031\n",
      "train loss:0.029516651264881996\n",
      "train loss:0.012673201381186591\n",
      "train loss:0.0064670060501457564\n",
      "train loss:0.024201873412947744\n",
      "train loss:0.031748923240778326\n",
      "train loss:0.028277157128968822\n",
      "train loss:0.02721530348694127\n",
      "train loss:0.027938521022493733\n",
      "train loss:0.005508718946026238\n",
      "train loss:0.04153159667776115\n",
      "train loss:0.02009328492103236\n",
      "train loss:0.07619497660575694\n",
      "train loss:0.01809176002573617\n",
      "train loss:0.052083789027984634\n",
      "train loss:0.042041566026308624\n",
      "train loss:0.022625576925355072\n",
      "train loss:0.06714039545707137\n",
      "train loss:0.07371223232055861\n",
      "train loss:0.011482408852098374\n",
      "train loss:0.058030355448994674\n",
      "train loss:0.016567815600902\n",
      "train loss:0.06088699322727989\n",
      "train loss:0.026295230122529968\n",
      "train loss:0.015381662681311407\n",
      "train loss:0.06514443865450402\n",
      "train loss:0.06488142238999017\n",
      "train loss:0.025750835648257846\n",
      "train loss:0.013813370625529144\n",
      "train loss:0.010363362809344506\n",
      "train loss:0.0064809526974180355\n",
      "train loss:0.04839726568521327\n",
      "train loss:0.15458612753551346\n",
      "train loss:0.011226523242068319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.026326194987089026\n",
      "train loss:0.05137991370965154\n",
      "train loss:0.03833711640219053\n",
      "train loss:0.0887577333403578\n",
      "train loss:0.0414956743739511\n",
      "train loss:0.05201215980308019\n",
      "train loss:0.0335420852062046\n",
      "train loss:0.0743141182808108\n",
      "train loss:0.024157353410008974\n",
      "train loss:0.021959000274044304\n",
      "train loss:0.029602546348593967\n",
      "train loss:0.0324087261225328\n",
      "train loss:0.06290395093235471\n",
      "train loss:0.025979330806256876\n",
      "train loss:0.027531471116432945\n",
      "train loss:0.13157741769709866\n",
      "train loss:0.034138920187770816\n",
      "train loss:0.039606469501584446\n",
      "train loss:0.030385584130353457\n",
      "train loss:0.06714421856218786\n",
      "train loss:0.08909730153816527\n",
      "train loss:0.01786713081346748\n",
      "train loss:0.023329275021611185\n",
      "train loss:0.005322600830144885\n",
      "train loss:0.026460898236950622\n",
      "train loss:0.022151439247337677\n",
      "=== epoch:5, train acc:0.983, test acc:0.982 ===\n",
      "train loss:0.01760690923252656\n",
      "train loss:0.05031647048877242\n",
      "train loss:0.025605180061242044\n",
      "train loss:0.023367609079630217\n",
      "train loss:0.01732876344095829\n",
      "train loss:0.03549233333178807\n",
      "train loss:0.013949041050312236\n",
      "train loss:0.020265890620552184\n",
      "train loss:0.026788686583144313\n",
      "train loss:0.031375750439010176\n",
      "train loss:0.012632207956690256\n",
      "train loss:0.08747068494312858\n",
      "train loss:0.04256144267567387\n",
      "train loss:0.008818357389213842\n",
      "train loss:0.005861152809870737\n",
      "train loss:0.009651900155578623\n",
      "train loss:0.019203535552903026\n",
      "train loss:0.07110699543845582\n",
      "train loss:0.006560596505255839\n",
      "train loss:0.0037746760305426086\n",
      "train loss:0.017633283626763373\n",
      "train loss:0.02795389105006452\n",
      "train loss:0.05845369590741985\n",
      "train loss:0.013942117946536142\n",
      "train loss:0.011743937733924214\n",
      "train loss:0.03420380233662573\n",
      "train loss:0.04424766922512167\n",
      "train loss:0.03335851487864834\n",
      "train loss:0.008472779221672276\n",
      "train loss:0.016562633491148747\n",
      "train loss:0.020139453745960087\n",
      "train loss:0.015967332631190285\n",
      "train loss:0.006595974275595957\n",
      "train loss:0.011695616529567283\n",
      "train loss:0.013334490196962706\n",
      "train loss:0.025786106783632707\n",
      "train loss:0.011773093265631751\n",
      "train loss:0.007892959444328466\n",
      "train loss:0.04800191709815296\n",
      "train loss:0.011916656621364773\n",
      "train loss:0.0362873560131372\n",
      "train loss:0.07003408963327706\n",
      "train loss:0.01831435650573254\n",
      "train loss:0.04700481993277917\n",
      "train loss:0.025215460012152278\n",
      "train loss:0.04104976055679397\n",
      "train loss:0.007587963660476644\n",
      "train loss:0.01108734941240782\n",
      "train loss:0.01910153955856038\n",
      "train loss:0.031048324334749463\n",
      "train loss:0.03487551447730874\n",
      "train loss:0.013831962463576477\n",
      "train loss:0.032376951714383095\n",
      "train loss:0.017425839440171186\n",
      "train loss:0.027446691560594542\n",
      "train loss:0.05541485790215891\n",
      "train loss:0.04404194215767717\n",
      "train loss:0.010037256924418916\n",
      "train loss:0.014933907890861586\n",
      "train loss:0.013200915344814362\n",
      "train loss:0.024558157363661418\n",
      "train loss:0.012668623200623383\n",
      "train loss:0.02286675175770315\n",
      "train loss:0.020361681967453412\n",
      "train loss:0.0602039376221709\n",
      "train loss:0.109358314403528\n",
      "train loss:0.0613632022920772\n",
      "train loss:0.021720825147272266\n",
      "train loss:0.016809917471319002\n",
      "train loss:0.0119488658125897\n",
      "train loss:0.02619389073436861\n",
      "train loss:0.0350331089906543\n",
      "train loss:0.04110851665769161\n",
      "train loss:0.008916690714665328\n",
      "train loss:0.041827329225311176\n",
      "train loss:0.08112422321567588\n",
      "train loss:0.024018930944675353\n",
      "train loss:0.03172884254376395\n",
      "train loss:0.012896682748947941\n",
      "train loss:0.008471971847737623\n",
      "train loss:0.0848390315225682\n",
      "train loss:0.03657665442842623\n",
      "train loss:0.020383819496650753\n",
      "train loss:0.017560156807730865\n",
      "train loss:0.034945041418572555\n",
      "train loss:0.03174989983586122\n",
      "train loss:0.05482676890523899\n",
      "train loss:0.03380848534840062\n",
      "train loss:0.07572402388710898\n",
      "train loss:0.003110229485739447\n",
      "train loss:0.06112264707495814\n",
      "train loss:0.028518091524506812\n",
      "train loss:0.005945170154855783\n",
      "train loss:0.012896362649753064\n",
      "train loss:0.005007687413399416\n",
      "train loss:0.039538185862115875\n",
      "train loss:0.038336742128384234\n",
      "train loss:0.054301874125918415\n",
      "train loss:0.01561315309838925\n",
      "train loss:0.012664177877173033\n",
      "train loss:0.013305149899851026\n",
      "train loss:0.01439692152872673\n",
      "train loss:0.009818589492061002\n",
      "train loss:0.0821882509322894\n",
      "train loss:0.030719923584511713\n",
      "train loss:0.0803798488128121\n",
      "train loss:0.04989775798179411\n",
      "train loss:0.01273927060518316\n",
      "train loss:0.04610243549910392\n",
      "train loss:0.044986346619874835\n",
      "train loss:0.07351675758032879\n",
      "train loss:0.006462266382559527\n",
      "train loss:0.022767807615299045\n",
      "train loss:0.04404991547827167\n",
      "train loss:0.07720552952575664\n",
      "train loss:0.020853843606347518\n",
      "train loss:0.06118983131061941\n",
      "train loss:0.035343594567408744\n",
      "train loss:0.01780841494184648\n",
      "train loss:0.03292712917330525\n",
      "train loss:0.018959608661957304\n",
      "train loss:0.08322865427317407\n",
      "train loss:0.010909614746299789\n",
      "train loss:0.015836251782218716\n",
      "train loss:0.02944168600728858\n",
      "train loss:0.04271611563126657\n",
      "train loss:0.02006508476743437\n",
      "train loss:0.05687440122082796\n",
      "train loss:0.019258494925670114\n",
      "train loss:0.03244476175086463\n",
      "train loss:0.016808222964685437\n",
      "train loss:0.011600070265218889\n",
      "train loss:0.01422940855590418\n",
      "train loss:0.035630718972476785\n",
      "train loss:0.014717370855978414\n",
      "train loss:0.022783690834666345\n",
      "train loss:0.006344474619485555\n",
      "train loss:0.03656763994498109\n",
      "train loss:0.007247632161909076\n",
      "train loss:0.03698419778147647\n",
      "train loss:0.010802359463592807\n",
      "train loss:0.12740247578852376\n",
      "train loss:0.046394636476685465\n",
      "train loss:0.022552661873559934\n",
      "train loss:0.018518708301321237\n",
      "train loss:0.03502462902726055\n",
      "train loss:0.017642899369047265\n",
      "train loss:0.18062340387493092\n",
      "train loss:0.07638298167922777\n",
      "train loss:0.03209335414010209\n",
      "train loss:0.0719809875096238\n",
      "train loss:0.036688735497497585\n",
      "train loss:0.044649481427477704\n",
      "train loss:0.01662867139267262\n",
      "train loss:0.005356990009458057\n",
      "train loss:0.10659449575053763\n",
      "train loss:0.07781959061645632\n",
      "train loss:0.03461969444809435\n",
      "train loss:0.06508615236019216\n",
      "train loss:0.05079713203299183\n",
      "train loss:0.052827431727444016\n",
      "train loss:0.01869261508801387\n",
      "train loss:0.00853261653973603\n",
      "train loss:0.005902602767926209\n",
      "train loss:0.10278475089703001\n",
      "train loss:0.02907052116537724\n",
      "train loss:0.04999678904859836\n",
      "train loss:0.010055060890463721\n",
      "train loss:0.0186012160068207\n",
      "train loss:0.007141318701978828\n",
      "train loss:0.04638512352414414\n",
      "train loss:0.013176132924253596\n",
      "train loss:0.031113868559874355\n",
      "train loss:0.011566014417497293\n",
      "train loss:0.0229690959969503\n",
      "train loss:0.07398647361635216\n",
      "train loss:0.027797529121552467\n",
      "train loss:0.047517738796910784\n",
      "train loss:0.03123529919540049\n",
      "train loss:0.016952346864041103\n",
      "train loss:0.019127765271850682\n",
      "train loss:0.01902357442228453\n",
      "train loss:0.038619253916394834\n",
      "train loss:0.07543954057441572\n",
      "train loss:0.031039136552998333\n",
      "train loss:0.02362588375722717\n",
      "train loss:0.050935966962622044\n",
      "train loss:0.040379353168815205\n",
      "train loss:0.04585656771968382\n",
      "train loss:0.06479198913331598\n",
      "train loss:0.041652426669158714\n",
      "train loss:0.024763279489432907\n",
      "train loss:0.06521482131354123\n",
      "train loss:0.0514068799565749\n",
      "train loss:0.02168823549132976\n",
      "train loss:0.03949416396440126\n",
      "train loss:0.013332684724009378\n",
      "train loss:0.016060479381182005\n",
      "train loss:0.022975780743989347\n",
      "train loss:0.011631260488386813\n",
      "train loss:0.006543508657362081\n",
      "train loss:0.006547906327259354\n",
      "train loss:0.08145599030596302\n",
      "train loss:0.030037060493847995\n",
      "train loss:0.008254787800656496\n",
      "train loss:0.041203951062649555\n",
      "train loss:0.009881949991332762\n",
      "train loss:0.008887487105653055\n",
      "train loss:0.019104924112443952\n",
      "train loss:0.019323708182123072\n",
      "train loss:0.058509171166319235\n",
      "train loss:0.00783432608078118\n",
      "train loss:0.015245191611018137\n",
      "train loss:0.014283907522004606\n",
      "train loss:0.09260368358505928\n",
      "train loss:0.028524734862687615\n",
      "train loss:0.0191740565047411\n",
      "train loss:0.06747794197643424\n",
      "train loss:0.021619082856782233\n",
      "train loss:0.11128412140804483\n",
      "train loss:0.030284276328308248\n",
      "train loss:0.008187597985392859\n",
      "train loss:0.021810380150749372\n",
      "train loss:0.012906501079201023\n",
      "train loss:0.00699183916233428\n",
      "train loss:0.011087574377119009\n",
      "train loss:0.02443305630943504\n",
      "train loss:0.025514191413589647\n",
      "train loss:0.036991599752139497\n",
      "train loss:0.010613736329283509\n",
      "train loss:0.08207157111854993\n",
      "train loss:0.00949338591716863\n",
      "train loss:0.0850038069481691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.009110702184462542\n",
      "train loss:0.02057501424759105\n",
      "train loss:0.04455575793950372\n",
      "train loss:0.015393845955326647\n",
      "train loss:0.005423438567377395\n",
      "train loss:0.06986710273104184\n",
      "train loss:0.023337268576650475\n",
      "train loss:0.005162179958743895\n",
      "train loss:0.011904860653572585\n",
      "train loss:0.010269317761063235\n",
      "train loss:0.0052435783143126215\n",
      "train loss:0.02945756601376011\n",
      "train loss:0.014447716322021435\n",
      "train loss:0.021130928534569347\n",
      "train loss:0.019332629943496354\n",
      "train loss:0.025339824889021742\n",
      "train loss:0.012166055208013993\n",
      "train loss:0.013577630575568494\n",
      "train loss:0.0055850705674912885\n",
      "train loss:0.04731486264105086\n",
      "train loss:0.018217115747854756\n",
      "train loss:0.007141777685529198\n",
      "train loss:0.00871412137520281\n",
      "train loss:0.040621537392575756\n",
      "train loss:0.03785108141400994\n",
      "train loss:0.02375672827055638\n",
      "train loss:0.010603877754047525\n",
      "train loss:0.009835105290661903\n",
      "train loss:0.06360091264283978\n",
      "train loss:0.060368481344002856\n",
      "train loss:0.0037941361241211015\n",
      "train loss:0.029062338230226102\n",
      "train loss:0.010988215660984664\n",
      "train loss:0.016632703105947035\n",
      "train loss:0.022979067372112486\n",
      "train loss:0.0368402910269693\n",
      "train loss:0.016323743777997016\n",
      "train loss:0.011649454406769203\n",
      "train loss:0.0071576433321835185\n",
      "train loss:0.016597591752110553\n",
      "train loss:0.029177418334317487\n",
      "train loss:0.044914677970349495\n",
      "train loss:0.06430443828314819\n",
      "train loss:0.020530497709611892\n",
      "train loss:0.08120442536027019\n",
      "train loss:0.023705773828026966\n",
      "train loss:0.02351128121118849\n",
      "train loss:0.025597713857733826\n",
      "train loss:0.025657318783402713\n",
      "train loss:0.05304488775691662\n",
      "train loss:0.012958533287312883\n",
      "train loss:0.018252874182437814\n",
      "train loss:0.025507967103940765\n",
      "train loss:0.016581818049966345\n",
      "train loss:0.009098857548307028\n",
      "train loss:0.06233291567349272\n",
      "train loss:0.019112368633510592\n",
      "train loss:0.019653116770203472\n",
      "train loss:0.016120075513639656\n",
      "train loss:0.036612425197051095\n",
      "train loss:0.03926840359776041\n",
      "train loss:0.04602940964616717\n",
      "train loss:0.027190739838994823\n",
      "train loss:0.08246177240969706\n",
      "train loss:0.0230004565544424\n",
      "train loss:0.018551738170757455\n",
      "train loss:0.0016754616131069333\n",
      "train loss:0.03261899234299527\n",
      "train loss:0.01628288135354735\n",
      "train loss:0.008480716649397778\n",
      "train loss:0.016686093142212952\n",
      "train loss:0.02540597663770242\n",
      "train loss:0.02158627434988295\n",
      "train loss:0.00921272550687954\n",
      "train loss:0.008265184814028638\n",
      "train loss:0.03189161033158667\n",
      "train loss:0.0655326423029637\n",
      "train loss:0.03617774711186654\n",
      "train loss:0.14361676755201516\n",
      "train loss:0.007022265656072098\n",
      "train loss:0.04943768639299122\n",
      "train loss:0.032243623571767334\n",
      "train loss:0.046539256278149546\n",
      "train loss:0.01935494125270144\n",
      "train loss:0.0904118626560802\n",
      "train loss:0.027793295433911642\n",
      "train loss:0.03545389211263316\n",
      "train loss:0.02757159746298994\n",
      "train loss:0.015265732392460922\n",
      "train loss:0.020537935999302342\n",
      "train loss:0.07692459635183294\n",
      "train loss:0.03409466561322291\n",
      "train loss:0.05555829374008558\n",
      "train loss:0.018029784188696593\n",
      "train loss:0.02166228164740184\n",
      "train loss:0.019666878781409988\n",
      "train loss:0.028727389923061297\n",
      "train loss:0.03234002856268839\n",
      "train loss:0.024714875510800285\n",
      "train loss:0.07748830643431166\n",
      "train loss:0.00941836102899245\n",
      "train loss:0.008327281389832806\n",
      "train loss:0.03257091982892677\n",
      "train loss:0.028916293753450124\n",
      "train loss:0.04835551578243859\n",
      "train loss:0.00975334286850344\n",
      "train loss:0.0532646945862548\n",
      "train loss:0.04652347240130606\n",
      "train loss:0.008426453221955425\n",
      "train loss:0.015509062460695978\n",
      "train loss:0.028708942781003173\n",
      "train loss:0.005344164003177063\n",
      "train loss:0.009442279640153983\n",
      "train loss:0.05290674504670811\n",
      "train loss:0.011108750299986845\n",
      "train loss:0.03563351847618857\n",
      "train loss:0.00930683770310061\n",
      "train loss:0.033978504714907355\n",
      "train loss:0.050090825221081665\n",
      "train loss:0.020620131306189685\n",
      "train loss:0.007592597061631858\n",
      "train loss:0.02047295884861616\n",
      "train loss:0.012345263771023865\n",
      "train loss:0.03339454329898624\n",
      "train loss:0.015358571480542947\n",
      "train loss:0.04511240523658472\n",
      "train loss:0.03285188199989915\n",
      "train loss:0.006588227134469612\n",
      "train loss:0.027416036398106775\n",
      "train loss:0.030942906947937582\n",
      "train loss:0.030531073362339744\n",
      "train loss:0.01833971507462072\n",
      "train loss:0.006210081642114466\n",
      "train loss:0.03246621889252177\n",
      "train loss:0.04951612347880238\n",
      "train loss:0.004889139052382059\n",
      "train loss:0.024031214427558404\n",
      "train loss:0.016959277629320747\n",
      "train loss:0.032077974680200516\n",
      "train loss:0.02144659913954909\n",
      "train loss:0.013090833641670336\n",
      "train loss:0.03486796230252644\n",
      "train loss:0.05039810898796133\n",
      "train loss:0.013062448951736503\n",
      "train loss:0.02773059131378345\n",
      "train loss:0.012087692081937645\n",
      "train loss:0.01093200491299904\n",
      "train loss:0.04604004572614759\n",
      "train loss:0.009553420652872605\n",
      "train loss:0.013234153764051026\n",
      "train loss:0.17926843488734856\n",
      "train loss:0.0397250329285727\n",
      "train loss:0.010453734113213433\n",
      "train loss:0.006702757507896383\n",
      "train loss:0.01645861807893684\n",
      "train loss:0.052338078276674124\n",
      "train loss:0.012394321728244293\n",
      "train loss:0.02261842995282091\n",
      "train loss:0.03270867932115877\n",
      "train loss:0.07463805337696523\n",
      "train loss:0.04253029836891128\n",
      "train loss:0.04239319697786887\n",
      "train loss:0.009940614952160514\n",
      "train loss:0.009363688414844352\n",
      "train loss:0.025607358357245816\n",
      "train loss:0.00688737431298201\n",
      "train loss:0.09302432481953789\n",
      "train loss:0.0710587893927202\n",
      "train loss:0.08299755320465087\n",
      "train loss:0.003391616481665961\n",
      "train loss:0.02404485131384436\n",
      "train loss:0.0050041342647679085\n",
      "train loss:0.03733406483397172\n",
      "train loss:0.017227958773692497\n",
      "train loss:0.015452341684452673\n",
      "train loss:0.013851271735717922\n",
      "train loss:0.02115147222147852\n",
      "train loss:0.03408886054856288\n",
      "train loss:0.019848468277588256\n",
      "train loss:0.01184674935236796\n",
      "train loss:0.02016793009227864\n",
      "train loss:0.01929969416955497\n",
      "train loss:0.009772258628381587\n",
      "train loss:0.014271123572252914\n",
      "train loss:0.004996995907753245\n",
      "train loss:0.009255200570443736\n",
      "train loss:0.01424514851048008\n",
      "train loss:0.09992788736400453\n",
      "train loss:0.028062815425647588\n",
      "train loss:0.05296374683499263\n",
      "train loss:0.024431206761594364\n",
      "train loss:0.021796148319125352\n",
      "train loss:0.07472373714662156\n",
      "train loss:0.00977981294170604\n",
      "train loss:0.004989749322589724\n",
      "train loss:0.018651184724487485\n",
      "train loss:0.0562579027257003\n",
      "train loss:0.03323727988309663\n",
      "train loss:0.021133777545031138\n",
      "train loss:0.0286485554967356\n",
      "train loss:0.018392138634732585\n",
      "train loss:0.007224652241187148\n",
      "train loss:0.016140441995794053\n",
      "train loss:0.05136832769334749\n",
      "train loss:0.07042186681849529\n",
      "train loss:0.003558581765339674\n",
      "train loss:0.026640325337233598\n",
      "train loss:0.010243757723233398\n",
      "train loss:0.029326835517449395\n",
      "train loss:0.04496747755274549\n",
      "train loss:0.050077809764312066\n",
      "train loss:0.013861938531225651\n",
      "train loss:0.049912397165171936\n",
      "train loss:0.10520072594839305\n",
      "train loss:0.009610569188672074\n",
      "train loss:0.06174187751535196\n",
      "train loss:0.00638499881818411\n",
      "train loss:0.016032494155544353\n",
      "train loss:0.00891058131669321\n",
      "train loss:0.03153682537417115\n",
      "train loss:0.021738883974356527\n",
      "train loss:0.11392287695971895\n",
      "train loss:0.018516790726602405\n",
      "train loss:0.04474471456414889\n",
      "train loss:0.0856533985291628\n",
      "train loss:0.050313651382905514\n",
      "train loss:0.014019410534911054\n",
      "train loss:0.015260534805336599\n",
      "train loss:0.02783852317026495\n",
      "train loss:0.009434075425477605\n",
      "train loss:0.08590770288539419\n",
      "train loss:0.076182333662827\n",
      "train loss:0.07729941050059709\n",
      "train loss:0.007479724126926147\n",
      "train loss:0.048349730184042095\n",
      "train loss:0.04356906205358965\n",
      "train loss:0.035570952390073296\n",
      "train loss:0.009890264518519463\n",
      "train loss:0.016332692682934465\n",
      "train loss:0.08436768122820869\n",
      "train loss:0.04560518518956932\n",
      "train loss:0.12297789228070556\n",
      "train loss:0.011903148968794373\n",
      "train loss:0.012705970028882322\n",
      "train loss:0.03798126297764273\n",
      "train loss:0.014168754590307236\n",
      "train loss:0.03367505873576189\n",
      "train loss:0.012790101987944016\n",
      "train loss:0.018979878480035014\n",
      "train loss:0.03564466211843954\n",
      "train loss:0.0072329282596442805\n",
      "train loss:0.01867171153641104\n",
      "train loss:0.07758037225148069\n",
      "train loss:0.04102684336695628\n",
      "train loss:0.004297624062498993\n",
      "train loss:0.013084838379687089\n",
      "train loss:0.008334374720249482\n",
      "train loss:0.022523498369529334\n",
      "train loss:0.03543742585529591\n",
      "train loss:0.012800715731173928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.03407510261144595\n",
      "train loss:0.03567584195535858\n",
      "train loss:0.010905988130928029\n",
      "train loss:0.02633009374831883\n",
      "train loss:0.008908059423588405\n",
      "train loss:0.017819514413245485\n",
      "train loss:0.028158243792834808\n",
      "train loss:0.06352150516121013\n",
      "train loss:0.010626961298103945\n",
      "train loss:0.009992133318974977\n",
      "train loss:0.021105605578339025\n",
      "train loss:0.05205452217748223\n",
      "train loss:0.033499890071628714\n",
      "train loss:0.03306265198428561\n",
      "train loss:0.09550275022110237\n",
      "train loss:0.059154747842009275\n",
      "train loss:0.021842054100520824\n",
      "train loss:0.035165898073350424\n",
      "train loss:0.005638018375497596\n",
      "train loss:0.026853705612198624\n",
      "train loss:0.046707251483661956\n",
      "train loss:0.014674080081210596\n",
      "train loss:0.02013515411701773\n",
      "train loss:0.04705400325209934\n",
      "train loss:0.02271538215093221\n",
      "train loss:0.00986131978159172\n",
      "train loss:0.029867416959528388\n",
      "train loss:0.03358809034457088\n",
      "train loss:0.00820571128608182\n",
      "train loss:0.0037909579479542743\n",
      "train loss:0.032190302041126294\n",
      "train loss:0.05305335269108271\n",
      "train loss:0.0078844320830487\n",
      "train loss:0.004309024842292025\n",
      "train loss:0.017540254478836344\n",
      "train loss:0.03088431240557589\n",
      "train loss:0.05522308583122797\n",
      "train loss:0.010161037777362634\n",
      "train loss:0.009942124826650809\n",
      "train loss:0.0581030835196473\n",
      "train loss:0.0193343872776232\n",
      "train loss:0.007135732360460731\n",
      "train loss:0.01638204654909007\n",
      "train loss:0.052466098755506\n",
      "train loss:0.024461272716377165\n",
      "train loss:0.027998736332581663\n",
      "train loss:0.023821470113321922\n",
      "train loss:0.03441073189319571\n",
      "train loss:0.06500783521532068\n",
      "train loss:0.022809330945511085\n",
      "train loss:0.021812167913388077\n",
      "train loss:0.037968517984414835\n",
      "train loss:0.013646828375528513\n",
      "train loss:0.012744960035135715\n",
      "train loss:0.02408705850418905\n",
      "train loss:0.016607797210082754\n",
      "train loss:0.020520659512064415\n",
      "train loss:0.003969713789903956\n",
      "train loss:0.018041875703242644\n",
      "train loss:0.01872292598896283\n",
      "train loss:0.024043969543291972\n",
      "train loss:0.010561732877727065\n",
      "train loss:0.0663434840802656\n",
      "train loss:0.011194143397024623\n",
      "train loss:0.017285001198660343\n",
      "train loss:0.012666499881526527\n",
      "train loss:0.005074694180686313\n",
      "train loss:0.043193079004965586\n",
      "train loss:0.03297647579298866\n",
      "train loss:0.048795334554056186\n",
      "train loss:0.03914973452924655\n",
      "train loss:0.01019629627649693\n",
      "train loss:0.024831211985733997\n",
      "train loss:0.08625558371796961\n",
      "train loss:0.006850314371388334\n",
      "train loss:0.02616986792096572\n",
      "train loss:0.01873392285839171\n",
      "train loss:0.026494866670456835\n",
      "train loss:0.04562678615114117\n",
      "train loss:0.003176674433130045\n",
      "train loss:0.02971648030726032\n",
      "train loss:0.006970127650238272\n",
      "train loss:0.011689272365091784\n",
      "train loss:0.0627082617531274\n",
      "train loss:0.007757872729335177\n",
      "train loss:0.04449207907361855\n",
      "train loss:0.038192792892081946\n",
      "train loss:0.007785108385963257\n",
      "train loss:0.012670429732228386\n",
      "train loss:0.023820612371131908\n",
      "train loss:0.025149528125431156\n",
      "train loss:0.03250328049298887\n",
      "train loss:0.012487899922334225\n",
      "train loss:0.006371529812349199\n",
      "train loss:0.014601819136223706\n",
      "train loss:0.004195884733166439\n",
      "train loss:0.006265783083391508\n",
      "train loss:0.012670492879903107\n",
      "train loss:0.03785150963832539\n",
      "train loss:0.019936963662880728\n",
      "train loss:0.03440406517685016\n",
      "train loss:0.00943293083973534\n",
      "train loss:0.060464305844187355\n",
      "train loss:0.009508551239912564\n",
      "train loss:0.011503419430263175\n",
      "train loss:0.019500943626425505\n",
      "train loss:0.009401295061656002\n",
      "=== epoch:6, train acc:0.985, test acc:0.981 ===\n",
      "train loss:0.015384067978458206\n",
      "train loss:0.0707322887401129\n",
      "train loss:0.011275423819889472\n",
      "train loss:0.02872849881990352\n",
      "train loss:0.026286546377067732\n",
      "train loss:0.01795962736501489\n",
      "train loss:0.008285079761949657\n",
      "train loss:0.020510268912882816\n",
      "train loss:0.06902232725358713\n",
      "train loss:0.02851083521651908\n",
      "train loss:0.10790365855032574\n",
      "train loss:0.017984060701378538\n",
      "train loss:0.014471092524208452\n",
      "train loss:0.0127218301474915\n",
      "train loss:0.01086647196959788\n",
      "train loss:0.01359480787270112\n",
      "train loss:0.016339721094366343\n",
      "train loss:0.06601136507716752\n",
      "train loss:0.007971707422235842\n",
      "train loss:0.014826370097107577\n",
      "train loss:0.07522921612690611\n",
      "train loss:0.02385523578114634\n",
      "train loss:0.05209957990987843\n",
      "train loss:0.029007022983079077\n",
      "train loss:0.020718294980585153\n",
      "train loss:0.08945806550956188\n",
      "train loss:0.03492005350475076\n",
      "train loss:0.009526884858131454\n",
      "train loss:0.007026153726482956\n",
      "train loss:0.04115920746133111\n",
      "train loss:0.01516993115220552\n",
      "train loss:0.06929473360852181\n",
      "train loss:0.03345433448501528\n",
      "train loss:0.031968671534901044\n",
      "train loss:0.002691170383146043\n",
      "train loss:0.015383579403475735\n",
      "train loss:0.032632323928849384\n",
      "train loss:0.005848764280430744\n",
      "train loss:0.0056656458477856945\n",
      "train loss:0.016951965318462946\n",
      "train loss:0.01848328247507845\n",
      "train loss:0.022327930263194434\n",
      "train loss:0.02400105243545758\n",
      "train loss:0.0037816676674633488\n",
      "train loss:0.021946980348479812\n",
      "train loss:0.012140818744763016\n",
      "train loss:0.012024078060430243\n",
      "train loss:0.010388032846322766\n",
      "train loss:0.037249478541914446\n",
      "train loss:0.02062903091892126\n",
      "train loss:0.016209620057967958\n",
      "train loss:0.019120724687222517\n",
      "train loss:0.009724494373652305\n",
      "train loss:0.03905408145122912\n",
      "train loss:0.0499514470847795\n",
      "train loss:0.023154608196170216\n",
      "train loss:0.004958508389849885\n",
      "train loss:0.008484760210611042\n",
      "train loss:0.013121210166461202\n",
      "train loss:0.08196225189359904\n",
      "train loss:0.04899285292295536\n",
      "train loss:0.021122211677870907\n",
      "train loss:0.01987193584436244\n",
      "train loss:0.01559757248989617\n",
      "train loss:0.00861294387297831\n",
      "train loss:0.0271670479754365\n",
      "train loss:0.013431640441250156\n",
      "train loss:0.009873201265047449\n",
      "train loss:0.008162009360460364\n",
      "train loss:0.017740743939998863\n",
      "train loss:0.04639818242838363\n",
      "train loss:0.017612006885053422\n",
      "train loss:0.07141401266340808\n",
      "train loss:0.030544617609743304\n",
      "train loss:0.01587618611509596\n",
      "train loss:0.006410539947391984\n",
      "train loss:0.04182245387343704\n",
      "train loss:0.011638016579011225\n",
      "train loss:0.005985046808693474\n",
      "train loss:0.00795136232908043\n",
      "train loss:0.01755104254001713\n",
      "train loss:0.025264011209205156\n",
      "train loss:0.013231678558525655\n",
      "train loss:0.013085797852724835\n",
      "train loss:0.0902469687974659\n",
      "train loss:0.0075722804127583854\n",
      "train loss:0.014811793544353961\n",
      "train loss:0.016358952581805277\n",
      "train loss:0.0023236801081438175\n",
      "train loss:0.00340990583687447\n",
      "train loss:0.029660177993946366\n",
      "train loss:0.04005373208172916\n",
      "train loss:0.004829673153388866\n",
      "train loss:0.0526650107470311\n",
      "train loss:0.004855790573769662\n",
      "train loss:0.03670005103658128\n",
      "train loss:0.0062006355722116656\n",
      "train loss:0.032226991870197765\n",
      "train loss:0.00460992569918976\n",
      "train loss:0.026933647347473392\n",
      "train loss:0.010241024544388556\n",
      "train loss:0.0020090909312990937\n",
      "train loss:0.01427234802737381\n",
      "train loss:0.0271155142184195\n",
      "train loss:0.008440560160565882\n",
      "train loss:0.028499365067642675\n",
      "train loss:0.029380246183864245\n",
      "train loss:0.00771461194393151\n",
      "train loss:0.010663059933077992\n",
      "train loss:0.009325886574373107\n",
      "train loss:0.006330235416097074\n",
      "train loss:0.014986693411660892\n",
      "train loss:0.010229602396999134\n",
      "train loss:0.029705236558128224\n",
      "train loss:0.013666079347233677\n",
      "train loss:0.013561211100063104\n",
      "train loss:0.1316171048894345\n",
      "train loss:0.015332833779223627\n",
      "train loss:0.005087716109122457\n",
      "train loss:0.03063852496556576\n",
      "train loss:0.016595286404651986\n",
      "train loss:0.0373008227446792\n",
      "train loss:0.08364280778983278\n",
      "train loss:0.04409599537546774\n",
      "train loss:0.010598058898834063\n",
      "train loss:0.02920288094274968\n",
      "train loss:0.01658457128170824\n",
      "train loss:0.006973572170019113\n",
      "train loss:0.0646817273520215\n",
      "train loss:0.03270343907045136\n",
      "train loss:0.028333156229171402\n",
      "train loss:0.01607237745663427\n",
      "train loss:0.04068928696902792\n",
      "train loss:0.009933043210800562\n",
      "train loss:0.013644137686912902\n",
      "train loss:0.006986521193919837\n",
      "train loss:0.024462511281339784\n",
      "train loss:0.02024513182190747\n",
      "train loss:0.045134656044807216\n",
      "train loss:0.004190640880233963\n",
      "train loss:0.02208770514056122\n",
      "train loss:0.018347771718841503\n",
      "train loss:0.01019103788595483\n",
      "train loss:0.014348099885327599\n",
      "train loss:0.027626285876085243\n",
      "train loss:0.011104983413341797\n",
      "train loss:0.04940730747562075\n",
      "train loss:0.007495648136645412\n",
      "train loss:0.02102877125582494\n",
      "train loss:0.05884915814809188\n",
      "train loss:0.01805085109542442\n",
      "train loss:0.019646318669025737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.02253886510883483\n",
      "train loss:0.02412717212764589\n",
      "train loss:0.020395715398338937\n",
      "train loss:0.028527845071557853\n",
      "train loss:0.00960616438622069\n",
      "train loss:0.01358703494320256\n",
      "train loss:0.016235021746179478\n",
      "train loss:0.013724797963391622\n",
      "train loss:0.017759994533443093\n",
      "train loss:0.026175455671285982\n",
      "train loss:0.01594855069236774\n",
      "train loss:0.011130743483605045\n",
      "train loss:0.024294331845717335\n",
      "train loss:0.00673542670300607\n",
      "train loss:0.00847943364391357\n",
      "train loss:0.04639214117809288\n",
      "train loss:0.00748835252684132\n",
      "train loss:0.009287758694327597\n",
      "train loss:0.020343507922446456\n",
      "train loss:0.01450516550793468\n",
      "train loss:0.026325227243216537\n",
      "train loss:0.011399213447896725\n",
      "train loss:0.016153976197824937\n",
      "train loss:0.029411372023701223\n",
      "train loss:0.02149336883538794\n",
      "train loss:0.012004837266535498\n",
      "train loss:0.030580500493987927\n",
      "train loss:0.02389559192182429\n",
      "train loss:0.005977985198154439\n",
      "train loss:0.015659304512129386\n",
      "train loss:0.017869413602750815\n",
      "train loss:0.018703499899567586\n",
      "train loss:0.011760018201337217\n",
      "train loss:0.22612839340166166\n",
      "train loss:0.0277210529277929\n",
      "train loss:0.01502805379321506\n",
      "train loss:0.010598399156774262\n",
      "train loss:0.013371631776541331\n",
      "train loss:0.018855298267168495\n",
      "train loss:0.04377366339580671\n",
      "train loss:0.01697222633121228\n",
      "train loss:0.007259631515043282\n",
      "train loss:0.02651473512439598\n",
      "train loss:0.010533038268406864\n",
      "train loss:0.05492163304755254\n",
      "train loss:0.011080429618246233\n",
      "train loss:0.009692801721720266\n",
      "train loss:0.019781080740979215\n",
      "train loss:0.060157776382793814\n",
      "train loss:0.028017040467537658\n",
      "train loss:0.07767470191999613\n",
      "train loss:0.010406566442459552\n",
      "train loss:0.01829961779158706\n",
      "train loss:0.0188219601734381\n",
      "train loss:0.03908132997613728\n",
      "train loss:0.004872255193705152\n",
      "train loss:0.022532806954098886\n",
      "train loss:0.019531373633512053\n",
      "train loss:0.019872169731419132\n",
      "train loss:0.005529420654200704\n",
      "train loss:0.05004297766013254\n",
      "train loss:0.02160873438495032\n",
      "train loss:0.030539774303515926\n",
      "train loss:0.0180138819392053\n",
      "train loss:0.019739271646066738\n",
      "train loss:0.07794775835715337\n",
      "train loss:0.030206465857523308\n",
      "train loss:0.028518862317862163\n",
      "train loss:0.07122350356299474\n",
      "train loss:0.0742255178380701\n",
      "train loss:0.00556920284511243\n",
      "train loss:0.012730492888623528\n",
      "train loss:0.023197200801533216\n",
      "train loss:0.03460973954602085\n",
      "train loss:0.09923635932887624\n",
      "train loss:0.014515104723314149\n",
      "train loss:0.009579466093824185\n",
      "train loss:0.03919549471075584\n",
      "train loss:0.042740535977581776\n",
      "train loss:0.010841597918083761\n",
      "train loss:0.024861818205708618\n",
      "train loss:0.014783089693272945\n",
      "train loss:0.022046228958032005\n",
      "train loss:0.09567076238066935\n",
      "train loss:0.037152070482845787\n",
      "train loss:0.013155321417425744\n",
      "train loss:0.01480818319117716\n",
      "train loss:0.048810891615269074\n",
      "train loss:0.005603781268957502\n",
      "train loss:0.013498295168194386\n",
      "train loss:0.02717137589324405\n",
      "train loss:0.04140263259754631\n",
      "train loss:0.014792420684169336\n",
      "train loss:0.003187434508475957\n",
      "train loss:0.02489138339866266\n",
      "train loss:0.009154632295623372\n",
      "train loss:0.011097346134615485\n",
      "train loss:0.034181736428922874\n",
      "train loss:0.019692139862178406\n",
      "train loss:0.007097809782257856\n",
      "train loss:0.014913656554149154\n",
      "train loss:0.10130928505447613\n",
      "train loss:0.060760935360524716\n",
      "train loss:0.09428525450264592\n",
      "train loss:0.005038120005205261\n",
      "train loss:0.005932160640888564\n",
      "train loss:0.02284725227301833\n",
      "train loss:0.006484670938095124\n",
      "train loss:0.02352994879986933\n",
      "train loss:0.015207016229837656\n",
      "train loss:0.03410203272714778\n",
      "train loss:0.028211536949763652\n",
      "train loss:0.020106765056763964\n",
      "train loss:0.020388325182894927\n",
      "train loss:0.023735038858384776\n",
      "train loss:0.009682193820860071\n",
      "train loss:0.043558490773585055\n",
      "train loss:0.039562679143358474\n",
      "train loss:0.02074539822005597\n",
      "train loss:0.07111028520731687\n",
      "train loss:0.015473040662839437\n",
      "train loss:0.017819193449491972\n",
      "train loss:0.017291564542251926\n",
      "train loss:0.01496246187389628\n",
      "train loss:0.0327016521910812\n",
      "train loss:0.0044088083687650196\n",
      "train loss:0.019172813333831182\n",
      "train loss:0.024990244813310532\n",
      "train loss:0.03274587813532383\n",
      "train loss:0.01566960601931147\n",
      "train loss:0.03702688074573861\n",
      "train loss:0.07055104752887738\n",
      "train loss:0.05948125511557369\n",
      "train loss:0.004053585234009336\n",
      "train loss:0.06485829692919604\n",
      "train loss:0.1101238423342604\n",
      "train loss:0.008114681552602433\n",
      "train loss:0.023803596489373958\n",
      "train loss:0.05383260395667419\n",
      "train loss:0.027973962677866046\n",
      "train loss:0.06520145125333827\n",
      "train loss:0.011280844029378194\n",
      "train loss:0.01672376319071426\n",
      "train loss:0.05842483331232238\n",
      "train loss:0.016432241037162117\n",
      "train loss:0.03895974704739458\n",
      "train loss:0.03182267322492203\n",
      "train loss:0.037728351877948395\n",
      "train loss:0.036045359035526164\n",
      "train loss:0.09848939005048109\n",
      "train loss:0.012749147143386475\n",
      "train loss:0.022507739612538585\n",
      "train loss:0.014063171330132669\n",
      "train loss:0.013341454262504791\n",
      "train loss:0.013910859803687448\n",
      "train loss:0.011033894201858472\n",
      "train loss:0.025690898952465426\n",
      "train loss:0.025452521811418646\n",
      "train loss:0.049488521790486135\n",
      "train loss:0.008323130059450724\n",
      "train loss:0.023786876804957658\n",
      "train loss:0.012481647101262454\n",
      "train loss:0.016121429121223593\n",
      "train loss:0.00977343653550742\n",
      "train loss:0.061093700683613535\n",
      "train loss:0.009839910405566648\n",
      "train loss:0.0200513535012346\n",
      "train loss:0.014120954410959159\n",
      "train loss:0.00576725844653904\n",
      "train loss:0.02595999358150327\n",
      "train loss:0.006690293828122822\n",
      "train loss:0.03078765299248125\n",
      "train loss:0.0567061082918878\n",
      "train loss:0.012709555150242333\n",
      "train loss:0.006810495644273764\n",
      "train loss:0.0041087589266597955\n",
      "train loss:0.01209424850122443\n",
      "train loss:0.012913168375133685\n",
      "train loss:0.009720957409525062\n",
      "train loss:0.004632932438455532\n",
      "train loss:0.029949816600887486\n",
      "train loss:0.015728590774422166\n",
      "train loss:0.009657766591088725\n",
      "train loss:0.009071225429798671\n",
      "train loss:0.03988675748785319\n",
      "train loss:0.00879345558053699\n",
      "train loss:0.00847307770879276\n",
      "train loss:0.0345436956724968\n",
      "train loss:0.08685486255268982\n",
      "train loss:0.004150865113345\n",
      "train loss:0.008208352676076988\n",
      "train loss:0.013181447919487676\n",
      "train loss:0.008953167723613136\n",
      "train loss:0.027855685858300384\n",
      "train loss:0.009186394653790253\n",
      "train loss:0.016465208761437967\n",
      "train loss:0.03381822779840724\n",
      "train loss:0.07416462673773883\n",
      "train loss:0.0061671112176079155\n",
      "train loss:0.008420716927148906\n",
      "train loss:0.013628143781296802\n",
      "train loss:0.010796326414404995\n",
      "train loss:0.005716682400294754\n",
      "train loss:0.013068363058029114\n",
      "train loss:0.008003744992685077\n",
      "train loss:0.053507582640520045\n",
      "train loss:0.05295668256414178\n",
      "train loss:0.01173264725092318\n",
      "train loss:0.061576216158981595\n",
      "train loss:0.01923007546159355\n",
      "train loss:0.06815182653113498\n",
      "train loss:0.02763819962555527\n",
      "train loss:0.011162544884532406\n",
      "train loss:0.025413420715842024\n",
      "train loss:0.017343331399368198\n",
      "train loss:0.03233300886178811\n",
      "train loss:0.026301058845934085\n",
      "train loss:0.02481509819652271\n",
      "train loss:0.023270020595310404\n",
      "train loss:0.03313009596034392\n",
      "train loss:0.021109361337214003\n",
      "train loss:0.012839550073681346\n",
      "train loss:0.045631047429040575\n",
      "train loss:0.017684441124450494\n",
      "train loss:0.00939895242425072\n",
      "train loss:0.026208130589693672\n",
      "train loss:0.025399924627194467\n",
      "train loss:0.007331959788933484\n",
      "train loss:0.013345434325612011\n",
      "train loss:0.05148700631409989\n",
      "train loss:0.030487984180418724\n",
      "train loss:0.014052445737239721\n",
      "train loss:0.01836792700332358\n",
      "train loss:0.07162038634090116\n",
      "train loss:0.0940715116419193\n",
      "train loss:0.017479456189274746\n",
      "train loss:0.015161679501704089\n",
      "train loss:0.018924306170222113\n",
      "train loss:0.014527495466093658\n",
      "train loss:0.02027326801217795\n",
      "train loss:0.017909861928863857\n",
      "train loss:0.018834650285510585\n",
      "train loss:0.017505854698633957\n",
      "train loss:0.030550051983486787\n",
      "train loss:0.00848439561595455\n",
      "train loss:0.01710209217522717\n",
      "train loss:0.017694603207100687\n",
      "train loss:0.014765469472145527\n",
      "train loss:0.010709684391189543\n",
      "train loss:0.00959089393695902\n",
      "train loss:0.03432351762450429\n",
      "train loss:0.13541387222414583\n",
      "train loss:0.02964111038168526\n",
      "train loss:0.007733049942450367\n",
      "train loss:0.014393410167036274\n",
      "train loss:0.02415777456639855\n",
      "train loss:0.003577164866302932\n",
      "train loss:0.01921278788443532\n",
      "train loss:0.007048901961135962\n",
      "train loss:0.007082466335172693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.049568545040720516\n",
      "train loss:0.03506940140956806\n",
      "train loss:0.009092544911279553\n",
      "train loss:0.013728593044387978\n",
      "train loss:0.01797515002496655\n",
      "train loss:0.027236551114688125\n",
      "train loss:0.009083202427825397\n",
      "train loss:0.004390400039364438\n",
      "train loss:0.010970204135950101\n",
      "train loss:0.017988221551306856\n",
      "train loss:0.02455877488696532\n",
      "train loss:0.045524451327732\n",
      "train loss:0.014437185666253304\n",
      "train loss:0.007912489086804123\n",
      "train loss:0.011897081008969603\n",
      "train loss:0.010332831761027535\n",
      "train loss:0.033908656881497336\n",
      "train loss:0.029090019766556764\n",
      "train loss:0.013368192286804486\n",
      "train loss:0.024368822103519875\n",
      "train loss:0.013200651029677893\n",
      "train loss:0.037964839378637906\n",
      "train loss:0.020487673765068687\n",
      "train loss:0.003348627100325684\n",
      "train loss:0.012980781390493624\n",
      "train loss:0.04012238502976919\n",
      "train loss:0.021483961287487162\n",
      "train loss:0.04077626636949164\n",
      "train loss:0.007564458774673259\n",
      "train loss:0.010364240181534987\n",
      "train loss:0.012178109860543393\n",
      "train loss:0.008976678510538412\n",
      "train loss:0.06705506999841865\n",
      "train loss:0.01294145955170751\n",
      "train loss:0.029552095634209644\n",
      "train loss:0.05850844070557741\n",
      "train loss:0.02404021589954546\n",
      "train loss:0.012501155362750323\n",
      "train loss:0.055507156706857\n",
      "train loss:0.010585215492068194\n",
      "train loss:0.012461520419595458\n",
      "train loss:0.018059582238313956\n",
      "train loss:0.01995931478628078\n",
      "train loss:0.08526206324422031\n",
      "train loss:0.004883461326866542\n",
      "train loss:0.006457743579295864\n",
      "train loss:0.023829842763182386\n",
      "train loss:0.09047019699092491\n",
      "train loss:0.0499212734853426\n",
      "train loss:0.0033884914263177224\n",
      "train loss:0.025909075576791483\n",
      "train loss:0.03714059444365104\n",
      "train loss:0.005283263951160799\n",
      "train loss:0.009214743831005368\n",
      "train loss:0.03644224269870852\n",
      "train loss:0.03787881085164377\n",
      "train loss:0.004359051051634069\n",
      "train loss:0.019278665751187248\n",
      "train loss:0.014386137868095124\n",
      "train loss:0.013532982582191398\n",
      "train loss:0.00964965019414574\n",
      "train loss:0.022774610092412117\n",
      "train loss:0.029329701348996942\n",
      "train loss:0.030892316145669684\n",
      "train loss:0.04108233994298205\n",
      "train loss:0.027007548693774787\n",
      "train loss:0.010408800751515939\n",
      "train loss:0.025702384250179053\n",
      "train loss:0.004566523379809394\n",
      "train loss:0.02038702964905575\n",
      "train loss:0.004745963318194388\n",
      "train loss:0.010415511437511162\n",
      "train loss:0.01548201119215466\n",
      "train loss:0.011657863363954947\n",
      "train loss:0.01552188105274311\n",
      "train loss:0.019658186061689273\n",
      "train loss:0.08850222702509548\n",
      "train loss:0.0020134089180727645\n",
      "train loss:0.004680674065869888\n",
      "train loss:0.02114893003389064\n",
      "train loss:0.0017002610862739951\n",
      "train loss:0.010350821111979358\n",
      "train loss:0.014458755371633042\n",
      "train loss:0.02390230299987115\n",
      "train loss:0.0061737455208564825\n",
      "train loss:0.020381346378643462\n",
      "train loss:0.007806613858857915\n",
      "train loss:0.015669245824232087\n",
      "train loss:0.006484049279135371\n",
      "train loss:0.02875963144173028\n",
      "train loss:0.04046107203903353\n",
      "train loss:0.009200242620637426\n",
      "train loss:0.057557403276680186\n",
      "train loss:0.015110509690217171\n",
      "train loss:0.005645966915197071\n",
      "train loss:0.03235814273000473\n",
      "train loss:0.01851808207916207\n",
      "train loss:0.022024282772768286\n",
      "train loss:0.011103874857407204\n",
      "train loss:0.026087811700279094\n",
      "train loss:0.02391927886007193\n",
      "train loss:0.006409053859069951\n",
      "train loss:0.018385729458643786\n",
      "train loss:0.015682698967961442\n",
      "train loss:0.00380431252266512\n",
      "train loss:0.011845337651420927\n",
      "train loss:0.015167126118361384\n",
      "train loss:0.01175576268359521\n",
      "train loss:0.012359045896320245\n",
      "train loss:0.007202849595904105\n",
      "train loss:0.001463232343403114\n",
      "train loss:0.047728940987677604\n",
      "train loss:0.01883999916988965\n",
      "train loss:0.023363828850165906\n",
      "train loss:0.01714616881505655\n",
      "train loss:0.009832015105962858\n",
      "train loss:0.02214883077791599\n",
      "train loss:0.019320592357630343\n",
      "train loss:0.010211562416603816\n",
      "train loss:0.04623380002789812\n",
      "train loss:0.004995015861065089\n",
      "train loss:0.011342316701443367\n",
      "train loss:0.0954870189527761\n",
      "train loss:0.00948486096640785\n",
      "train loss:0.01695475653630558\n",
      "train loss:0.023236668558039138\n",
      "train loss:0.018427437631721454\n",
      "train loss:0.017301631595202885\n",
      "train loss:0.009337937808569957\n",
      "train loss:0.020911637308903473\n",
      "train loss:0.08407673148728648\n",
      "train loss:0.02254554259359499\n",
      "train loss:0.014173180594616763\n",
      "train loss:0.01801175721065048\n",
      "train loss:0.008446296465372927\n",
      "train loss:0.061405992331610204\n",
      "train loss:0.02328760242923382\n",
      "train loss:0.018471824151634647\n",
      "train loss:0.0022759477489839564\n",
      "train loss:0.03633059238426561\n",
      "train loss:0.017321144996880335\n",
      "train loss:0.014424679525941498\n",
      "train loss:0.012491350253495383\n",
      "train loss:0.023041677489207383\n",
      "train loss:0.015700059877008232\n",
      "train loss:0.023624997410752267\n",
      "train loss:0.018299801244720776\n",
      "train loss:0.014679230926772972\n",
      "train loss:0.03414104090770052\n",
      "train loss:0.006807629656607561\n",
      "train loss:0.006888702051455392\n",
      "train loss:0.008708413111815186\n",
      "train loss:0.0041773047459242405\n",
      "train loss:0.004194210181434621\n",
      "train loss:0.016123888179081922\n",
      "train loss:0.007427189679702205\n",
      "train loss:0.006220015614110301\n",
      "train loss:0.01421394744338492\n",
      "train loss:0.011195924096254884\n",
      "train loss:0.04021624413399493\n",
      "train loss:0.04452106385959878\n",
      "train loss:0.003972339568175985\n",
      "train loss:0.01372733372308281\n",
      "train loss:0.03179908283977375\n",
      "train loss:0.03229935918627577\n",
      "train loss:0.03771670845776859\n",
      "train loss:0.016231105323818707\n",
      "train loss:0.026389616085193777\n",
      "train loss:0.019560082030115066\n",
      "train loss:0.006486694421261607\n",
      "train loss:0.009155956021672454\n",
      "train loss:0.010001182565881346\n",
      "train loss:0.018132557051317996\n",
      "train loss:0.028176293208003148\n",
      "train loss:0.024678578689238142\n",
      "train loss:0.01220765904942966\n",
      "train loss:0.03255336648780561\n",
      "train loss:0.01567040206534653\n",
      "train loss:0.01565265137382661\n",
      "train loss:0.006098685620735677\n",
      "train loss:0.004714024672966645\n",
      "train loss:0.006683193984431307\n",
      "train loss:0.0030479645940608914\n",
      "train loss:0.004780204930581082\n",
      "train loss:0.027876560700708906\n",
      "train loss:0.030817183130158143\n",
      "train loss:0.011283917992727916\n",
      "train loss:0.00509759457160958\n",
      "=== epoch:7, train acc:0.988, test acc:0.985 ===\n",
      "train loss:0.03217780080624157\n",
      "train loss:0.053490540506661875\n",
      "train loss:0.012314523123077719\n",
      "train loss:0.009657626895918894\n",
      "train loss:0.022681858056335727\n",
      "train loss:0.023450694505250766\n",
      "train loss:0.0035296202389851895\n",
      "train loss:0.020535950668472996\n",
      "train loss:0.055028258492100905\n",
      "train loss:0.0029343277036947345\n",
      "train loss:0.00886650928171911\n",
      "train loss:0.0016182194933482981\n",
      "train loss:0.013152438764098176\n",
      "train loss:0.006467453749434709\n",
      "train loss:0.018173041928493075\n",
      "train loss:0.0119349191679513\n",
      "train loss:0.03485106590778035\n",
      "train loss:0.016563035897622657\n",
      "train loss:0.013088707921032077\n",
      "train loss:0.07512731464956264\n",
      "train loss:0.013659831333677016\n",
      "train loss:0.011374365797567378\n",
      "train loss:0.010741215038551489\n",
      "train loss:0.004131954632125249\n",
      "train loss:0.02809295550954357\n",
      "train loss:0.011222624706208812\n",
      "train loss:0.002666106758082748\n",
      "train loss:0.007099605419710181\n",
      "train loss:0.02290030980726386\n",
      "train loss:0.01583911017149462\n",
      "train loss:0.019321688555900052\n",
      "train loss:0.009464837008137026\n",
      "train loss:0.007962375280834627\n",
      "train loss:0.01906100382373811\n",
      "train loss:0.010648559798209327\n",
      "train loss:0.008736991363323036\n",
      "train loss:0.006407677764546585\n",
      "train loss:0.023554689675787603\n",
      "train loss:0.012599433479829588\n",
      "train loss:0.023279492684584454\n",
      "train loss:0.015408699883186074\n",
      "train loss:0.004662790247158083\n",
      "train loss:0.010071642228584888\n",
      "train loss:0.021979710058093894\n",
      "train loss:0.04109173830366102\n",
      "train loss:0.028368087268029155\n",
      "train loss:0.014828298703782439\n",
      "train loss:0.004708563028956621\n",
      "train loss:0.038262085941416696\n",
      "train loss:0.007461985921529702\n",
      "train loss:0.02263866174987138\n",
      "train loss:0.008476963376539142\n",
      "train loss:0.009052493576788967\n",
      "train loss:0.009023066314283646\n",
      "train loss:0.005509296247773391\n",
      "train loss:0.05957100608658286\n",
      "train loss:0.006535307181181408\n",
      "train loss:0.015562985477678488\n",
      "train loss:0.009783971331584434\n",
      "train loss:0.012531345710843703\n",
      "train loss:0.010546615994729128\n",
      "train loss:0.12734512660067318\n",
      "train loss:0.005143263101717623\n",
      "train loss:0.006044767381278243\n",
      "train loss:0.0703311025136598\n",
      "train loss:0.018980223107748412\n",
      "train loss:0.016536762586882595\n",
      "train loss:0.028930665881768194\n",
      "train loss:0.010895270581550041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.019735736930211915\n",
      "train loss:0.02218800171593642\n",
      "train loss:0.004432560992995642\n",
      "train loss:0.002566921148360265\n",
      "train loss:0.004691392683455469\n",
      "train loss:0.053465865779918215\n",
      "train loss:0.0562284715670087\n",
      "train loss:0.011179167539396519\n",
      "train loss:0.005446641037974773\n",
      "train loss:0.006373476734961205\n",
      "train loss:0.08446641292452632\n",
      "train loss:0.004914695154237331\n",
      "train loss:0.018474219062926785\n",
      "train loss:0.007071645265228478\n",
      "train loss:0.013272472745737184\n",
      "train loss:0.03427966038215355\n",
      "train loss:0.011236308532197852\n",
      "train loss:0.01126575154920966\n",
      "train loss:0.05957284227837807\n",
      "train loss:0.014908324929839298\n",
      "train loss:0.008887882602163203\n",
      "train loss:0.005992036213510346\n",
      "train loss:0.005823655847766506\n",
      "train loss:0.00869260204441944\n",
      "train loss:0.018179911310452327\n",
      "train loss:0.017927189331071545\n",
      "train loss:0.005697821942196036\n",
      "train loss:0.009446984911468661\n",
      "train loss:0.01613432923542139\n",
      "train loss:0.01754674500665869\n",
      "train loss:0.010177567873061826\n",
      "train loss:0.019867729698362244\n",
      "train loss:0.007534152107080499\n",
      "train loss:0.010158636996272478\n",
      "train loss:0.01322106454789723\n",
      "train loss:0.004743139834412251\n",
      "train loss:0.0384494298696874\n",
      "train loss:0.007515619386609376\n",
      "train loss:0.00786466148243999\n",
      "train loss:0.00800517156564088\n",
      "train loss:0.0299810977672212\n",
      "train loss:0.02865742235416882\n",
      "train loss:0.015554812719013038\n",
      "train loss:0.027613222807556244\n",
      "train loss:0.0021919286777578114\n",
      "train loss:0.024833311329155484\n",
      "train loss:0.002578866712295184\n",
      "train loss:0.012685956393888366\n",
      "train loss:0.008077079610492682\n",
      "train loss:0.0032481529248888957\n",
      "train loss:0.004618812635162156\n",
      "train loss:0.06467916272355001\n",
      "train loss:0.025672841344021095\n",
      "train loss:0.007833201036947887\n",
      "train loss:0.011852893425212145\n",
      "train loss:0.0383084322086599\n",
      "train loss:0.0012734532552446122\n",
      "train loss:0.011299265260139447\n",
      "train loss:0.028479936996509504\n",
      "train loss:0.009155182305268185\n",
      "train loss:0.026601676751294344\n",
      "train loss:0.011823845461498998\n",
      "train loss:0.026629786249575068\n",
      "train loss:0.010113900369035887\n",
      "train loss:0.007235124668271367\n",
      "train loss:0.005124620629730521\n",
      "train loss:0.006153532965336764\n",
      "train loss:0.04601422593028942\n",
      "train loss:0.006047840236363032\n",
      "train loss:0.006938767242723652\n",
      "train loss:0.008494763799483654\n",
      "train loss:0.004630453149025321\n",
      "train loss:0.10128028600876482\n",
      "train loss:0.002276263161577258\n",
      "train loss:0.016357956775133672\n",
      "train loss:0.010469819624260177\n",
      "train loss:0.007459317432515152\n",
      "train loss:0.007222843828025187\n",
      "train loss:0.054179317880316935\n",
      "train loss:0.002810568191454208\n",
      "train loss:0.010042966658336512\n",
      "train loss:0.07669660889472023\n",
      "train loss:0.01983942439653401\n",
      "train loss:0.0059993776223592685\n",
      "train loss:0.0020105403738135317\n",
      "train loss:0.013846744067056476\n",
      "train loss:0.0044679472335177935\n",
      "train loss:0.03728766948278185\n",
      "train loss:0.02548035586741031\n",
      "train loss:0.0012466307378427347\n",
      "train loss:0.00787500693125261\n",
      "train loss:0.0067192443610189535\n",
      "train loss:0.006761381612696417\n",
      "train loss:0.007918136508069022\n",
      "train loss:0.02347713777259486\n",
      "train loss:0.007964465002035683\n",
      "train loss:0.004598120954605089\n",
      "train loss:0.007671918024732077\n",
      "train loss:0.014047359391779033\n",
      "train loss:0.006275989651383162\n",
      "train loss:0.08149218352407583\n",
      "train loss:0.013207532195676998\n",
      "train loss:0.031498124896536445\n",
      "train loss:0.009109505046259722\n",
      "train loss:0.008635177152793104\n",
      "train loss:0.009918962997908277\n",
      "train loss:0.005249467143059945\n",
      "train loss:0.04564210788643029\n",
      "train loss:0.007106185331505498\n",
      "train loss:0.004734547190416408\n",
      "train loss:0.06715350807260485\n",
      "train loss:0.028874177197064133\n",
      "train loss:0.02096388550988543\n",
      "train loss:0.02228592614467493\n",
      "train loss:0.04228549463041285\n",
      "train loss:0.021353172932760702\n",
      "train loss:0.004131256271170452\n",
      "train loss:0.005016538616382838\n",
      "train loss:0.03776402957416118\n",
      "train loss:0.006538679639306608\n",
      "train loss:0.02747634064857535\n",
      "train loss:0.033416711169440776\n",
      "train loss:0.025591058773667012\n",
      "train loss:0.0019468910344768212\n",
      "train loss:0.005011053441742272\n",
      "train loss:0.016788645740653616\n",
      "train loss:0.015535056050486305\n",
      "train loss:0.009266121200982419\n",
      "train loss:0.016662984108363157\n",
      "train loss:0.004347235426046027\n",
      "train loss:0.003877289433166426\n",
      "train loss:0.028316528784584776\n",
      "train loss:0.032578103966684376\n",
      "train loss:0.04233334061790081\n",
      "train loss:0.006966860782764814\n",
      "train loss:0.003942934967988015\n",
      "train loss:0.024335934968004035\n",
      "train loss:0.01383085149505173\n",
      "train loss:0.010652481573124374\n",
      "train loss:0.010822424437139487\n",
      "train loss:0.013649134349325642\n",
      "train loss:0.009049527833463989\n",
      "train loss:0.008711952189326258\n",
      "train loss:0.015043085961306126\n",
      "train loss:0.019172481783270027\n",
      "train loss:0.0024647741811661852\n",
      "train loss:0.012710374422420458\n",
      "train loss:0.002358946116764156\n",
      "train loss:0.006164801407722439\n",
      "train loss:0.002185831145598228\n",
      "train loss:0.003178570553766457\n",
      "train loss:0.004848607950556977\n",
      "train loss:0.00999994517764522\n",
      "train loss:0.005578483224783906\n",
      "train loss:0.032298137707654016\n",
      "train loss:0.01784115058893596\n",
      "train loss:0.0019654331184654817\n",
      "train loss:0.017058528936358598\n",
      "train loss:0.009930204871925119\n",
      "train loss:0.007856292225329086\n",
      "train loss:0.01934684202944852\n",
      "train loss:0.06148855787848729\n",
      "train loss:0.0018733122091551214\n",
      "train loss:0.01284462135676916\n",
      "train loss:0.00918636628444151\n",
      "train loss:0.007096235275783278\n",
      "train loss:0.006089721865374256\n",
      "train loss:0.010206185695685745\n",
      "train loss:0.003411738284128582\n",
      "train loss:0.00997664215106549\n",
      "train loss:0.024407060931110548\n",
      "train loss:0.004311266814802659\n",
      "train loss:0.0025455257401835237\n",
      "train loss:0.015007670885584832\n",
      "train loss:0.00468646609011902\n",
      "train loss:0.023648974826973274\n",
      "train loss:0.006818651863800987\n",
      "train loss:0.03959706607963902\n",
      "train loss:0.01148292890513693\n",
      "train loss:0.04624079855705989\n",
      "train loss:0.013416220046762455\n",
      "train loss:0.03740441123317399\n",
      "train loss:0.00715038694052603\n",
      "train loss:0.025091491518012515\n",
      "train loss:0.04508565843247166\n",
      "train loss:0.060892043264906104\n",
      "train loss:0.0022544873015950518\n",
      "train loss:0.0041197174650856126\n",
      "train loss:0.014628467972827013\n",
      "train loss:0.011138936732442173\n",
      "train loss:0.01959204564896976\n",
      "train loss:0.009038286419063589\n",
      "train loss:0.009195385191041183\n",
      "train loss:0.0021602152888867956\n",
      "train loss:0.0066216715528466\n",
      "train loss:0.026290539204552196\n",
      "train loss:0.008311181494034835\n",
      "train loss:0.033194717106841264\n",
      "train loss:0.0036049552505879956\n",
      "train loss:0.005715973913621072\n",
      "train loss:0.025651190984132256\n",
      "train loss:0.005136552809181073\n",
      "train loss:0.0025805577640577526\n",
      "train loss:0.010368293728417013\n",
      "train loss:0.009122030400824169\n",
      "train loss:0.023504521625220175\n",
      "train loss:0.010290750382401157\n",
      "train loss:0.0016883899741510318\n",
      "train loss:0.006954242041639276\n",
      "train loss:0.006843618982745671\n",
      "train loss:0.01871033543752052\n",
      "train loss:0.01564210861999415\n",
      "train loss:0.017692056150657946\n",
      "train loss:0.0023924289548666474\n",
      "train loss:0.008442921277725295\n",
      "train loss:0.02443057017642767\n",
      "train loss:0.007167392022723113\n",
      "train loss:0.013984935736981468\n",
      "train loss:0.04086443076206542\n",
      "train loss:0.012758467264015591\n",
      "train loss:0.06996981540065318\n",
      "train loss:0.01788557559476296\n",
      "train loss:0.00885541382040868\n",
      "train loss:0.03898537841468777\n",
      "train loss:0.01647766379340125\n",
      "train loss:0.013331020450616592\n",
      "train loss:0.006417864773646925\n",
      "train loss:0.05515077947405211\n",
      "train loss:0.017021276962757355\n",
      "train loss:0.008864471031568864\n",
      "train loss:0.003791021863673132\n",
      "train loss:0.04139298240400913\n",
      "train loss:0.008235424396373654\n",
      "train loss:0.014492182539607046\n",
      "train loss:0.00244094604299771\n",
      "train loss:0.01016016444922259\n",
      "train loss:0.030565837904913788\n",
      "train loss:0.008874578487173858\n",
      "train loss:0.0436416024719149\n",
      "train loss:0.053148662301855935\n",
      "train loss:0.005448209649536278\n",
      "train loss:0.015182251423684723\n",
      "train loss:0.006707197470472077\n",
      "train loss:0.02263786195994777\n",
      "train loss:0.022600735087786462\n",
      "train loss:0.04781208622233677\n",
      "train loss:0.0058356506787349514\n",
      "train loss:0.005089713604769885\n",
      "train loss:0.020381780335139345\n",
      "train loss:0.0021376082410148652\n",
      "train loss:0.010748565353371507\n",
      "train loss:0.007651478945682101\n",
      "train loss:0.007775065934677488\n",
      "train loss:0.018442199599746193\n",
      "train loss:0.020872031274187103\n",
      "train loss:0.013221671342677146\n",
      "train loss:0.0032276746566342316\n",
      "train loss:0.02416553828735332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.048309712607472646\n",
      "train loss:0.007106780195307415\n",
      "train loss:0.011650718584900622\n",
      "train loss:0.010798421152776032\n",
      "train loss:0.02546912137704815\n",
      "train loss:0.010904606052975531\n",
      "train loss:0.027051602832816397\n",
      "train loss:0.04346996792016679\n",
      "train loss:0.030895743174428635\n",
      "train loss:0.030562641696395616\n",
      "train loss:0.10308489955125115\n",
      "train loss:0.008740171173631\n",
      "train loss:0.04642536876106756\n",
      "train loss:0.008571411864690959\n",
      "train loss:0.0075523692797205555\n",
      "train loss:0.0012993212859257288\n",
      "train loss:0.055005272755130584\n",
      "train loss:0.052041962932152463\n",
      "train loss:0.032444172432546214\n",
      "train loss:0.01700337247521641\n",
      "train loss:0.014852192571912589\n",
      "train loss:0.0392627703569453\n",
      "train loss:0.10096051985257364\n",
      "train loss:0.005705056092633798\n",
      "train loss:0.07616695354994099\n",
      "train loss:0.009644872116271533\n",
      "train loss:0.010528658181131734\n",
      "train loss:0.011789426397728625\n",
      "train loss:0.013341392965401091\n",
      "train loss:0.024333334794143128\n",
      "train loss:0.01973504956107409\n",
      "train loss:0.01383725717514531\n",
      "train loss:0.03091577562218127\n",
      "train loss:0.04326628624687928\n",
      "train loss:0.029730780629492658\n",
      "train loss:0.017032443855720513\n",
      "train loss:0.02537672852705803\n",
      "train loss:0.12339588572652975\n",
      "train loss:0.016009447900168252\n",
      "train loss:0.05592580312855281\n",
      "train loss:0.012202689670282974\n",
      "train loss:0.02344200958828557\n",
      "train loss:0.010332349867578581\n",
      "train loss:0.016720252421530458\n",
      "train loss:0.01366126800974956\n",
      "train loss:0.023945123896294912\n",
      "train loss:0.00759778838722676\n",
      "train loss:0.040655302860154535\n",
      "train loss:0.011013988901503123\n",
      "train loss:0.013115503879323061\n",
      "train loss:0.005219294691803846\n",
      "train loss:0.006956105067112046\n",
      "train loss:0.007023203666442043\n",
      "train loss:0.006199278178645208\n",
      "train loss:0.03217371414576222\n",
      "train loss:0.03048289974311942\n",
      "train loss:0.03684150213382102\n",
      "train loss:0.0028780852975331863\n",
      "train loss:0.005901454265450645\n",
      "train loss:0.0251008548693809\n",
      "train loss:0.00793119419147612\n",
      "train loss:0.00923559951576239\n",
      "train loss:0.017504619964156656\n",
      "train loss:0.013637959871025562\n",
      "train loss:0.03360441627424943\n",
      "train loss:0.00733476678575657\n",
      "train loss:0.014779924217234633\n",
      "train loss:0.005469195503024109\n",
      "train loss:0.014327627095837204\n",
      "train loss:0.009140205796394385\n",
      "train loss:0.032938877220418154\n",
      "train loss:0.08304171005283158\n",
      "train loss:0.024405277924861784\n",
      "train loss:0.007378291582120131\n",
      "train loss:0.02034693243812792\n",
      "train loss:0.008155040677254047\n",
      "train loss:0.022973767990587306\n",
      "train loss:0.0134204720785178\n",
      "train loss:0.005762063985065029\n",
      "train loss:0.01966627402763413\n",
      "train loss:0.00870726894277975\n",
      "train loss:0.023038453520370306\n",
      "train loss:0.028801415621487556\n",
      "train loss:0.0026516075114347937\n",
      "train loss:0.008063940174836207\n",
      "train loss:0.014832062900065274\n",
      "train loss:0.004029243761742841\n",
      "train loss:0.026538800318226318\n",
      "train loss:0.003893017298604332\n",
      "train loss:0.013194083092080904\n",
      "train loss:0.0021715817456559997\n",
      "train loss:0.0441600810332037\n",
      "train loss:0.002082364983005746\n",
      "train loss:0.02211615258285228\n",
      "train loss:0.012349755974612525\n",
      "train loss:0.004888058927273683\n",
      "train loss:0.004790536146471214\n",
      "train loss:0.014363135687031327\n",
      "train loss:0.004951017129424841\n",
      "train loss:0.04033721215231057\n",
      "train loss:0.008345103049526372\n",
      "train loss:0.003644382517143572\n",
      "train loss:0.025570158505043305\n",
      "train loss:0.007090635272272222\n",
      "train loss:0.018009137751328588\n",
      "train loss:0.004562155493986393\n",
      "train loss:0.007307937772525791\n",
      "train loss:0.05098184127679192\n",
      "train loss:0.005729632945199217\n",
      "train loss:0.01260489629378632\n",
      "train loss:0.04464389802682439\n",
      "train loss:0.05862151919542251\n",
      "train loss:0.013704160099126648\n",
      "train loss:0.04423231073238529\n",
      "train loss:0.005271978774033083\n",
      "train loss:0.02671931247721621\n",
      "train loss:0.03518748306042191\n",
      "train loss:0.015377424657800266\n",
      "train loss:0.021393220105929624\n",
      "train loss:0.0038750782413329563\n",
      "train loss:0.0077131323954263645\n",
      "train loss:0.01032356011013274\n",
      "train loss:0.008723544976755987\n",
      "train loss:0.00412184605246481\n",
      "train loss:0.014641622221162527\n",
      "train loss:0.03088045632399669\n",
      "train loss:0.015998965172566257\n",
      "train loss:0.009218380951250545\n",
      "train loss:0.01042805826448993\n",
      "train loss:0.022086798733418962\n",
      "train loss:0.0032331232479005734\n",
      "train loss:0.003376163850864267\n",
      "train loss:0.013215934214627283\n",
      "train loss:0.00772014002298563\n",
      "train loss:0.01118684229047447\n",
      "train loss:0.0024838810354404564\n",
      "train loss:0.02946405697300035\n",
      "train loss:0.020970162925396187\n",
      "train loss:0.009755223665611237\n",
      "train loss:0.005322988979670426\n",
      "train loss:0.011797200844432743\n",
      "train loss:0.03713555390210724\n",
      "train loss:0.00945095984699004\n",
      "train loss:0.05390023239684446\n",
      "train loss:0.009537687194480959\n",
      "train loss:0.018631394414093106\n",
      "train loss:0.04055971206164649\n",
      "train loss:0.010561630653987502\n",
      "train loss:0.016072868150847054\n",
      "train loss:0.0039117904454873224\n",
      "train loss:0.017343876225552775\n",
      "train loss:0.004802401840591425\n",
      "train loss:0.013930802447792262\n",
      "train loss:0.001430317482679404\n",
      "train loss:0.012230819728987768\n",
      "train loss:0.03546281674456034\n",
      "train loss:0.008812974834468848\n",
      "train loss:0.014140836222370296\n",
      "train loss:0.012488256453904167\n",
      "train loss:0.0034222800706529477\n",
      "train loss:0.005886522428822636\n",
      "train loss:0.006433704086210059\n",
      "train loss:0.029501992473162545\n",
      "train loss:0.014637336272223873\n",
      "train loss:0.017434359658344313\n",
      "train loss:0.010103093805643266\n",
      "train loss:0.0169193096290276\n",
      "train loss:0.018472471536863516\n",
      "train loss:0.010568947630363004\n",
      "train loss:0.013736951722629604\n",
      "train loss:0.004423057907666266\n",
      "train loss:0.001305256502375159\n",
      "train loss:0.006321151360977964\n",
      "train loss:0.013656131043431077\n",
      "train loss:0.003886091522186525\n",
      "train loss:0.0031241907767419006\n",
      "train loss:0.015079651018679334\n",
      "train loss:0.006184137098924739\n",
      "train loss:0.04936767299723557\n",
      "train loss:0.017242409234414464\n",
      "train loss:0.004434858932403529\n",
      "train loss:0.0036209172341467115\n",
      "train loss:0.002726646445677655\n",
      "train loss:0.03802452731559787\n",
      "train loss:0.06957950832629026\n",
      "train loss:0.030028027155321865\n",
      "train loss:0.0069067539735645\n",
      "train loss:0.025291510317506777\n",
      "train loss:0.0033845492909166937\n",
      "train loss:0.01903943169138257\n",
      "train loss:0.005399897895879405\n",
      "train loss:0.018521423218134905\n",
      "train loss:0.015842575119275608\n",
      "train loss:0.0063638759195833085\n",
      "train loss:0.006024235990539006\n",
      "train loss:0.041787093127805965\n",
      "train loss:0.010098251754792127\n",
      "train loss:0.02936464335558288\n",
      "train loss:0.0056405561029404284\n",
      "train loss:0.010673089881773717\n",
      "train loss:0.032685959214710014\n",
      "train loss:0.00558810612174372\n",
      "train loss:0.031128486055759342\n",
      "train loss:0.018564439465780413\n",
      "train loss:0.04321175772567436\n",
      "train loss:0.03447503599414535\n",
      "train loss:0.006757040851886793\n",
      "train loss:0.008493608695768413\n",
      "train loss:0.03736325698721514\n",
      "train loss:0.01985114745732183\n",
      "train loss:0.016231548403920396\n",
      "train loss:0.005308903558922076\n",
      "train loss:0.007111450932638403\n",
      "train loss:0.005061391306124863\n",
      "train loss:0.03620909683644053\n",
      "train loss:0.005229857287782289\n",
      "train loss:0.011680547281141485\n",
      "train loss:0.037999199181457055\n",
      "train loss:0.012542420009173612\n",
      "train loss:0.0011518885709235279\n",
      "train loss:0.014331630251043089\n",
      "train loss:0.004630896107295234\n",
      "train loss:0.035449834258899714\n",
      "train loss:0.017309782362392792\n",
      "train loss:0.005978416977334724\n",
      "train loss:0.020180810003813422\n",
      "train loss:0.02873624228020716\n",
      "train loss:0.007114950683789419\n",
      "train loss:0.00498250205865521\n",
      "train loss:0.004236900953785754\n",
      "train loss:0.025840052519741592\n",
      "train loss:0.001718696909865726\n",
      "train loss:0.003758696401844286\n",
      "train loss:0.003034667858380845\n",
      "train loss:0.007339848499609692\n",
      "train loss:0.02707222314574799\n",
      "train loss:0.0021992573247071614\n",
      "train loss:0.06919738244984723\n",
      "train loss:0.004059804075416612\n",
      "train loss:0.0036909004432148485\n",
      "train loss:0.026067675257591006\n",
      "train loss:0.00427531459898898\n",
      "train loss:0.006106354286772615\n",
      "train loss:0.019233975313934393\n",
      "train loss:0.032060977196027095\n",
      "train loss:0.012404916917601084\n",
      "train loss:0.008263038939514534\n",
      "train loss:0.06697949536647574\n",
      "train loss:0.012630597848411217\n",
      "train loss:0.03366358128326699\n",
      "train loss:0.04161106746323728\n",
      "train loss:0.008789332365617374\n",
      "train loss:0.009901213222706899\n",
      "train loss:0.004454863331057232\n",
      "train loss:0.010044436096557278\n",
      "train loss:0.0021802596887748995\n",
      "train loss:0.013753528242413007\n",
      "train loss:0.022135453322862823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.01726703283191574\n",
      "train loss:0.0035542530809643132\n",
      "train loss:0.008351752188157346\n",
      "train loss:0.011273862258650744\n",
      "train loss:0.019969154805912798\n",
      "train loss:0.00310684890242056\n",
      "train loss:0.0037692514384617486\n",
      "train loss:0.013515767841018664\n",
      "train loss:0.0036139815589004\n",
      "train loss:0.005360092425325705\n",
      "train loss:0.007734191818508162\n",
      "train loss:0.005444789116489061\n",
      "train loss:0.07302687120753416\n",
      "train loss:0.018087526416814402\n",
      "train loss:0.016041603061813042\n",
      "=== epoch:8, train acc:0.991, test acc:0.99 ===\n",
      "train loss:0.003990055288610207\n",
      "train loss:0.0034086789028193103\n",
      "train loss:0.03583953298334357\n",
      "train loss:0.006019508502533174\n",
      "train loss:0.004234419272958084\n",
      "train loss:0.011229668807099661\n",
      "train loss:0.0024718795928073654\n",
      "train loss:0.006707363981984512\n",
      "train loss:0.0015670131287837028\n",
      "train loss:0.006902000368736053\n",
      "train loss:0.00518643791007969\n",
      "train loss:0.0033777566236450375\n",
      "train loss:0.007817026688804825\n",
      "train loss:0.06377823983331059\n",
      "train loss:0.006669748240291666\n",
      "train loss:0.019087358237083907\n",
      "train loss:0.01046057939659897\n",
      "train loss:0.06799321534734712\n",
      "train loss:0.0024902755564733333\n",
      "train loss:0.01283874632751296\n",
      "train loss:0.008424097283050172\n",
      "train loss:0.007062638770288512\n",
      "train loss:0.005885456084350802\n",
      "train loss:0.012633199220805233\n",
      "train loss:0.03247224055757083\n",
      "train loss:0.0019711850945313765\n",
      "train loss:0.013135611579815578\n",
      "train loss:0.0015337006330830682\n",
      "train loss:0.0009615391370309647\n",
      "train loss:0.02144928743092752\n",
      "train loss:0.005124159139611442\n",
      "train loss:0.024356513376534456\n",
      "train loss:0.005481377920887876\n",
      "train loss:0.012276844950067195\n",
      "train loss:0.013056646702353665\n",
      "train loss:0.022413418745184256\n",
      "train loss:0.010736023699763255\n",
      "train loss:0.0016568242706122055\n",
      "train loss:0.008984554045257083\n",
      "train loss:0.0025954507333387855\n",
      "train loss:0.01947505492025201\n",
      "train loss:0.012487988395563348\n",
      "train loss:0.0045898821243253295\n",
      "train loss:0.028545681592586275\n",
      "train loss:0.0038836689773207827\n",
      "train loss:0.05760077748049421\n",
      "train loss:0.00954240598838015\n",
      "train loss:0.005683809905529337\n",
      "train loss:0.0034710749580953355\n",
      "train loss:0.0010534643136940942\n",
      "train loss:0.005069894151110446\n",
      "train loss:0.005101522241570479\n",
      "train loss:0.01065305051710481\n",
      "train loss:0.007192420305054265\n",
      "train loss:0.012203236533967581\n",
      "train loss:0.0020857985451920033\n",
      "train loss:0.004210158948370113\n",
      "train loss:0.014846133751170318\n",
      "train loss:0.008649183640405508\n",
      "train loss:0.003093995522164213\n",
      "train loss:0.004021521330569954\n",
      "train loss:0.0139052737759462\n",
      "train loss:0.024967690971713374\n",
      "train loss:0.0085130563347353\n",
      "train loss:0.00891557384291432\n",
      "train loss:0.017718901586650043\n",
      "train loss:0.004306232319401271\n",
      "train loss:0.019332841268112147\n",
      "train loss:0.015508583564496381\n",
      "train loss:0.002376167377438257\n",
      "train loss:0.0026329850066835175\n",
      "train loss:0.010746191784576134\n",
      "train loss:0.008123783291422864\n",
      "train loss:0.004388039064450166\n",
      "train loss:0.006859430212830708\n",
      "train loss:0.0025012688362130975\n",
      "train loss:0.014963146447752944\n",
      "train loss:0.02246812711086397\n",
      "train loss:0.0020597396295572072\n",
      "train loss:0.00995320142408155\n",
      "train loss:0.004074096377318596\n",
      "train loss:0.08082957269368357\n",
      "train loss:0.014217231144491482\n",
      "train loss:0.018650772155302527\n",
      "train loss:0.005967977178120467\n",
      "train loss:0.004031622957828421\n",
      "train loss:0.01599733203720489\n",
      "train loss:0.022183536979715854\n",
      "train loss:0.04719106537776668\n",
      "train loss:0.018917938288745474\n",
      "train loss:0.011119379550346581\n",
      "train loss:0.008957401300417509\n",
      "train loss:0.0056811963006908285\n",
      "train loss:0.0072483345040771086\n",
      "train loss:0.044836867390287034\n",
      "train loss:0.00913701575005846\n",
      "train loss:0.007510830336734714\n",
      "train loss:0.005428615506320397\n",
      "train loss:0.013249935213415\n",
      "train loss:0.03446639907090552\n",
      "train loss:0.0144357826311399\n",
      "train loss:0.01912029086648342\n",
      "train loss:0.011367696637600518\n",
      "train loss:0.01323061587321994\n",
      "train loss:0.010366050305057793\n",
      "train loss:0.005762658854248187\n",
      "train loss:0.00675926839123974\n",
      "train loss:0.002976928336030193\n",
      "train loss:0.0004481639921006234\n",
      "train loss:0.009133456227887513\n",
      "train loss:0.004699664022305698\n",
      "train loss:0.00757275884797221\n",
      "train loss:0.008750558965024115\n",
      "train loss:0.015245036310098692\n",
      "train loss:0.0044775464787167145\n",
      "train loss:0.04143978926183658\n",
      "train loss:0.004981440383743315\n",
      "train loss:0.07554140433303527\n",
      "train loss:0.012200470765478295\n",
      "train loss:0.014056958479991706\n",
      "train loss:0.003166043726288348\n",
      "train loss:0.07322927138426469\n",
      "train loss:0.0025551813708726374\n",
      "train loss:0.006252666303518707\n",
      "train loss:0.006224997436125496\n",
      "train loss:0.022047019083106092\n",
      "train loss:0.06665691900693929\n",
      "train loss:0.0032990171859633866\n",
      "train loss:0.010889277112543195\n",
      "train loss:0.008941738057261705\n",
      "train loss:0.009643628776488436\n",
      "train loss:0.03372327081357763\n",
      "train loss:0.010677581419830617\n",
      "train loss:0.008136329232084918\n",
      "train loss:0.0023328125692742598\n",
      "train loss:0.0013429270562697647\n",
      "train loss:0.0019379977201669516\n",
      "train loss:0.08501085876997173\n",
      "train loss:0.009080296180371416\n",
      "train loss:0.05029748104195186\n",
      "train loss:0.0405225849252814\n",
      "train loss:0.011696713534384921\n",
      "train loss:0.01851421529188172\n",
      "train loss:0.02148232757165613\n",
      "train loss:0.00932269334807604\n",
      "train loss:0.018829975051271507\n",
      "train loss:0.02273278952348503\n",
      "train loss:0.006770071296113978\n",
      "train loss:0.018808719224663397\n",
      "train loss:0.005986902523030096\n",
      "train loss:0.004506113110397856\n",
      "train loss:0.01061529209129582\n",
      "train loss:0.013378035272621156\n",
      "train loss:0.006070725883269758\n",
      "train loss:0.020817851204960654\n",
      "train loss:0.012614460215521586\n",
      "train loss:0.017656678137569326\n",
      "train loss:0.003862986169985509\n",
      "train loss:0.004047892624100507\n",
      "train loss:0.012246870099032962\n",
      "train loss:0.007205057392681007\n",
      "train loss:0.08087406842496422\n",
      "train loss:0.0071542581468055375\n",
      "train loss:0.005106124775259304\n",
      "train loss:0.0017158515946579442\n",
      "train loss:0.0075137004045833945\n",
      "train loss:0.013817599685931834\n",
      "train loss:0.027490026503631415\n",
      "train loss:0.0014186160795640864\n",
      "train loss:0.00817324826678283\n",
      "train loss:0.014027271066932143\n",
      "train loss:0.00690718402918161\n",
      "train loss:0.011537437730705502\n",
      "train loss:0.006065508039128249\n",
      "train loss:0.006656488176013051\n",
      "train loss:0.019187650686377563\n",
      "train loss:0.0036968828620936446\n",
      "train loss:0.029767710911239934\n",
      "train loss:0.008543034658264101\n",
      "train loss:0.0048127116799685345\n",
      "train loss:0.005667624178700984\n",
      "train loss:0.0020599333220008135\n",
      "train loss:0.003779994330472832\n",
      "train loss:0.004265680676800376\n",
      "train loss:0.0045051888654325635\n",
      "train loss:0.013084335715873911\n",
      "train loss:0.002265044995317847\n",
      "train loss:0.026935428656826615\n",
      "train loss:0.007752658474830222\n",
      "train loss:0.03697849495599149\n",
      "train loss:0.024929760520247042\n",
      "train loss:0.007715610637351556\n",
      "train loss:0.011686245299824514\n",
      "train loss:0.021101810331012712\n",
      "train loss:0.0037651351949999647\n",
      "train loss:0.009083803415926558\n",
      "train loss:0.0053174431339920334\n",
      "train loss:0.019278830587284242\n",
      "train loss:0.0040062890779051724\n",
      "train loss:0.007197025517548286\n",
      "train loss:0.004496623520423748\n",
      "train loss:0.061263360284941025\n",
      "train loss:0.007649196033650918\n",
      "train loss:0.008582508937113868\n",
      "train loss:0.011872037987431628\n",
      "train loss:0.003256724625736786\n",
      "train loss:0.007271031463966893\n",
      "train loss:0.01815327511518462\n",
      "train loss:0.005947002991170554\n",
      "train loss:0.0653839427494936\n",
      "train loss:0.004793181770233464\n",
      "train loss:0.014713698111790232\n",
      "train loss:0.008013753534646567\n",
      "train loss:0.004700034701711473\n",
      "train loss:0.005374855528807177\n",
      "train loss:0.012244995299427424\n",
      "train loss:0.013240961965247067\n",
      "train loss:0.011064031931186406\n",
      "train loss:0.002386983294257812\n",
      "train loss:0.010717993698767843\n",
      "train loss:0.016972568203712665\n",
      "train loss:0.007416560735761298\n",
      "train loss:0.005244854404133439\n",
      "train loss:0.004050324288887998\n",
      "train loss:0.009656490820335229\n",
      "train loss:0.005062141789125728\n",
      "train loss:0.01617183559545556\n",
      "train loss:0.004774811454069942\n",
      "train loss:0.007699879767532573\n",
      "train loss:0.01767831012654562\n",
      "train loss:0.002420203923236519\n",
      "train loss:0.031137417492754692\n",
      "train loss:0.001106370383030203\n",
      "train loss:0.0030031187803292118\n",
      "train loss:0.019577583324709547\n",
      "train loss:0.009274794088849533\n",
      "train loss:0.04658340573697516\n",
      "train loss:0.05667126497881303\n",
      "train loss:0.007354703338128467\n",
      "train loss:0.00929982274795388\n",
      "train loss:0.006936552171003413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.03123137335162295\n",
      "train loss:0.03941171863930054\n",
      "train loss:0.0345229791442184\n",
      "train loss:0.04044240920406221\n",
      "train loss:0.01375387900778141\n",
      "train loss:0.017430154117174815\n",
      "train loss:0.016645244446419002\n",
      "train loss:0.00732422062821466\n",
      "train loss:0.007965506007799075\n",
      "train loss:0.00801653838459794\n",
      "train loss:0.007651615207384399\n",
      "train loss:0.09399238955745932\n",
      "train loss:0.04799330782012289\n",
      "train loss:0.025934694245163384\n",
      "train loss:0.017598312890840465\n",
      "train loss:0.02521389913368293\n",
      "train loss:0.016875153871477196\n",
      "train loss:0.05734692912735518\n",
      "train loss:0.007057185600331987\n",
      "train loss:0.0056652815983425095\n",
      "train loss:0.016709949630677064\n",
      "train loss:0.011569893339141206\n",
      "train loss:0.0951595245562702\n",
      "train loss:0.006591666167164242\n",
      "train loss:0.005126012929422968\n",
      "train loss:0.006114380729687336\n",
      "train loss:0.025903318472612496\n",
      "train loss:0.013461507654244073\n",
      "train loss:0.0012930371727183903\n",
      "train loss:0.007366273548679085\n",
      "train loss:0.022338532818628888\n",
      "train loss:0.0035085794224075707\n",
      "train loss:0.03498777222318167\n",
      "train loss:0.0050642178095246185\n",
      "train loss:0.013548179787490185\n",
      "train loss:0.008035522406081592\n",
      "train loss:0.018699582266284445\n",
      "train loss:0.0214223900489395\n",
      "train loss:0.03962870678484264\n",
      "train loss:0.008622072976107157\n",
      "train loss:0.035614913146447595\n",
      "train loss:0.01857685574666328\n",
      "train loss:0.03691662709396137\n",
      "train loss:0.0025610270471999267\n",
      "train loss:0.004845782878377277\n",
      "train loss:0.014652197203684755\n",
      "train loss:0.004191118306804589\n",
      "train loss:0.005343479705621581\n",
      "train loss:0.03245044811605918\n",
      "train loss:0.014903667411303952\n",
      "train loss:0.01500315983533482\n",
      "train loss:0.007768193296850748\n",
      "train loss:0.014447411295073962\n",
      "train loss:0.016978368428814908\n",
      "train loss:0.0124015196649684\n",
      "train loss:0.012739538417530378\n",
      "train loss:0.009542797912452983\n",
      "train loss:0.004030728162042467\n",
      "train loss:0.013252206990684095\n",
      "train loss:0.004015390575706956\n",
      "train loss:0.015330341447102252\n",
      "train loss:0.010405742682471584\n",
      "train loss:0.004541118227130027\n",
      "train loss:0.011479967973890774\n",
      "train loss:0.013873993072761938\n",
      "train loss:0.010636740396904782\n",
      "train loss:0.015124650086676746\n",
      "train loss:0.014817652224653826\n",
      "train loss:0.018735963133243837\n",
      "train loss:0.00418600917448854\n",
      "train loss:0.01981328524542971\n",
      "train loss:0.009976545709023383\n",
      "train loss:0.007057559943608838\n",
      "train loss:0.012887432594206029\n",
      "train loss:0.014481381567064909\n",
      "train loss:0.0013117735465521321\n",
      "train loss:0.008394664786242416\n",
      "train loss:0.04038993497777102\n",
      "train loss:0.0022158753032952214\n",
      "train loss:0.0052999881054562\n",
      "train loss:0.008827281055314655\n",
      "train loss:0.003905242457774328\n",
      "train loss:0.002496836397981839\n",
      "train loss:0.01320836785215954\n",
      "train loss:0.008604346238428328\n",
      "train loss:0.002530659907791493\n",
      "train loss:0.004930535928297602\n",
      "train loss:0.011939173209122663\n",
      "train loss:0.00907226196324213\n",
      "train loss:0.02889166720393426\n",
      "train loss:0.004641781441530562\n",
      "train loss:0.010635735725559831\n",
      "train loss:0.0018447775765748275\n",
      "train loss:0.0048480811736191145\n",
      "train loss:0.002387746040568742\n",
      "train loss:0.006672382764275524\n",
      "train loss:0.004232131375709151\n",
      "train loss:0.016928053703675446\n",
      "train loss:0.03650697975437271\n",
      "train loss:0.06411402822861512\n",
      "train loss:0.0043374261386857895\n",
      "train loss:0.0018868783568437308\n",
      "train loss:0.07524876567516639\n",
      "train loss:0.012402247986821458\n",
      "train loss:0.0057270422599163115\n",
      "train loss:0.009502613765694879\n",
      "train loss:0.014174842357330533\n",
      "train loss:0.010788049408290208\n",
      "train loss:0.0639045561945038\n",
      "train loss:0.0019866321773235177\n",
      "train loss:0.003914375458431669\n",
      "train loss:0.006459834222904034\n",
      "train loss:0.0042849480607054105\n",
      "train loss:0.002110398474395048\n",
      "train loss:0.006736546261174692\n",
      "train loss:0.02750824077563714\n",
      "train loss:0.018739991181988422\n",
      "train loss:0.0048384322250325275\n",
      "train loss:0.005190072153166312\n",
      "train loss:0.0036187962626060767\n",
      "train loss:0.007775271573574289\n",
      "train loss:0.030135901369769718\n",
      "train loss:0.02549094587228136\n",
      "train loss:0.0014197020503882857\n",
      "train loss:0.009388464910354779\n",
      "train loss:0.039267243161867395\n",
      "train loss:0.020581984012135582\n",
      "train loss:0.02480509384921709\n",
      "train loss:0.0022315506350541812\n",
      "train loss:0.0294894883789665\n",
      "train loss:0.0025310195997559682\n",
      "train loss:0.019172928133904015\n",
      "train loss:0.0026075506873888604\n",
      "train loss:0.00619537157501298\n",
      "train loss:0.017522390876471255\n",
      "train loss:0.04137354974738032\n",
      "train loss:0.027501170539085164\n",
      "train loss:0.01112257973441285\n",
      "train loss:0.011305005680369655\n",
      "train loss:0.02049132484559517\n",
      "train loss:0.017627830656583986\n",
      "train loss:0.04998009576628544\n",
      "train loss:0.0046042665732664\n",
      "train loss:0.005531861249122485\n",
      "train loss:0.0024889000051716965\n",
      "train loss:0.003601953614229389\n",
      "train loss:0.018441284347108435\n",
      "train loss:0.03257619285720753\n",
      "train loss:0.0077853237549151515\n",
      "train loss:0.04448334248432022\n",
      "train loss:0.007071791477002126\n",
      "train loss:0.0025042099979597225\n",
      "train loss:0.003229268318269844\n",
      "train loss:0.014933375595720742\n",
      "train loss:0.011513745206178386\n",
      "train loss:0.022763923538606182\n",
      "train loss:0.004907223715850529\n",
      "train loss:0.014916844159739413\n",
      "train loss:0.009472706335969635\n",
      "train loss:0.009828815544335484\n",
      "train loss:0.01647532139636401\n",
      "train loss:0.003457451784463712\n",
      "train loss:0.049628260302512855\n",
      "train loss:0.007633215211103419\n",
      "train loss:0.018858367423105923\n",
      "train loss:0.01929885430610827\n",
      "train loss:0.006494894829615491\n",
      "train loss:0.002611061000401044\n",
      "train loss:0.012654098708869445\n",
      "train loss:0.0025681044223758876\n",
      "train loss:0.001302323226004742\n",
      "train loss:0.021981330903123587\n",
      "train loss:0.01965067674590873\n",
      "train loss:0.009360510496610346\n",
      "train loss:0.023619309021040834\n",
      "train loss:0.0069267157092767475\n",
      "train loss:0.028065784885377445\n",
      "train loss:0.021793542873919866\n",
      "train loss:0.02088922008200226\n",
      "train loss:0.014520049186608161\n",
      "train loss:0.010558014793730976\n",
      "train loss:0.021888884430198288\n",
      "train loss:0.005602574205003149\n",
      "train loss:0.02386459774966568\n",
      "train loss:0.03038798761351228\n",
      "train loss:0.014177943827377281\n",
      "train loss:0.010931046487745413\n",
      "train loss:0.01996473294263614\n",
      "train loss:0.012839892478910203\n",
      "train loss:0.0018809454429281006\n",
      "train loss:0.004000627640639206\n",
      "train loss:0.0324728675023342\n",
      "train loss:0.002246252785927714\n",
      "train loss:0.016724578316993387\n",
      "train loss:0.01975733261227501\n",
      "train loss:0.003894061036602791\n",
      "train loss:0.0034592666808125213\n",
      "train loss:0.010391259811101849\n",
      "train loss:0.001131333420501782\n",
      "train loss:0.00159304007499585\n",
      "train loss:0.03179343650794952\n",
      "train loss:0.0010090317160102865\n",
      "train loss:0.0068112274437520095\n",
      "train loss:0.005715319067087797\n",
      "train loss:0.003822282511144393\n",
      "train loss:0.006966052413004931\n",
      "train loss:0.019816359749510876\n",
      "train loss:0.001892650337914137\n",
      "train loss:0.0061751229233598425\n",
      "train loss:0.0036137400920849038\n",
      "train loss:0.00910516742687041\n",
      "train loss:0.002073966232188675\n",
      "train loss:0.0029281240597625745\n",
      "train loss:0.002939712305116572\n",
      "train loss:0.001371791137291046\n",
      "train loss:0.010164707290595298\n",
      "train loss:0.005398322201837808\n",
      "train loss:0.00422604091154605\n",
      "train loss:0.027960995184527514\n",
      "train loss:0.004337730953374398\n",
      "train loss:0.011772577659876991\n",
      "train loss:0.04496216360561758\n",
      "train loss:0.004442865522116588\n",
      "train loss:0.003988816472008552\n",
      "train loss:0.005967145484996983\n",
      "train loss:0.00291929003326984\n",
      "train loss:0.00763190436951233\n",
      "train loss:0.0025364589904866134\n",
      "train loss:0.002327471435546966\n",
      "train loss:0.006704612697346573\n",
      "train loss:0.008458558381234724\n",
      "train loss:0.05658703379362026\n",
      "train loss:0.035637460150303675\n",
      "train loss:0.02562926623245733\n",
      "train loss:0.002276961278135383\n",
      "train loss:0.0053313275991366095\n",
      "train loss:0.0007593400301220763\n",
      "train loss:0.02079156205036696\n",
      "train loss:0.0059023906495760045\n",
      "train loss:0.0028568233686899354\n",
      "train loss:0.001669052929863808\n",
      "train loss:0.0069701403757632206\n",
      "train loss:0.0013728191232025469\n",
      "train loss:0.007204771803880995\n",
      "train loss:0.01051638709316574\n",
      "train loss:0.03632338546474549\n",
      "train loss:0.003926139296622037\n",
      "train loss:0.022983508192116576\n",
      "train loss:0.034305201214205314\n",
      "train loss:0.009354054575628944\n",
      "train loss:0.02794398456626035\n",
      "train loss:0.012608156943895141\n",
      "train loss:0.011806782416647137\n",
      "train loss:0.03349623748609107\n",
      "train loss:0.007861296198072167\n",
      "train loss:0.006261650042115588\n",
      "train loss:0.023877661788635807\n",
      "train loss:0.007998579172432642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.003984637801147072\n",
      "train loss:0.015505448850543195\n",
      "train loss:0.006352907185190695\n",
      "train loss:0.0071175396194417965\n",
      "train loss:0.0019101004292955926\n",
      "train loss:0.015639045936864007\n",
      "train loss:0.035740161668207746\n",
      "train loss:0.010727613077976213\n",
      "train loss:0.006764674639599805\n",
      "train loss:0.012243623000552175\n",
      "train loss:0.028364711375234698\n",
      "train loss:0.022984629884786396\n",
      "train loss:0.010884641268056479\n",
      "train loss:0.0024561902789800695\n",
      "train loss:0.0030310598459432525\n",
      "train loss:0.029285895448937074\n",
      "train loss:0.026096611630090204\n",
      "train loss:0.04370309711022431\n",
      "train loss:0.014408394199706506\n",
      "train loss:0.001387782537960921\n",
      "train loss:0.003034137287891832\n",
      "train loss:0.013420648216485555\n",
      "train loss:0.007714036099772451\n",
      "train loss:0.005226587182702556\n",
      "train loss:0.0011209624951300865\n",
      "train loss:0.01888840157211351\n",
      "train loss:0.06271343642429769\n",
      "train loss:0.005372204695818794\n",
      "train loss:0.005859382249891358\n",
      "train loss:0.001555077316848679\n",
      "train loss:0.01604574952825433\n",
      "train loss:0.02530920298897981\n",
      "train loss:0.01921469260491966\n",
      "train loss:0.009110996407090295\n",
      "train loss:0.02841166781575176\n",
      "train loss:0.013244004412250123\n",
      "train loss:0.01700561419532512\n",
      "train loss:0.0028036062777834986\n",
      "train loss:0.0144533448731659\n",
      "train loss:0.0012007711238488413\n",
      "train loss:0.022547851904208657\n",
      "train loss:0.031286231331100776\n",
      "train loss:0.005640484021362635\n",
      "train loss:0.005204385424948566\n",
      "train loss:0.03275731604893797\n",
      "train loss:0.01853086204162528\n",
      "train loss:0.004982103403568789\n",
      "train loss:0.0024735218766271014\n",
      "train loss:0.009594650140423338\n",
      "train loss:0.00477264260979209\n",
      "train loss:0.006843443154799438\n",
      "train loss:0.009028822588207315\n",
      "train loss:0.004779668609514626\n",
      "train loss:0.03699259762390027\n",
      "train loss:0.016996188539969072\n",
      "train loss:0.021533822307120542\n",
      "train loss:0.03264856337409916\n",
      "train loss:0.011115432192116663\n",
      "train loss:0.0034868261429017804\n",
      "train loss:0.042581119802311614\n",
      "train loss:0.011435661264759124\n",
      "train loss:0.008500913247317766\n",
      "train loss:0.0030403600133066936\n",
      "train loss:0.006826346503237422\n",
      "train loss:0.00792686187912488\n",
      "train loss:0.011725243980436808\n",
      "train loss:0.0021917611089907205\n",
      "train loss:0.003031644132654348\n",
      "train loss:0.0009728660198591918\n",
      "train loss:0.009251987887136092\n",
      "train loss:0.0020831727400865\n",
      "train loss:0.013921353156293875\n",
      "train loss:0.003068062585566556\n",
      "train loss:0.0007311213451800238\n",
      "train loss:0.0033319989068382365\n",
      "train loss:0.008936335005791291\n",
      "train loss:0.004303575260350547\n",
      "train loss:0.0014625648694373075\n",
      "train loss:0.0026875856379812418\n",
      "train loss:0.0015928180922312192\n",
      "train loss:0.02486609801632198\n",
      "train loss:0.03983213775797753\n",
      "train loss:0.011241049186206102\n",
      "train loss:0.005105095138991097\n",
      "train loss:0.02018987842958792\n",
      "train loss:0.017839139200328046\n",
      "train loss:0.002870593182236659\n",
      "train loss:0.0060593820210749615\n",
      "train loss:0.05138468591015686\n",
      "train loss:0.013683277412556179\n",
      "train loss:0.012461983752347939\n",
      "train loss:0.023418564589673244\n",
      "train loss:0.18751030448905356\n",
      "train loss:0.005041585417722389\n",
      "train loss:0.013803610477639474\n",
      "train loss:0.012495602246504898\n",
      "train loss:0.003328209126380938\n",
      "train loss:0.004452664344794914\n",
      "train loss:0.01410297083268465\n",
      "train loss:0.008452250001405832\n",
      "train loss:0.006554140982596161\n",
      "=== epoch:9, train acc:0.993, test acc:0.985 ===\n",
      "train loss:0.008270972319306758\n",
      "train loss:0.0034539885761298234\n",
      "train loss:0.00553615854442082\n",
      "train loss:0.0017036011283992289\n",
      "train loss:0.013912762910796466\n",
      "train loss:0.007729532698710483\n",
      "train loss:0.02239305822821837\n",
      "train loss:0.005450129936272471\n",
      "train loss:0.007805797016871288\n",
      "train loss:0.039190447415018516\n",
      "train loss:0.028332631849531734\n",
      "train loss:0.02378253098259881\n",
      "train loss:0.02463152423169262\n",
      "train loss:0.011998800802984126\n",
      "train loss:0.0016554343384223293\n",
      "train loss:0.01084942856247614\n",
      "train loss:0.028364864802429942\n",
      "train loss:0.0069978351101489126\n",
      "train loss:0.005357863668843643\n",
      "train loss:0.030857279930624915\n",
      "train loss:0.060703234704146555\n",
      "train loss:0.001748003283102485\n",
      "train loss:0.00412540250120084\n",
      "train loss:0.0021503850704137615\n",
      "train loss:0.0043289291076349275\n",
      "train loss:0.00447369079068447\n",
      "train loss:0.007559835593240948\n",
      "train loss:0.018004481394143085\n",
      "train loss:0.0095933388225919\n",
      "train loss:0.0020148771573178046\n",
      "train loss:0.011360230210121825\n",
      "train loss:0.01528858779660325\n",
      "train loss:0.12106050640974086\n",
      "train loss:0.005580807592083805\n",
      "train loss:0.015740496996143168\n",
      "train loss:0.0029404851809032044\n",
      "train loss:0.0023364231104219253\n",
      "train loss:0.00815726759848643\n",
      "train loss:0.014653783266553493\n",
      "train loss:0.01207634632033774\n",
      "train loss:0.014381120660659687\n",
      "train loss:0.004687814570211988\n",
      "train loss:0.0054437271643578335\n",
      "train loss:0.054939998133160924\n",
      "train loss:0.008204426758933776\n",
      "train loss:0.0033936750236162956\n",
      "train loss:0.029962154528845177\n",
      "train loss:0.0009043149343397273\n",
      "train loss:0.012418430674713299\n",
      "train loss:0.015042380410155733\n",
      "train loss:0.015075226099357953\n",
      "train loss:0.004268585284563942\n",
      "train loss:0.027139582925512763\n",
      "train loss:0.03442024826421895\n",
      "train loss:0.02822750208172458\n",
      "train loss:0.005793251482711264\n",
      "train loss:0.00581018092804692\n",
      "train loss:0.006811892107245727\n",
      "train loss:0.0022815007365607504\n",
      "train loss:0.01051815394345608\n",
      "train loss:0.005959186297123401\n",
      "train loss:0.002204501153630864\n",
      "train loss:0.005053739985398872\n",
      "train loss:0.008585933394644233\n",
      "train loss:0.0010579447455358907\n",
      "train loss:0.00517553770403125\n",
      "train loss:0.0007896784175489848\n",
      "train loss:0.01184630730802567\n",
      "train loss:0.01746942020427153\n",
      "train loss:0.0014501271944712926\n",
      "train loss:0.0056176493829534005\n",
      "train loss:0.010366010245196438\n",
      "train loss:0.007762989784015319\n",
      "train loss:0.004957070475897926\n",
      "train loss:0.009835394956147837\n",
      "train loss:0.0058473152030484995\n",
      "train loss:0.008123733042899532\n",
      "train loss:0.0026315089195152463\n",
      "train loss:0.0009822228859572124\n",
      "train loss:0.0031840557821410293\n",
      "train loss:0.00142753214761022\n",
      "train loss:0.03920489324702006\n",
      "train loss:0.0050047314607734325\n",
      "train loss:0.018447683549709756\n",
      "train loss:0.022198877493382996\n",
      "train loss:0.0015017519944564863\n",
      "train loss:0.044563448922614365\n",
      "train loss:0.008139966874017855\n",
      "train loss:0.009468776653309599\n",
      "train loss:0.004350472355360005\n",
      "train loss:0.01169107748666715\n",
      "train loss:0.012750643392865307\n",
      "train loss:0.03023959884709969\n",
      "train loss:0.002081698382899532\n",
      "train loss:0.011987119455717888\n",
      "train loss:0.040149107346240026\n",
      "train loss:0.0033458173681054255\n",
      "train loss:0.014458616454856396\n",
      "train loss:0.01000444507013525\n",
      "train loss:0.0036411662643029076\n",
      "train loss:0.031461769576488295\n",
      "train loss:0.0026494992777238336\n",
      "train loss:0.010706151268046622\n",
      "train loss:0.030977117673546894\n",
      "train loss:0.005791560047083577\n",
      "train loss:0.053537643392621785\n",
      "train loss:0.05184643564430168\n",
      "train loss:0.0182903430571078\n",
      "train loss:0.026915840125356257\n",
      "train loss:0.033895501287088355\n",
      "train loss:0.00889676306670696\n",
      "train loss:0.013746376484342227\n",
      "train loss:0.014381234537437355\n",
      "train loss:0.0034329437948356512\n",
      "train loss:0.0021181003018097386\n",
      "train loss:0.0194560168074342\n",
      "train loss:0.009665959416716384\n",
      "train loss:0.005573103521133286\n",
      "train loss:0.006973726888719548\n",
      "train loss:0.018762749677859666\n",
      "train loss:0.005104926198605093\n",
      "train loss:0.01201747152475299\n",
      "train loss:0.007546644653660473\n",
      "train loss:0.006302577024025869\n",
      "train loss:0.00704447552840633\n",
      "train loss:0.0332597684969341\n",
      "train loss:0.011321924483333126\n",
      "train loss:0.0057020868545962075\n",
      "train loss:0.011898435794050224\n",
      "train loss:0.004146986700375159\n",
      "train loss:0.0031377641794737747\n",
      "train loss:0.0029821619249468688\n",
      "train loss:0.0032230216650928857\n",
      "train loss:0.004232115208956967\n",
      "train loss:0.0034950812388998592\n",
      "train loss:0.007136314847776845\n",
      "train loss:0.00332971691651716\n",
      "train loss:0.005074287659579329\n",
      "train loss:0.002025096750393701\n",
      "train loss:0.007785862807622145\n",
      "train loss:0.03668360137946761\n",
      "train loss:0.002347208671436617\n",
      "train loss:0.004272058837615368\n",
      "train loss:0.05695581359425959\n",
      "train loss:0.005537351700345492\n",
      "train loss:0.010573695349488488\n",
      "train loss:0.006332415467659426\n",
      "train loss:0.0021487898195558467\n",
      "train loss:0.01398281328336902\n",
      "train loss:0.018896629892666727\n",
      "train loss:0.0025914298136855748\n",
      "train loss:0.005620994209595654\n",
      "train loss:0.033842501840624636\n",
      "train loss:0.005780655788343853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00860086053417312\n",
      "train loss:0.002631673946988043\n",
      "train loss:0.031000485332909413\n",
      "train loss:0.019082671825946383\n",
      "train loss:0.006139479166576723\n",
      "train loss:0.01518484944214839\n",
      "train loss:0.002522671048045588\n",
      "train loss:0.004386010493039337\n",
      "train loss:0.004849386430615899\n",
      "train loss:0.011280125883038127\n",
      "train loss:0.0059705476727820875\n",
      "train loss:0.030159828141677118\n",
      "train loss:0.0017224333200976211\n",
      "train loss:0.0016021067332773053\n",
      "train loss:0.05327035601360918\n",
      "train loss:0.0011079324605592492\n",
      "train loss:0.004342472325389815\n",
      "train loss:0.010976288186404918\n",
      "train loss:0.005786177338306805\n",
      "train loss:0.010954407606308192\n",
      "train loss:0.006796459008359271\n",
      "train loss:0.028623365593397426\n",
      "train loss:0.1099917229259891\n",
      "train loss:0.0012948196892916023\n",
      "train loss:0.0019228010020650454\n",
      "train loss:0.014708641843851187\n",
      "train loss:0.006426975662357785\n",
      "train loss:0.009932993488459307\n",
      "train loss:0.022981552506048022\n",
      "train loss:0.024142719474689146\n",
      "train loss:0.0023106815960119336\n",
      "train loss:0.016190129700596446\n",
      "train loss:0.017132691491472972\n",
      "train loss:0.006593167854271767\n",
      "train loss:0.008061623848456293\n",
      "train loss:0.01429375266956432\n",
      "train loss:0.029507214109128443\n",
      "train loss:0.004618665363000877\n",
      "train loss:0.007315397408508794\n",
      "train loss:0.011697462199535135\n",
      "train loss:0.011934925871936165\n",
      "train loss:0.005785175142234011\n",
      "train loss:0.016693882249052418\n",
      "train loss:0.01844745546240187\n",
      "train loss:0.0142680796470821\n",
      "train loss:0.03794543647140583\n",
      "train loss:0.006717189952087873\n",
      "train loss:0.008484796293844445\n",
      "train loss:0.001196398192447227\n",
      "train loss:0.014824554569348782\n",
      "train loss:0.005757529808466654\n",
      "train loss:0.013897541582158437\n",
      "train loss:0.006779481753357055\n",
      "train loss:0.010384010996498605\n",
      "train loss:0.009743734660342635\n",
      "train loss:0.012607745606081983\n",
      "train loss:0.026445401068445316\n",
      "train loss:0.021434411414255835\n",
      "train loss:0.001031001883174478\n",
      "train loss:0.006879041609554381\n",
      "train loss:0.00022111485903396878\n",
      "train loss:0.007338825620181238\n",
      "train loss:0.01776189976766365\n",
      "train loss:0.0011588264806063182\n",
      "train loss:0.00324630484115528\n",
      "train loss:0.010781788363938645\n",
      "train loss:0.008977912019980723\n",
      "train loss:0.03382550592091741\n",
      "train loss:0.0014867196134413516\n",
      "train loss:0.0011298870599228132\n",
      "train loss:0.03486375756807832\n",
      "train loss:0.007552123849854977\n",
      "train loss:0.004551367808886848\n",
      "train loss:0.0564535804517457\n",
      "train loss:0.0034403213368951317\n",
      "train loss:0.01138836707077968\n",
      "train loss:0.01443850696040171\n",
      "train loss:0.007035106551414637\n",
      "train loss:0.004605991918870797\n",
      "train loss:0.004148162955054729\n",
      "train loss:0.022542647112289232\n",
      "train loss:0.005721909690020074\n",
      "train loss:0.006240180105793323\n",
      "train loss:0.04799836210134303\n",
      "train loss:0.017804946504558296\n",
      "train loss:0.014419780900861323\n",
      "train loss:0.0076252424881736005\n",
      "train loss:0.006205914203621986\n",
      "train loss:0.006647015216185934\n",
      "train loss:0.008814790344530978\n",
      "train loss:0.011121935288657705\n",
      "train loss:0.00712471441144134\n",
      "train loss:0.0069162185465272375\n",
      "train loss:0.002422083648574732\n",
      "train loss:0.011565245584245059\n",
      "train loss:0.0030930508341992834\n",
      "train loss:0.0033946357416375587\n",
      "train loss:0.0074656647070490455\n",
      "train loss:0.01307550968445942\n",
      "train loss:0.007826147300978754\n",
      "train loss:0.011314033949459788\n",
      "train loss:0.0018803415694803535\n",
      "train loss:0.002251068065703737\n",
      "train loss:0.0005541762110719795\n",
      "train loss:0.005005184483337125\n",
      "train loss:0.014834722503162479\n",
      "train loss:0.010905255129985579\n",
      "train loss:0.0019580219984916282\n",
      "train loss:0.012796192872679463\n",
      "train loss:0.005393546843170005\n",
      "train loss:0.009181683010522697\n",
      "train loss:0.0006958886467690704\n",
      "train loss:0.010112691264855771\n",
      "train loss:0.003998666301802847\n",
      "train loss:0.011177074862780065\n",
      "train loss:0.003926286175263918\n",
      "train loss:0.0006914166225330298\n",
      "train loss:0.004656003445462997\n",
      "train loss:0.0012089476085189893\n",
      "train loss:0.002276455524975507\n",
      "train loss:0.002147108063146858\n",
      "train loss:0.0077415698585772096\n",
      "train loss:0.001364992333412275\n",
      "train loss:0.005735764827723\n",
      "train loss:0.028768485726060448\n",
      "train loss:0.028067731236893746\n",
      "train loss:0.006201119283415288\n",
      "train loss:0.023955578217041654\n",
      "train loss:0.011015543288563578\n",
      "train loss:0.004790886122514211\n",
      "train loss:0.007568904433616137\n",
      "train loss:0.00046749716461062346\n",
      "train loss:0.005590596635301901\n",
      "train loss:0.01399125390260035\n",
      "train loss:0.0013181408742580496\n",
      "train loss:0.0032878214572596588\n",
      "train loss:0.00949686223288335\n",
      "train loss:0.002166896718959663\n",
      "train loss:0.004467045829522465\n",
      "train loss:0.010891110461983138\n",
      "train loss:0.013817240577018206\n",
      "train loss:0.008401772965423875\n",
      "train loss:0.0020810822795213745\n",
      "train loss:0.0031042411806528696\n",
      "train loss:0.0076663138358022045\n",
      "train loss:0.0014856202961485187\n",
      "train loss:0.0057210364134716585\n",
      "train loss:0.007416600640927343\n",
      "train loss:0.0030564402567806615\n",
      "train loss:0.007656369263801305\n",
      "train loss:0.0016191749999435816\n",
      "train loss:0.0008342455090526646\n",
      "train loss:0.013987561486398127\n",
      "train loss:0.01210431830564441\n",
      "train loss:0.005062776327042982\n",
      "train loss:0.0016656285449090902\n",
      "train loss:0.0026027501425097055\n",
      "train loss:0.002115699890419275\n",
      "train loss:0.05235969498956848\n",
      "train loss:0.006762268935982182\n",
      "train loss:0.003510281544917141\n",
      "train loss:0.0020131069333953256\n",
      "train loss:0.004918797014186463\n",
      "train loss:0.020676416891861348\n",
      "train loss:0.0049411535144452\n",
      "train loss:0.011165510514372283\n",
      "train loss:0.027447024030387998\n",
      "train loss:0.002054208257293891\n",
      "train loss:0.0007107239863532996\n",
      "train loss:0.006791740105741561\n",
      "train loss:0.004245941174000047\n",
      "train loss:0.008315951643924702\n",
      "train loss:0.0101599652595384\n",
      "train loss:0.0038721397482023535\n",
      "train loss:0.010289874265994467\n",
      "train loss:0.004571727827725833\n",
      "train loss:0.002056557645569778\n",
      "train loss:0.009371628405546853\n",
      "train loss:0.001988146025899966\n",
      "train loss:0.006075453436540586\n",
      "train loss:0.005217231959458857\n",
      "train loss:0.019815317529710375\n",
      "train loss:0.0053492590415206934\n",
      "train loss:0.0028969996788453167\n",
      "train loss:0.001287811594404547\n",
      "train loss:0.01376203027191379\n",
      "train loss:0.00198833242090588\n",
      "train loss:0.012822188353202596\n",
      "train loss:0.008963476395959548\n",
      "train loss:0.02711881980179079\n",
      "train loss:0.0023540281275479563\n",
      "train loss:0.0038511786978491\n",
      "train loss:0.02719990146498988\n",
      "train loss:0.004806506682013567\n",
      "train loss:0.0026129206117703353\n",
      "train loss:0.01447985537893702\n",
      "train loss:0.008434393017548175\n",
      "train loss:0.006297661306985878\n",
      "train loss:0.025651865099172885\n",
      "train loss:0.0031682348380037677\n",
      "train loss:0.006069313163121395\n",
      "train loss:0.0005275395357998121\n",
      "train loss:0.0037905780774894265\n",
      "train loss:0.01579321501678308\n",
      "train loss:0.004029196764910031\n",
      "train loss:0.09117950743145437\n",
      "train loss:0.00356228946003377\n",
      "train loss:0.0012805187513097675\n",
      "train loss:0.008270506301092542\n",
      "train loss:0.003904889376848405\n",
      "train loss:0.013320772272077421\n",
      "train loss:0.011759193014870195\n",
      "train loss:0.005573138409004913\n",
      "train loss:0.012945942003519516\n",
      "train loss:0.007273575267532223\n",
      "train loss:0.013854132184088753\n",
      "train loss:0.012311327692690882\n",
      "train loss:0.0015938432092756874\n",
      "train loss:0.008456443402157244\n",
      "train loss:0.00537858670057298\n",
      "train loss:0.00455221454380084\n",
      "train loss:0.005636966124293622\n",
      "train loss:0.009533978722746646\n",
      "train loss:0.010593417666823458\n",
      "train loss:0.0008787047014049034\n",
      "train loss:0.06692618092626555\n",
      "train loss:0.00574843850870677\n",
      "train loss:0.0034604784795116334\n",
      "train loss:0.029834147435464087\n",
      "train loss:0.004356859122062451\n",
      "train loss:0.0025227141287537556\n",
      "train loss:0.003952696699979364\n",
      "train loss:0.008094370005429842\n",
      "train loss:0.01193555941839227\n",
      "train loss:0.006286461213867331\n",
      "train loss:0.011487483418290314\n",
      "train loss:0.017179305635952165\n",
      "train loss:0.030083657666758655\n",
      "train loss:0.003965634851224229\n",
      "train loss:0.0008359507003283528\n",
      "train loss:0.0018408865149059394\n",
      "train loss:0.04123601682710263\n",
      "train loss:0.008575091064514408\n",
      "train loss:0.005383271586513294\n",
      "train loss:0.030313789457605683\n",
      "train loss:0.01001347170561737\n",
      "train loss:0.004400268559374584\n",
      "train loss:0.0017763819322089772\n",
      "train loss:0.005395194858635035\n",
      "train loss:0.017363418624046615\n",
      "train loss:0.004928474965866491\n",
      "train loss:0.006679217524370285\n",
      "train loss:0.012124357215357588\n",
      "train loss:0.009013371336076222\n",
      "train loss:0.006060051196127663\n",
      "train loss:0.002701070398674524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004588494256227758\n",
      "train loss:0.002420961327800203\n",
      "train loss:0.004484172739664173\n",
      "train loss:0.02027420827505891\n",
      "train loss:0.04066808515270358\n",
      "train loss:0.0018145252725651814\n",
      "train loss:0.005305568964123112\n",
      "train loss:0.015415692752553245\n",
      "train loss:0.0038070872730384697\n",
      "train loss:0.005741609128348774\n",
      "train loss:0.009992422968132826\n",
      "train loss:0.029147159893081295\n",
      "train loss:0.0031398724267572647\n",
      "train loss:0.004665946045758847\n",
      "train loss:0.04366662740641343\n",
      "train loss:0.008343132281255794\n",
      "train loss:0.010169771882361728\n",
      "train loss:0.06198041060244397\n",
      "train loss:0.006874568535931751\n",
      "train loss:0.00607018691403772\n",
      "train loss:0.0015770435748493222\n",
      "train loss:0.01052795509768848\n",
      "train loss:0.0071837280671963035\n",
      "train loss:0.008604395138878961\n",
      "train loss:0.0028865143302707957\n",
      "train loss:0.007574999600469412\n",
      "train loss:0.023017192628058188\n",
      "train loss:0.02715249747648444\n",
      "train loss:0.0071509659461298026\n",
      "train loss:0.01253505377058044\n",
      "train loss:0.00280357733469971\n",
      "train loss:0.014832479109661387\n",
      "train loss:0.0028413981136508394\n",
      "train loss:0.00722704858385924\n",
      "train loss:0.022392911309736526\n",
      "train loss:0.007285560233392083\n",
      "train loss:0.03398120410939946\n",
      "train loss:0.0008646913110587749\n",
      "train loss:0.010567689857230824\n",
      "train loss:0.016729033209813594\n",
      "train loss:0.01074778669615252\n",
      "train loss:0.0013519509306688857\n",
      "train loss:0.007676679994307861\n",
      "train loss:0.015576848930088514\n",
      "train loss:0.00942332656995493\n",
      "train loss:0.01865662136918284\n",
      "train loss:0.0042447536828051965\n",
      "train loss:0.02601418526062555\n",
      "train loss:0.0071342558821488045\n",
      "train loss:0.04987408741235705\n",
      "train loss:0.011049532569787074\n",
      "train loss:0.0047709301838813264\n",
      "train loss:0.004128626297118975\n",
      "train loss:0.024689297104697267\n",
      "train loss:0.019494774229846086\n",
      "train loss:0.00496576670487651\n",
      "train loss:0.00372962639629735\n",
      "train loss:0.02837509845446476\n",
      "train loss:0.01187306391812783\n",
      "train loss:0.005411160606111743\n",
      "train loss:0.0068324268628189725\n",
      "train loss:0.012119976381746202\n",
      "train loss:0.0020623054157819522\n",
      "train loss:0.021833819493836594\n",
      "train loss:0.0058247910912755\n",
      "train loss:0.008503248470792849\n",
      "train loss:0.000562755982065023\n",
      "train loss:0.019127778807258616\n",
      "train loss:0.05229552448049735\n",
      "train loss:0.005255126547254943\n",
      "train loss:0.0014021953374362772\n",
      "train loss:0.000710530891420462\n",
      "train loss:0.03703674055312444\n",
      "train loss:0.00624477977722241\n",
      "train loss:0.002595630052300419\n",
      "train loss:0.0037822661894349875\n",
      "train loss:0.07367224600680164\n",
      "train loss:0.059688392308736196\n",
      "train loss:0.005928319916845362\n",
      "train loss:0.002343314279630944\n",
      "train loss:0.0035169134500635667\n",
      "train loss:0.037484135043940874\n",
      "train loss:0.05514048802755158\n",
      "train loss:0.04930050889642112\n",
      "train loss:0.009631636226712483\n",
      "train loss:0.0037624246617605685\n",
      "train loss:0.0022577045766378305\n",
      "train loss:0.004652195478071546\n",
      "train loss:0.005214285085689402\n",
      "train loss:0.0011448309307993466\n",
      "train loss:0.002876530405054264\n",
      "train loss:0.008053551964562972\n",
      "train loss:0.03406694582178658\n",
      "train loss:0.010311619417361943\n",
      "train loss:0.0026462903016008475\n",
      "train loss:0.002171856633694733\n",
      "train loss:0.004790917279018547\n",
      "train loss:0.024864763268528975\n",
      "train loss:0.024284607874471256\n",
      "train loss:0.0013475292183131487\n",
      "train loss:0.002883913958259635\n",
      "train loss:0.010443849644945822\n",
      "train loss:0.006174309269457444\n",
      "train loss:0.003085168793658272\n",
      "train loss:0.008506126445433965\n",
      "train loss:0.013760677614220134\n",
      "train loss:0.0030690429022826233\n",
      "train loss:0.006085555819868166\n",
      "train loss:0.028771600954079126\n",
      "train loss:0.01843140912211515\n",
      "train loss:0.0045086809878007806\n",
      "train loss:0.00697024549239122\n",
      "train loss:0.013404118956752692\n",
      "train loss:0.00794349010473407\n",
      "train loss:0.012609572041955891\n",
      "train loss:0.0045756701906544475\n",
      "train loss:0.01061357494437683\n",
      "train loss:0.009995198425938594\n",
      "train loss:0.003104097982321438\n",
      "train loss:0.006521890991755598\n",
      "train loss:0.0004495242833020673\n",
      "train loss:0.006802897174172106\n",
      "train loss:0.0016784895739761934\n",
      "train loss:0.01506525907921044\n",
      "train loss:0.0009214281975943142\n",
      "train loss:0.0052485122457969135\n",
      "train loss:0.005910432402570054\n",
      "train loss:0.006185655608302188\n",
      "train loss:0.023689454649131903\n",
      "train loss:0.0030339972612866413\n",
      "train loss:0.17944593222960337\n",
      "train loss:0.023251713969694023\n",
      "train loss:0.0018243031709031503\n",
      "train loss:0.0011660198595205922\n",
      "train loss:0.026691896057702506\n",
      "train loss:0.004853092872652861\n",
      "train loss:0.009864395826936984\n",
      "train loss:0.006978473952558414\n",
      "train loss:0.013424199026789922\n",
      "train loss:0.04047756135827592\n",
      "train loss:0.005167729006413869\n",
      "train loss:0.0024523701060746458\n",
      "train loss:0.0023446178178937868\n",
      "train loss:0.008764642961674564\n",
      "train loss:0.03795974730239755\n",
      "train loss:0.002201882844499383\n",
      "train loss:0.04893531119795134\n",
      "train loss:0.009387334627910726\n",
      "train loss:0.004161853453707021\n",
      "train loss:0.0017676949162109433\n",
      "train loss:0.013596070535951582\n",
      "train loss:0.0005406871698348873\n",
      "train loss:0.004116392744256035\n",
      "train loss:0.005479111337584901\n",
      "train loss:0.010842113047070709\n",
      "train loss:0.0030780812386008815\n",
      "train loss:0.0031056286885832642\n",
      "train loss:0.004731265297619588\n",
      "train loss:0.0024257264078776835\n",
      "train loss:0.008878689016797968\n",
      "train loss:0.06447618936247758\n",
      "train loss:0.012958640598100915\n",
      "train loss:0.004346222699912509\n",
      "train loss:0.0005904363711430009\n",
      "train loss:0.00758932977564428\n",
      "train loss:0.041602866676729106\n",
      "train loss:0.0076976538542930795\n",
      "train loss:0.007735679716658735\n",
      "train loss:0.008597009635775204\n",
      "train loss:0.0032561780217320114\n",
      "train loss:0.007827131431040803\n",
      "train loss:0.005617425218715166\n",
      "train loss:0.009788778889989084\n",
      "train loss:0.002832403906214646\n",
      "train loss:0.002791394464583842\n",
      "train loss:0.002239934845441628\n",
      "train loss:0.005859353552006492\n",
      "train loss:0.004786538586104362\n",
      "train loss:0.028674408042367955\n",
      "train loss:0.009215912401775092\n",
      "train loss:0.005275313104480842\n",
      "train loss:0.0012337557581793774\n",
      "train loss:0.010283516079412313\n",
      "train loss:0.0030895465893955366\n",
      "train loss:0.009428910805454693\n",
      "train loss:0.00509640510113163\n",
      "train loss:0.0027217319786578026\n",
      "train loss:0.01612895887675396\n",
      "train loss:0.002158421034489904\n",
      "train loss:0.004736548131398597\n",
      "=== epoch:10, train acc:0.994, test acc:0.987 ===\n",
      "train loss:0.0024531669705020747\n",
      "train loss:0.0044320567688113845\n",
      "train loss:0.005192737482521759\n",
      "train loss:0.007478627745900288\n",
      "train loss:0.008687392283976867\n",
      "train loss:0.000494878177832498\n",
      "train loss:0.004725733535920584\n",
      "train loss:0.004574821904617652\n",
      "train loss:0.000659852341597546\n",
      "train loss:0.0025828343680403586\n",
      "train loss:0.004717954730838416\n",
      "train loss:0.0016288809433367816\n",
      "train loss:0.006191895446469407\n",
      "train loss:0.00931675322388962\n",
      "train loss:0.0022710676871061652\n",
      "train loss:0.020589038965313815\n",
      "train loss:0.009329494099972\n",
      "train loss:0.0032061302151735484\n",
      "train loss:0.006681053694567366\n",
      "train loss:0.0049065722788357085\n",
      "train loss:0.014487135690863946\n",
      "train loss:0.001273922073961911\n",
      "train loss:0.0027890000596707447\n",
      "train loss:0.009121450469255669\n",
      "train loss:0.006370998072354298\n",
      "train loss:0.00531474588124068\n",
      "train loss:0.0016012084989684534\n",
      "train loss:0.0027781949690417074\n",
      "train loss:0.013797617362005313\n",
      "train loss:0.0029781861335503057\n",
      "train loss:0.009416571259168737\n",
      "train loss:0.017757795922849113\n",
      "train loss:0.0012205415557841387\n",
      "train loss:0.0031510437599738977\n",
      "train loss:0.015356500666061677\n",
      "train loss:0.010294595207571174\n",
      "train loss:0.0028236407131181866\n",
      "train loss:0.07380738425329898\n",
      "train loss:0.0032331327683295047\n",
      "train loss:0.00473079366908437\n",
      "train loss:0.0039246699976941725\n",
      "train loss:0.026789804313333394\n",
      "train loss:0.014210143276560942\n",
      "train loss:0.0022850528178204473\n",
      "train loss:0.00300429497159976\n",
      "train loss:0.011312369078317414\n",
      "train loss:0.004671029742278127\n",
      "train loss:0.0006842504422872167\n",
      "train loss:0.0017426943491946872\n",
      "train loss:0.011518514219222023\n",
      "train loss:0.042890655110828985\n",
      "train loss:0.0038768263875256477\n",
      "train loss:0.007024598830272193\n",
      "train loss:0.0029200875038639883\n",
      "train loss:0.055778603760289355\n",
      "train loss:0.008507803392133965\n",
      "train loss:0.006049672953451476\n",
      "train loss:0.011122592660930457\n",
      "train loss:0.08530057524562626\n",
      "train loss:0.0011771146685146377\n",
      "train loss:0.0021348559861533657\n",
      "train loss:0.001658345442833767\n",
      "train loss:0.0011375253149012348\n",
      "train loss:0.012860489204278234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0016471660880270343\n",
      "train loss:0.0029387985857788103\n",
      "train loss:0.000999635057291087\n",
      "train loss:0.007894566525072746\n",
      "train loss:0.0036108377532355386\n",
      "train loss:0.004362907990619968\n",
      "train loss:0.007012142942370239\n",
      "train loss:0.04746319429973655\n",
      "train loss:0.049676825258640846\n",
      "train loss:0.006131368779988488\n",
      "train loss:0.00680511039920641\n",
      "train loss:0.007547468060241346\n",
      "train loss:0.004111352660135075\n",
      "train loss:0.0020927882820791347\n",
      "train loss:0.0047143171213941465\n",
      "train loss:0.007962993261492697\n",
      "train loss:0.01640342850710911\n",
      "train loss:0.0020055316343543152\n",
      "train loss:0.003927361382413518\n",
      "train loss:0.0017321346387881523\n",
      "train loss:0.007494247342170229\n",
      "train loss:0.0060924119806970685\n",
      "train loss:0.004373238861626078\n",
      "train loss:0.005890428559322733\n",
      "train loss:0.001265105498665109\n",
      "train loss:0.005258506562608584\n",
      "train loss:0.14183817191810572\n",
      "train loss:0.0029090436206499\n",
      "train loss:0.0014829290455231686\n",
      "train loss:0.0048325614793468625\n",
      "train loss:0.0071281024445147955\n",
      "train loss:0.00627752727428772\n",
      "train loss:0.0004073869549941987\n",
      "train loss:0.0003049904665089879\n",
      "train loss:0.011610676583208973\n",
      "train loss:0.0018576655398709857\n",
      "train loss:0.0300607548995232\n",
      "train loss:0.0035004651586427443\n",
      "train loss:0.018819491890542467\n",
      "train loss:0.009643741710910023\n",
      "train loss:0.004666620520955413\n",
      "train loss:0.005116351624572208\n",
      "train loss:0.0039051229947250645\n",
      "train loss:0.047097200898113166\n",
      "train loss:0.00621896355421789\n",
      "train loss:0.005791426038141624\n",
      "train loss:0.0070322931556302745\n",
      "train loss:0.012735983782046522\n",
      "train loss:0.0013528975399111896\n",
      "train loss:0.007930340612121152\n",
      "train loss:0.008926018619648795\n",
      "train loss:0.0020601989282516796\n",
      "train loss:0.030040969878086226\n",
      "train loss:0.0014918211717942715\n",
      "train loss:0.005211159056581743\n",
      "train loss:0.00536314036657418\n",
      "train loss:0.0010195033210908951\n",
      "train loss:0.0010822597832605269\n",
      "train loss:0.004062035472150965\n",
      "train loss:0.01238293906306053\n",
      "train loss:0.002684955703108671\n",
      "train loss:0.06773738782387262\n",
      "train loss:0.14252729495130828\n",
      "train loss:0.007932929180649903\n",
      "train loss:0.006350904803764161\n",
      "train loss:0.01235239086644801\n",
      "train loss:0.002228722751105728\n",
      "train loss:0.019519466882401554\n",
      "train loss:0.037357962094124134\n",
      "train loss:0.036252017220506236\n",
      "train loss:0.005672656565258871\n",
      "train loss:0.0025067653772418374\n",
      "train loss:0.0035275207677937714\n",
      "train loss:0.005402499913473648\n",
      "train loss:0.002538260771155092\n",
      "train loss:0.010169242802388878\n",
      "train loss:0.009166095949507637\n",
      "train loss:0.01146833899402922\n",
      "train loss:0.025190631070392863\n",
      "train loss:0.00819075661804319\n",
      "train loss:0.011566979097889256\n",
      "train loss:0.014973902974541936\n",
      "train loss:0.0037583810983863267\n",
      "train loss:0.028987035590604962\n",
      "train loss:0.014678158721159105\n",
      "train loss:0.009035807119978022\n",
      "train loss:0.008046135791844967\n",
      "train loss:0.010133674087852356\n",
      "train loss:0.0016654989854195243\n",
      "train loss:0.002408266472987075\n",
      "train loss:0.02120396102909315\n",
      "train loss:0.004060267884956939\n",
      "train loss:0.008979873966855735\n",
      "train loss:0.010093760203415852\n",
      "train loss:0.004254940758570983\n",
      "train loss:0.00853915896864692\n",
      "train loss:0.004517695592044274\n",
      "train loss:0.003281313395482014\n",
      "train loss:0.002722791787521895\n",
      "train loss:0.00313105767755042\n",
      "train loss:0.011479132382959225\n",
      "train loss:0.006352599026503489\n",
      "train loss:0.009308239089073333\n",
      "train loss:0.040947708261838585\n",
      "train loss:0.013246936649360512\n",
      "train loss:0.01633769264147823\n",
      "train loss:0.005306567225169391\n",
      "train loss:0.0018566531945677187\n",
      "train loss:0.004971748453122038\n",
      "train loss:0.003989246570333151\n",
      "train loss:0.001008413033734555\n",
      "train loss:0.012254898113762968\n",
      "train loss:0.00622000519604361\n",
      "train loss:0.0020419316291891507\n",
      "train loss:0.003899363857129236\n",
      "train loss:0.002644270312734458\n",
      "train loss:0.005792464638632236\n",
      "train loss:0.008993503616997777\n",
      "train loss:0.0038233274684735153\n",
      "train loss:0.0257509513550775\n",
      "train loss:0.032259063321325866\n",
      "train loss:0.014802828113435328\n",
      "train loss:0.00314827696428736\n",
      "train loss:0.009405252453670748\n",
      "train loss:0.0030983408050793138\n",
      "train loss:0.0055778022398747466\n",
      "train loss:0.003214082849940837\n",
      "train loss:0.007965776109740667\n",
      "train loss:0.001348219144118082\n",
      "train loss:0.004542312037218884\n",
      "train loss:0.010782929701589887\n",
      "train loss:0.0014950723351179764\n",
      "train loss:0.010803860062024172\n",
      "train loss:0.0033691670221893456\n",
      "train loss:0.0076101362851854655\n",
      "train loss:0.001510108949239543\n",
      "train loss:0.04299530345873359\n",
      "train loss:0.014345352502232601\n",
      "train loss:0.001710935613962339\n",
      "train loss:0.0998131263683897\n",
      "train loss:0.004659481896596784\n",
      "train loss:0.006459152205641374\n",
      "train loss:0.0022457945497833796\n",
      "train loss:0.001216921525675361\n",
      "train loss:0.0842132691052423\n",
      "train loss:0.0013963984958519134\n",
      "train loss:0.006219630218448756\n",
      "train loss:0.015522148836196412\n",
      "train loss:0.0015943847093287055\n",
      "train loss:0.0099525112134338\n",
      "train loss:0.006671199165889823\n",
      "train loss:0.0083233708936911\n",
      "train loss:0.00453383494358622\n",
      "train loss:0.006577053163064985\n",
      "train loss:0.0012291106664021874\n",
      "train loss:0.007187817089756291\n",
      "train loss:0.0024372319108963035\n",
      "train loss:0.04024135524151049\n",
      "train loss:0.008616423506767298\n",
      "train loss:0.0035736534414295335\n",
      "train loss:0.021603978744537643\n",
      "train loss:0.006457812192958439\n",
      "train loss:0.03218136442948824\n",
      "train loss:0.0011540629024381604\n",
      "train loss:0.008790326648908496\n",
      "train loss:0.0017466142356273493\n",
      "train loss:0.001882624124334462\n",
      "train loss:0.013009146991092123\n",
      "train loss:0.0015915580979456603\n",
      "train loss:0.0053102544491480785\n",
      "train loss:0.021324637047259218\n",
      "train loss:0.013284834187452112\n",
      "train loss:0.01648426252861852\n",
      "train loss:0.03296396772312072\n",
      "train loss:0.00952549009217086\n",
      "train loss:0.008637684602373451\n",
      "train loss:0.0026004615098802718\n",
      "train loss:0.006607298978733999\n",
      "train loss:0.0007523165417208101\n",
      "train loss:0.0031835981876909155\n",
      "train loss:0.0030994023766525813\n",
      "train loss:0.019604934891830014\n",
      "train loss:0.003573455913298341\n",
      "train loss:0.02409838397397346\n",
      "train loss:0.016671682376901985\n",
      "train loss:0.0052561411090300235\n",
      "train loss:0.022516102294418586\n",
      "train loss:0.027691056456886458\n",
      "train loss:0.015485814804842055\n",
      "train loss:0.001517662610849923\n",
      "train loss:0.023338749562874943\n",
      "train loss:0.001250103135817609\n",
      "train loss:0.002807910882028375\n",
      "train loss:0.007194362064234785\n",
      "train loss:0.0159022725784592\n",
      "train loss:0.00217984384563864\n",
      "train loss:0.00944633636728215\n",
      "train loss:0.004912165743185884\n",
      "train loss:0.009841861714775168\n",
      "train loss:0.004293866116225872\n",
      "train loss:0.006214243621794822\n",
      "train loss:0.004968722783430905\n",
      "train loss:0.003759431945287053\n",
      "train loss:0.0031921976147506396\n",
      "train loss:0.0033102529959903415\n",
      "train loss:0.0035333528636482146\n",
      "train loss:0.02815449294352395\n",
      "train loss:0.0013543112407545072\n",
      "train loss:0.01256929077094849\n",
      "train loss:0.07899184334411907\n",
      "train loss:0.011841029850356453\n",
      "train loss:0.0014562383491521788\n",
      "train loss:0.005049438131195971\n",
      "train loss:0.00579805644565623\n",
      "train loss:0.005771535198849595\n",
      "train loss:0.006836403486651757\n",
      "train loss:0.006025248150720775\n",
      "train loss:0.0051691370856660306\n",
      "train loss:0.00043303051899251405\n",
      "train loss:0.0045029555769334016\n",
      "train loss:0.0011373121635881328\n",
      "train loss:0.001534653222997673\n",
      "train loss:0.019709438943501346\n",
      "train loss:0.011921912820764415\n",
      "train loss:0.011275256942469846\n",
      "train loss:0.002716915499494224\n",
      "train loss:0.0024069052117870206\n",
      "train loss:0.0011378218383917035\n",
      "train loss:0.0030211965907534976\n",
      "train loss:0.003791168936877137\n",
      "train loss:0.004731304817055555\n",
      "train loss:0.002198647574790987\n",
      "train loss:0.007896603511805404\n",
      "train loss:0.004743745857391672\n",
      "train loss:0.02977257942401931\n",
      "train loss:0.005290449493970424\n",
      "train loss:0.015832507783857083\n",
      "train loss:0.03209135484239497\n",
      "train loss:0.008078423544931568\n",
      "train loss:0.0038158551301498756\n",
      "train loss:0.0025439048680831367\n",
      "train loss:0.0009369833602045625\n",
      "train loss:0.0328524959099322\n",
      "train loss:0.004570491712778105\n",
      "train loss:0.0021896184464479706\n",
      "train loss:0.007392258495868606\n",
      "train loss:0.0006776750712593012\n",
      "train loss:0.00029017208981967383\n",
      "train loss:0.02588210719587615\n",
      "train loss:0.004541693931024123\n",
      "train loss:0.06061431777363033\n",
      "train loss:0.012263554503580331\n",
      "train loss:0.0026382900853512098\n",
      "train loss:0.03262005916171375\n",
      "train loss:0.0028907297743026106\n",
      "train loss:0.038061450252793096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0031431430312562386\n",
      "train loss:0.024985743052066987\n",
      "train loss:0.002213295049230323\n",
      "train loss:0.00345149891710365\n",
      "train loss:0.014524166507220134\n",
      "train loss:0.002718946834679966\n",
      "train loss:0.002050121597389877\n",
      "train loss:0.039095542921756356\n",
      "train loss:0.030724397080059633\n",
      "train loss:0.01179396050541498\n",
      "train loss:0.0009199624080506269\n",
      "train loss:0.0040186943605186485\n",
      "train loss:0.005854967254755072\n",
      "train loss:0.003606022706031834\n",
      "train loss:0.0061922323183730065\n",
      "train loss:0.013681248621550466\n",
      "train loss:0.002336918953086079\n",
      "train loss:0.00619312695975189\n",
      "train loss:0.017871554665020405\n",
      "train loss:0.009273794082171242\n",
      "train loss:0.007697836033034279\n",
      "train loss:0.007410087195892578\n",
      "train loss:0.021237081580556573\n",
      "train loss:0.014414262063563806\n",
      "train loss:0.006156904840732374\n",
      "train loss:0.005495040771200951\n",
      "train loss:0.019581934691866743\n",
      "train loss:0.004963503027961145\n",
      "train loss:0.01232248193804468\n",
      "train loss:0.014511613876445317\n",
      "train loss:0.0978837641547757\n",
      "train loss:0.0043150180198097635\n",
      "train loss:0.006306096466444661\n",
      "train loss:0.004321082240787182\n",
      "train loss:0.004297747996840639\n",
      "train loss:0.013329995901735038\n",
      "train loss:0.007962631724574154\n",
      "train loss:0.01125882598967336\n",
      "train loss:0.022721043137094526\n",
      "train loss:0.004159234221345699\n",
      "train loss:0.01075128837041645\n",
      "train loss:0.006599604572025274\n",
      "train loss:0.004337412588439872\n",
      "train loss:0.007878316692548754\n",
      "train loss:0.039063602758914684\n",
      "train loss:0.0013859307506783821\n",
      "train loss:0.005081395581912409\n",
      "train loss:0.05168634029743488\n",
      "train loss:0.008853400200589214\n",
      "train loss:0.022266529300882812\n",
      "train loss:0.004912510113092179\n",
      "train loss:0.0029154755037855335\n",
      "train loss:0.0009988085008377037\n",
      "train loss:0.03549132899085384\n",
      "train loss:0.00954701335811826\n",
      "train loss:0.00535299012931666\n",
      "train loss:0.004559996591905564\n",
      "train loss:0.002235275719216653\n",
      "train loss:0.0004332731254309138\n",
      "train loss:0.007498633204583607\n",
      "train loss:0.007874434343623123\n",
      "train loss:0.004155846740681736\n",
      "train loss:0.0016993615688485817\n",
      "train loss:0.002648363956934535\n",
      "train loss:0.048397706480498515\n",
      "train loss:0.0025099836717361484\n",
      "train loss:0.004609178139905785\n",
      "train loss:0.015899685533259624\n",
      "train loss:0.006781143501843924\n",
      "train loss:0.0018852397703325156\n",
      "train loss:0.008451568630505913\n",
      "train loss:0.0025988993993462887\n",
      "train loss:0.035364200441627955\n",
      "train loss:0.006366443922014411\n",
      "train loss:0.003409101498475166\n",
      "train loss:0.00558531470502747\n",
      "train loss:0.009447090739276102\n",
      "train loss:0.004703146962829178\n",
      "train loss:0.003398701997410488\n",
      "train loss:0.0027672651610237482\n",
      "train loss:0.00372353915048603\n",
      "train loss:0.0032137892739847844\n",
      "train loss:0.005401568563440368\n",
      "train loss:0.007663102018490202\n",
      "train loss:0.028842629413553908\n",
      "train loss:0.006265118337433274\n",
      "train loss:0.0036843944145793996\n",
      "train loss:0.006468462113263554\n",
      "train loss:0.0631911228036763\n",
      "train loss:0.023417603359522962\n",
      "train loss:0.0014158471280583732\n",
      "train loss:0.007377233654836632\n",
      "train loss:0.032934152220043214\n",
      "train loss:0.018036242544531456\n",
      "train loss:0.004790159807655953\n",
      "train loss:0.013790577476399635\n",
      "train loss:0.002713580923514103\n",
      "train loss:0.00725908374734929\n",
      "train loss:0.0016897288956837597\n",
      "train loss:0.007753671012302513\n",
      "train loss:0.0019002587849743513\n",
      "train loss:0.001425025798044478\n",
      "train loss:0.0017203117101718204\n",
      "train loss:0.0014708004225150362\n",
      "train loss:0.028468759094368367\n",
      "train loss:0.0021893635919341685\n",
      "train loss:0.0041018073753163135\n",
      "train loss:0.002930233387835817\n",
      "train loss:0.010787345720795196\n",
      "train loss:0.0020617856462986027\n",
      "train loss:0.013575346520849267\n",
      "train loss:0.005958280778933125\n",
      "train loss:0.02335403296899719\n",
      "train loss:0.004261627410185711\n",
      "train loss:0.007668555917151463\n",
      "train loss:0.004784842566293143\n",
      "train loss:0.0023481240552105987\n",
      "train loss:0.030993890068870524\n",
      "train loss:0.012446681886565973\n",
      "train loss:0.011117746918945093\n",
      "train loss:0.0008633819942407582\n",
      "train loss:0.024746584370350832\n",
      "train loss:0.006946828654252093\n",
      "train loss:0.0025746332748272913\n",
      "train loss:0.012245096917582297\n",
      "train loss:0.0037551259402789283\n",
      "train loss:0.0014435089318263282\n",
      "train loss:0.005007164655831973\n",
      "train loss:0.017152158440720818\n",
      "train loss:0.007740859407510071\n",
      "train loss:0.0011867932681455784\n",
      "train loss:0.0017516157139092086\n",
      "train loss:0.0018086366538369505\n",
      "train loss:0.0026723513332369895\n",
      "train loss:0.004932053256201423\n",
      "train loss:0.0006015913532089162\n",
      "train loss:0.01239305703836678\n",
      "train loss:0.004148722415523636\n",
      "train loss:0.011040299200301933\n",
      "train loss:0.00044661736482930653\n",
      "train loss:0.005227757404683835\n",
      "train loss:0.0021128953772028723\n",
      "train loss:0.00788334632567398\n",
      "train loss:0.002891325301865761\n",
      "train loss:0.0004720460160734073\n",
      "train loss:0.0032718515906412227\n",
      "train loss:0.005388118975341431\n",
      "train loss:0.008062356667284984\n",
      "train loss:0.0035322818977864285\n",
      "train loss:0.016031089250741797\n",
      "train loss:0.001368272229713518\n",
      "train loss:0.021615008469639305\n",
      "train loss:0.005964479816811934\n",
      "train loss:0.032021906440952194\n",
      "train loss:0.003178125630294509\n",
      "train loss:0.0039449755792702905\n",
      "train loss:0.014071768720866162\n",
      "train loss:0.025610006462916637\n",
      "train loss:0.02414085730190421\n",
      "train loss:0.019768789482047983\n",
      "train loss:0.004532305280805744\n",
      "train loss:0.0028419017506990185\n",
      "train loss:0.006742091978999816\n",
      "train loss:0.01160403453360801\n",
      "train loss:0.01561895587391976\n",
      "train loss:0.0038012444339971365\n",
      "train loss:0.020914297274801763\n",
      "train loss:0.0013484565017803812\n",
      "train loss:0.01927730671656853\n",
      "train loss:0.008587529925666991\n",
      "train loss:0.002002956466447533\n",
      "train loss:0.01254477530094124\n",
      "train loss:0.008565310012359675\n",
      "train loss:0.004075204365082097\n",
      "train loss:0.035360658615464925\n",
      "train loss:0.0047699152728405666\n",
      "train loss:0.012141535074631298\n",
      "train loss:0.01728658237919883\n",
      "train loss:0.004901308628308658\n",
      "train loss:0.0033529406974043665\n",
      "train loss:0.006082739814717798\n",
      "train loss:0.01047445785349154\n",
      "train loss:0.009125376899191916\n",
      "train loss:0.003503746072092653\n",
      "train loss:0.001529336771782179\n",
      "train loss:0.004250561704656447\n",
      "train loss:0.004125295152446157\n",
      "train loss:0.0024850788751588507\n",
      "train loss:0.0068099146566011955\n",
      "train loss:0.0056166965839954865\n",
      "train loss:0.002687031919909015\n",
      "train loss:0.002141459254280313\n",
      "train loss:0.0015199528809280054\n",
      "train loss:0.02166337717169902\n",
      "train loss:0.007667731040187677\n",
      "train loss:0.025363571572535163\n",
      "train loss:0.002584241361251478\n",
      "train loss:0.002317566340851367\n",
      "train loss:0.00234018941617455\n",
      "train loss:0.010569859535751189\n",
      "train loss:0.015552404611553746\n",
      "train loss:0.004158867846835565\n",
      "train loss:0.001689505695053249\n",
      "train loss:0.004817245775365759\n",
      "train loss:0.013518408597259352\n",
      "train loss:0.003280458888254282\n",
      "train loss:0.005119044033522283\n",
      "train loss:0.007433422711770181\n",
      "train loss:0.050715761168585644\n",
      "train loss:0.004376311131109743\n",
      "train loss:0.001039330765570804\n",
      "train loss:0.0033482641827250396\n",
      "train loss:0.014939166645135966\n",
      "train loss:0.054749618027227574\n",
      "train loss:0.003720096719325714\n",
      "train loss:0.028929442185336683\n",
      "train loss:0.0035508145870986395\n",
      "train loss:0.0015568235650251258\n",
      "train loss:0.002481655488834259\n",
      "train loss:0.002659584426883507\n",
      "train loss:0.03454882428408332\n",
      "train loss:0.021968319220585918\n",
      "train loss:0.005694328777320037\n",
      "train loss:0.00212410422400052\n",
      "train loss:0.0020152174066849554\n",
      "train loss:0.00905661137598655\n",
      "train loss:0.0037135781253834384\n",
      "train loss:0.0032865540842205773\n",
      "train loss:0.0007368263133625054\n",
      "train loss:0.007508021187540569\n",
      "train loss:0.011030217834808086\n",
      "train loss:0.007809616858549276\n",
      "train loss:0.0020770968785638953\n",
      "train loss:0.006146359135340363\n",
      "train loss:0.016496442859174273\n",
      "train loss:0.0010290337650982946\n",
      "train loss:0.010247458970191092\n",
      "train loss:0.005941574944787229\n",
      "train loss:0.008122243131438119\n",
      "train loss:0.004240938277648758\n",
      "train loss:0.006431523911818705\n",
      "train loss:0.0035527116739447894\n",
      "train loss:0.02084367679140712\n",
      "train loss:0.003520590013019582\n",
      "train loss:0.02217526237517979\n",
      "train loss:0.006411405089151734\n",
      "train loss:0.0046155536458645716\n",
      "train loss:0.017809222826405936\n",
      "train loss:0.015175033060721606\n",
      "train loss:0.0047586712690399725\n",
      "train loss:0.008225353244052163\n",
      "train loss:0.007491594150635549\n",
      "train loss:0.0005788711169222564\n",
      "train loss:0.001747416171753241\n",
      "train loss:0.011719242663114365\n",
      "train loss:0.0007334230801224494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.001630915089056366\n",
      "train loss:0.012724342032056336\n",
      "train loss:0.003805838742512167\n",
      "train loss:0.01350072988763337\n",
      "train loss:0.007138752166105022\n",
      "train loss:0.004059895910494155\n",
      "train loss:0.0035501104269559814\n",
      "train loss:0.0020515071352850515\n",
      "train loss:0.0013317369739159707\n",
      "train loss:0.006561658446610115\n",
      "train loss:0.04598684974839525\n",
      "train loss:0.0018660029798862054\n",
      "train loss:0.0062531463133508654\n",
      "train loss:0.002036496911067891\n",
      "train loss:0.0017934552647027014\n",
      "train loss:0.04320009401829896\n",
      "train loss:0.008626690296919082\n",
      "train loss:0.002236527621860414\n",
      "train loss:0.002833513437066949\n",
      "train loss:0.03405953398992545\n",
      "train loss:0.007074898165471208\n",
      "train loss:0.012600642174517642\n",
      "train loss:0.014157571199926618\n",
      "train loss:0.010745549442182256\n",
      "=== epoch:11, train acc:0.992, test acc:0.984 ===\n",
      "train loss:0.004307622439892008\n",
      "train loss:0.015747516191130195\n",
      "train loss:0.0448196763916179\n",
      "train loss:0.013230862706693335\n",
      "train loss:0.0026460048365213474\n",
      "train loss:0.010104410141422075\n",
      "train loss:0.0005360586782995721\n",
      "train loss:0.022667632476199417\n",
      "train loss:0.0027751685480269708\n",
      "train loss:0.025704350193749906\n",
      "train loss:0.005644947635869559\n",
      "train loss:0.007017383441313657\n",
      "train loss:0.001179891176204827\n",
      "train loss:0.008197141328391354\n",
      "train loss:0.006851506552271558\n",
      "train loss:0.007614078535594041\n",
      "train loss:0.003298328748947942\n",
      "train loss:0.0030843782912257194\n",
      "train loss:0.007742056543664191\n",
      "train loss:0.0068925214272603265\n",
      "train loss:0.06748053898576072\n",
      "train loss:0.010266522497001803\n",
      "train loss:0.0013012980466728693\n",
      "train loss:0.007546036230622869\n",
      "train loss:0.004462874007398012\n",
      "train loss:0.011792616743182186\n",
      "train loss:0.0059146256891641925\n",
      "train loss:0.0011577110497624124\n",
      "train loss:0.0022278647101269355\n",
      "train loss:0.0049107145282771235\n",
      "train loss:0.027602101965317125\n",
      "train loss:0.009585876628821712\n",
      "train loss:0.024182417107421753\n",
      "train loss:0.04764055627454852\n",
      "train loss:0.0280597606258621\n",
      "train loss:0.002294845860919317\n",
      "train loss:0.003865542805539809\n",
      "train loss:0.018496123060559425\n",
      "train loss:0.009630721106878699\n",
      "train loss:0.004591818406286102\n",
      "train loss:0.005986373770659983\n",
      "train loss:0.0021252929353681727\n",
      "train loss:0.004895170040123798\n",
      "train loss:0.0021492024585473076\n",
      "train loss:0.020334618095731304\n",
      "train loss:0.017487327768315932\n",
      "train loss:0.010414931735657234\n",
      "train loss:0.018399583975346044\n",
      "train loss:0.00811835007795306\n",
      "train loss:0.005314607834891159\n",
      "train loss:0.00731863024294208\n",
      "train loss:0.00889175376782083\n",
      "train loss:0.004336238891560626\n",
      "train loss:0.009992939704068192\n",
      "train loss:0.0013951989443868743\n",
      "train loss:0.004186882748291713\n",
      "train loss:0.007924490886176971\n",
      "train loss:0.0028680679213557315\n",
      "train loss:0.0017318597578774627\n",
      "train loss:0.021649058557771904\n",
      "train loss:0.00032556038094123544\n",
      "train loss:0.013657803862052455\n",
      "train loss:0.0058696224683690325\n",
      "train loss:0.005056120296776216\n",
      "train loss:0.06896699490644687\n",
      "train loss:0.0053872228702867096\n",
      "train loss:0.007313547095976352\n",
      "train loss:0.004785378899899445\n",
      "train loss:0.0006533937002588415\n",
      "train loss:0.008794078782581543\n",
      "train loss:0.0034304487556039848\n",
      "train loss:0.011006918758200085\n",
      "train loss:0.006973987454470947\n",
      "train loss:0.0036638408821716133\n",
      "train loss:0.013349638585727464\n",
      "train loss:0.0038902726473850585\n",
      "train loss:0.013303023346491043\n",
      "train loss:0.007693311406549263\n",
      "train loss:0.0071372537348145014\n",
      "train loss:0.002671826447873675\n",
      "train loss:0.004815822641963127\n",
      "train loss:0.003481943119113536\n",
      "train loss:0.0011037400845566327\n",
      "train loss:0.006813075372319266\n",
      "train loss:0.015685402937613398\n",
      "train loss:0.005635839306924846\n",
      "train loss:0.0013235418000783605\n",
      "train loss:0.016871818335183874\n",
      "train loss:0.00375205351342756\n",
      "train loss:0.001992253424532571\n",
      "train loss:0.0029920041155285493\n",
      "train loss:0.005874639746541295\n",
      "train loss:0.007713809955216938\n",
      "train loss:0.006303291930335337\n",
      "train loss:0.004260802456919138\n",
      "train loss:0.002410415306001607\n",
      "train loss:0.03349243170605767\n",
      "train loss:0.002559368872003751\n",
      "train loss:0.012771639497439638\n",
      "train loss:0.000976992325584792\n",
      "train loss:0.002772884608154583\n",
      "train loss:0.002415589683976241\n",
      "train loss:0.006146914199577492\n",
      "train loss:0.011138736584156534\n",
      "train loss:0.006897716785851235\n",
      "train loss:0.011080205470532834\n",
      "train loss:0.0015803334802828774\n",
      "train loss:0.0010667529750076651\n",
      "train loss:0.0032756777465671417\n",
      "train loss:0.003003941981656949\n",
      "train loss:0.004251635964926984\n",
      "train loss:0.003833091487505092\n",
      "train loss:0.024549158189401402\n",
      "train loss:0.0019350722469028614\n",
      "train loss:0.0006846524594154488\n",
      "train loss:0.00028241932343239096\n",
      "train loss:0.001014960330594476\n",
      "train loss:0.0022106636214573074\n",
      "train loss:0.006154084156225877\n",
      "train loss:0.0036144828742062972\n",
      "train loss:0.006508330435978687\n",
      "train loss:0.010058275765402951\n",
      "train loss:0.004980862249579204\n",
      "train loss:0.0026385210673839986\n",
      "train loss:0.0064263458775863595\n",
      "train loss:0.011399008506307427\n",
      "train loss:0.0015471978642536976\n",
      "train loss:0.0033849637043809823\n",
      "train loss:0.004824829298245771\n",
      "train loss:0.0005485342690317581\n",
      "train loss:0.00267186244386037\n",
      "train loss:0.005391819799007813\n",
      "train loss:0.008031426482892621\n",
      "train loss:0.00380721889909754\n",
      "train loss:0.007725053197496332\n",
      "train loss:0.06420341447124671\n",
      "train loss:0.002925176112234897\n",
      "train loss:0.005636876386909316\n",
      "train loss:0.002518352769230207\n",
      "train loss:0.03855857846243011\n",
      "train loss:0.0012501745980572582\n",
      "train loss:0.0032405439076473946\n",
      "train loss:0.008119480687243205\n",
      "train loss:0.0035071149781086192\n",
      "train loss:0.01304343758048497\n",
      "train loss:0.0028324036369718115\n",
      "train loss:0.00383332632450456\n",
      "train loss:0.015588515521313023\n",
      "train loss:0.005042173935712917\n",
      "train loss:0.0035822460034170014\n",
      "train loss:0.003697958946576729\n",
      "train loss:0.002327310282345103\n",
      "train loss:0.015613316949801843\n",
      "train loss:0.002143804034361332\n",
      "train loss:0.006444196077198882\n",
      "train loss:0.002630834516762482\n",
      "train loss:0.0016145522504135274\n",
      "train loss:0.0039442860610888544\n",
      "train loss:0.0012424237251589016\n",
      "train loss:0.009413987569666379\n",
      "train loss:0.001657421566966889\n",
      "train loss:0.024185287149488918\n",
      "train loss:0.001730008941197695\n",
      "train loss:0.004360988218754735\n",
      "train loss:0.0059938178646736905\n",
      "train loss:0.001374050150920585\n",
      "train loss:0.002092559745648793\n",
      "train loss:0.005459321131023053\n",
      "train loss:0.0028353829482902254\n",
      "train loss:0.002661157007933695\n",
      "train loss:0.007800031747457869\n",
      "train loss:0.00457082878633375\n",
      "train loss:0.0039228872748676355\n",
      "train loss:0.011345530878029565\n",
      "train loss:0.0025906008280536814\n",
      "train loss:0.0009526487315775906\n",
      "train loss:0.00039698746021175603\n",
      "train loss:0.0021678090938610697\n",
      "train loss:0.0012111652072794947\n",
      "train loss:0.001841188564375261\n",
      "train loss:0.00872026291330185\n",
      "train loss:0.0011080890561311666\n",
      "train loss:0.004533961189015848\n",
      "train loss:0.001688301103700095\n",
      "train loss:0.013212063697706366\n",
      "train loss:0.0004726191850595341\n",
      "train loss:0.0023258770263642143\n",
      "train loss:0.016110548296490796\n",
      "train loss:0.0028076356998741835\n",
      "train loss:0.009306883053073317\n",
      "train loss:0.0005171737139068544\n",
      "train loss:0.0019007882314785915\n",
      "train loss:0.0008187135593524129\n",
      "train loss:0.00900609096627932\n",
      "train loss:0.0013853318067240062\n",
      "train loss:0.002027227191255357\n",
      "train loss:0.003341231511111069\n",
      "train loss:0.00780898421118458\n",
      "train loss:0.0014329972775761382\n",
      "train loss:0.006788534034620783\n",
      "train loss:0.002124644648490078\n",
      "train loss:0.00368280401757133\n",
      "train loss:0.011080338061703188\n",
      "train loss:0.0449869444679522\n",
      "train loss:0.0008864902554128804\n",
      "train loss:0.0022187735738641496\n",
      "train loss:0.0035222536894304497\n",
      "train loss:0.012308054596548792\n",
      "train loss:0.007200360602310375\n",
      "train loss:0.009711391354547804\n",
      "train loss:0.0022397367677934213\n",
      "train loss:0.008206702744767928\n",
      "train loss:0.03697950307847639\n",
      "train loss:0.001000044480149005\n",
      "train loss:0.0059696247522425\n",
      "train loss:0.0018105548071095882\n",
      "train loss:0.006000933363324404\n",
      "train loss:0.11259330157777526\n",
      "train loss:0.0017794363011016203\n",
      "train loss:0.0060151607464387045\n",
      "train loss:0.005233064931258246\n",
      "train loss:0.0014668620156254805\n",
      "train loss:0.00827290912526153\n",
      "train loss:0.0016643553557426042\n",
      "train loss:0.007341803323786704\n",
      "train loss:0.002944865767061233\n",
      "train loss:0.005479544161627539\n",
      "train loss:0.053575918749407495\n",
      "train loss:0.004125904315236635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0005279071744287673\n",
      "train loss:0.006278680770549685\n",
      "train loss:0.004225079307326195\n",
      "train loss:0.024681185034513296\n",
      "train loss:0.001806353320660376\n",
      "train loss:0.01852525286406236\n",
      "train loss:0.012840498792101656\n",
      "train loss:0.0017525364450157214\n",
      "train loss:0.0058310979890610955\n",
      "train loss:0.014189091469603681\n",
      "train loss:0.0003889265237842415\n",
      "train loss:0.005181021627883364\n",
      "train loss:0.008433824430593694\n",
      "train loss:0.0012170622286088151\n",
      "train loss:0.002983905350776787\n",
      "train loss:0.01514382814651262\n",
      "train loss:0.004754546642001383\n",
      "train loss:0.003967206775485916\n",
      "train loss:0.0032016788967773346\n",
      "train loss:0.009857751694336107\n",
      "train loss:0.00622287525907311\n",
      "train loss:0.0017117822952034498\n",
      "train loss:0.004013367403313819\n",
      "train loss:0.000379153937762964\n",
      "train loss:0.004324480360021198\n",
      "train loss:0.00307124089079076\n",
      "train loss:0.016193457167583046\n",
      "train loss:0.016239861536417495\n",
      "train loss:0.0027067144195496396\n",
      "train loss:0.0013646386141871005\n",
      "train loss:0.0017533555369759538\n",
      "train loss:0.004962657681408921\n",
      "train loss:0.0023163432501564114\n",
      "train loss:0.051319052159680856\n",
      "train loss:0.0025626401408586495\n",
      "train loss:0.008688729435948471\n",
      "train loss:0.003702896741490948\n",
      "train loss:0.0008083233465286417\n",
      "train loss:0.01169931430389166\n",
      "train loss:0.004036234793310535\n",
      "train loss:0.0038053312794681608\n",
      "train loss:0.0047653597793329335\n",
      "train loss:0.0024596257990177222\n",
      "train loss:0.0006209391056657419\n",
      "train loss:0.0013171995439172763\n",
      "train loss:0.006458854279341301\n",
      "train loss:0.007201996494653044\n",
      "train loss:0.0011736152728227213\n",
      "train loss:0.03174137887663674\n",
      "train loss:0.002460878758066537\n",
      "train loss:0.0044689609134911275\n",
      "train loss:0.004297640779161242\n",
      "train loss:0.013184101209273512\n",
      "train loss:0.0016481811109764805\n",
      "train loss:0.005123237984368678\n",
      "train loss:0.009930824904867243\n",
      "train loss:0.011098673081836232\n",
      "train loss:0.0034925891149489422\n",
      "train loss:0.005389338918319758\n",
      "train loss:0.0035176587754954607\n",
      "train loss:0.027397030146452624\n",
      "train loss:0.013767497634760923\n",
      "train loss:0.0016952833099948869\n",
      "train loss:0.0016843830760228237\n",
      "train loss:0.0034197578121326357\n",
      "train loss:0.0016263137890324094\n",
      "train loss:0.0028480606672621213\n",
      "train loss:0.005824009289006329\n",
      "train loss:0.001658105788960095\n",
      "train loss:0.005703428164352999\n",
      "train loss:0.005943134617803964\n",
      "train loss:0.003230334907649402\n",
      "train loss:0.00520359347612417\n",
      "train loss:0.0019078524442988115\n",
      "train loss:0.0008632481335300063\n",
      "train loss:0.001463346643263039\n",
      "train loss:0.0020940001682145278\n",
      "train loss:0.0056242197565679755\n",
      "train loss:0.0005549194139912277\n",
      "train loss:0.002077984093158834\n",
      "train loss:0.0012503404011037253\n",
      "train loss:0.024921357825071443\n",
      "train loss:0.004708931035985875\n",
      "train loss:0.0044319868979281725\n",
      "train loss:0.0015334421621189956\n",
      "train loss:0.000403874691360585\n",
      "train loss:0.0011100731844162208\n",
      "train loss:0.003902962972986726\n",
      "train loss:0.0024121343508377996\n",
      "train loss:0.004733262898294364\n",
      "train loss:0.011114376780575053\n",
      "train loss:0.001235389222472825\n",
      "train loss:0.002798826284713313\n",
      "train loss:0.007325463066002348\n",
      "train loss:0.004707465742259166\n",
      "train loss:0.011218090625500705\n",
      "train loss:0.0096124287782989\n",
      "train loss:0.05733168864811862\n",
      "train loss:0.006233429764817229\n",
      "train loss:0.0005350983990605493\n",
      "train loss:0.00088169462498841\n",
      "train loss:0.0029407690588149865\n",
      "train loss:0.010680961872426755\n",
      "train loss:0.0063545870828821205\n",
      "train loss:0.0011635860460925554\n",
      "train loss:0.013531290505786393\n",
      "train loss:0.008773562943866517\n",
      "train loss:0.008574799427039748\n",
      "train loss:0.007335645284871564\n",
      "train loss:0.002348186920187778\n",
      "train loss:0.007434085694763276\n",
      "train loss:0.0016275223590192858\n",
      "train loss:0.004225252182273489\n",
      "train loss:0.0034393562309097208\n",
      "train loss:0.036449436714142754\n",
      "train loss:0.0029404343373011514\n",
      "train loss:0.010103177303960749\n",
      "train loss:0.027689976005841187\n",
      "train loss:0.002736675903292439\n",
      "train loss:0.002032014834880745\n",
      "train loss:0.00258627175838276\n",
      "train loss:0.010849139345207386\n",
      "train loss:0.07345792442487672\n",
      "train loss:0.0035531894580885866\n",
      "train loss:0.0034329586302944528\n",
      "train loss:0.0021173139140185752\n",
      "train loss:0.03521540819308932\n",
      "train loss:0.0018894783355905068\n",
      "train loss:0.008356783380028994\n",
      "train loss:0.0009493741278303893\n",
      "train loss:0.0028236892905524557\n",
      "train loss:0.00956352262266576\n",
      "train loss:0.009190897020168638\n",
      "train loss:0.012141788267477645\n",
      "train loss:0.00180730791865933\n",
      "train loss:0.008064918012254717\n",
      "train loss:0.002115844805375777\n",
      "train loss:0.003511151212654711\n",
      "train loss:0.0026774111061383275\n",
      "train loss:0.003029682544790151\n",
      "train loss:0.005849830563608366\n",
      "train loss:0.009238674576265184\n",
      "train loss:0.0027698828251534217\n",
      "train loss:0.0024323052142536297\n",
      "train loss:0.0008364887623361312\n",
      "train loss:0.02487464487018975\n",
      "train loss:0.005812872145447533\n",
      "train loss:0.0008349934885439654\n",
      "train loss:0.023476246874857335\n",
      "train loss:0.003920157320488688\n",
      "train loss:0.008710912244023527\n",
      "train loss:0.006068662370574306\n",
      "train loss:0.003574722323857607\n",
      "train loss:0.00213308391482656\n",
      "train loss:0.008843319172902426\n",
      "train loss:0.006693766987789082\n",
      "train loss:0.00720275507718707\n",
      "train loss:0.0005990482338005536\n",
      "train loss:0.0038400146594614365\n",
      "train loss:0.002830580362664038\n",
      "train loss:0.002010027141005912\n",
      "train loss:0.013731788993605824\n",
      "train loss:0.0011601626799089158\n",
      "train loss:0.008518496468512451\n",
      "train loss:0.008509579991812642\n",
      "train loss:0.0035397290864524356\n",
      "train loss:0.003955897736615111\n",
      "train loss:0.005395746474995267\n",
      "train loss:0.000883089520166211\n",
      "train loss:0.03559607004043906\n",
      "train loss:0.003600404010700598\n",
      "train loss:0.000220354180982431\n",
      "train loss:0.002576260184136907\n",
      "train loss:0.01720128925597809\n",
      "train loss:0.0016630764035224642\n",
      "train loss:0.003510287656698907\n",
      "train loss:0.004335026901153397\n",
      "train loss:0.0024883099755725517\n",
      "train loss:0.0017428484097662836\n",
      "train loss:0.009837526502521333\n",
      "train loss:0.027842371911139415\n",
      "train loss:0.021426641217221112\n",
      "train loss:0.0016972111795144041\n",
      "train loss:0.0022679238581216257\n",
      "train loss:0.007621340953102297\n",
      "train loss:0.022486916077583484\n",
      "train loss:0.0010128701972996986\n",
      "train loss:0.002599992777274772\n",
      "train loss:0.0008366414358370098\n",
      "train loss:0.00766156822360333\n",
      "train loss:0.0026827961283417048\n",
      "train loss:0.005455055639086931\n",
      "train loss:0.01155037989220515\n",
      "train loss:0.016604600578081295\n",
      "train loss:0.001359445867889035\n",
      "train loss:0.00969779960113031\n",
      "train loss:0.0005507487323298127\n",
      "train loss:0.0052344936018224745\n",
      "train loss:0.0010477296340352974\n",
      "train loss:0.013260377297498096\n",
      "train loss:0.007285924212344213\n",
      "train loss:0.020566637541682815\n",
      "train loss:0.0023173973801563037\n",
      "train loss:0.012190830572352835\n",
      "train loss:0.001733176890423859\n",
      "train loss:0.008620754178041578\n",
      "train loss:0.003414774347177686\n",
      "train loss:0.007767544982712739\n",
      "train loss:0.0071309589968502445\n",
      "train loss:0.013831615872084344\n",
      "train loss:0.002497124869631992\n",
      "train loss:0.013066127852474239\n",
      "train loss:0.0012037752895643864\n",
      "train loss:0.008182407098185665\n",
      "train loss:0.008569520379992741\n",
      "train loss:0.0007149434566984625\n",
      "train loss:0.002611688971012023\n",
      "train loss:0.008464242562177761\n",
      "train loss:0.001860380497582138\n",
      "train loss:0.003357779163767159\n",
      "train loss:0.002293447294580838\n",
      "train loss:0.006411721670358369\n",
      "train loss:0.0033304605857758557\n",
      "train loss:0.003002251284858406\n",
      "train loss:0.009865559487218435\n",
      "train loss:0.0021193681533901872\n",
      "train loss:0.0030802709347109054\n",
      "train loss:0.0018339679635426109\n",
      "train loss:0.0037156994780056384\n",
      "train loss:0.0018640225281974917\n",
      "train loss:0.002021723501219801\n",
      "train loss:0.007090298840774476\n",
      "train loss:0.0005368136318812975\n",
      "train loss:0.0031465622949483113\n",
      "train loss:0.05522989848292007\n",
      "train loss:0.0024043305621235596\n",
      "train loss:0.0027148109242636277\n",
      "train loss:0.008281836343888765\n",
      "train loss:0.004030282380969251\n",
      "train loss:0.0054542741554294925\n",
      "train loss:0.008217012589190663\n",
      "train loss:0.0022924584068043886\n",
      "train loss:0.01741305318276988\n",
      "train loss:0.0015310706403872058\n",
      "train loss:0.04291096490821685\n",
      "train loss:0.0005721721580593051\n",
      "train loss:0.00298760100075592\n",
      "train loss:0.0020252578424720478\n",
      "train loss:0.0015606854665354561\n",
      "train loss:0.0019342582355070489\n",
      "train loss:0.020042674817517828\n",
      "train loss:0.007549026786516544\n",
      "train loss:0.003862921752116387\n",
      "train loss:0.007024017761202009\n",
      "train loss:0.000805464457409813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0010217140639731145\n",
      "train loss:0.0007242053695117889\n",
      "train loss:0.001957971859729439\n",
      "train loss:0.00840838057979146\n",
      "train loss:0.002157918264070005\n",
      "train loss:0.004986294152600737\n",
      "train loss:0.004599346723502085\n",
      "train loss:0.0013190974601274682\n",
      "train loss:0.006792198932905105\n",
      "train loss:0.04599439549942413\n",
      "train loss:0.005645165174244795\n",
      "train loss:0.0009290911095179177\n",
      "train loss:0.0031433544976965755\n",
      "train loss:0.007518110380078264\n",
      "train loss:0.0014600852637208237\n",
      "train loss:0.05247001192955647\n",
      "train loss:0.001737848002831774\n",
      "train loss:0.0020495432947024816\n",
      "train loss:0.0018380883081915433\n",
      "train loss:0.001596713173800413\n",
      "train loss:0.003621755827872554\n",
      "train loss:0.010232627260918616\n",
      "train loss:0.006534782373880072\n",
      "train loss:0.008079034674181293\n",
      "train loss:0.00429992713299907\n",
      "train loss:0.00820162789464434\n",
      "train loss:0.010253949089964999\n",
      "train loss:0.12460933978368406\n",
      "train loss:0.004692283721802514\n",
      "train loss:0.03972873870777931\n",
      "train loss:0.011707652704609193\n",
      "train loss:0.002139555763368885\n",
      "train loss:0.0010019854937470913\n",
      "train loss:0.0017054529525680812\n",
      "train loss:0.005947569733208693\n",
      "train loss:0.005667776564482954\n",
      "train loss:0.0017338657014636352\n",
      "train loss:0.01342987202582347\n",
      "train loss:0.01174533432862767\n",
      "train loss:0.0016247557709919125\n",
      "train loss:0.005006408948045924\n",
      "train loss:0.006481478034933988\n",
      "train loss:0.0014566805628488957\n",
      "train loss:0.001444504639409463\n",
      "train loss:0.007054429860249634\n",
      "train loss:0.015259408221724313\n",
      "train loss:0.0014374353223054115\n",
      "train loss:0.02812535870175728\n",
      "train loss:0.01774656764269907\n",
      "train loss:0.0031885423559604932\n",
      "train loss:0.018323117806490808\n",
      "train loss:0.036415947401628374\n",
      "train loss:0.002442584431619278\n",
      "train loss:0.019900723293688506\n",
      "train loss:0.0017867699227221761\n",
      "train loss:0.0054853225453424005\n",
      "train loss:0.0037159672600312944\n",
      "train loss:0.02302515688535218\n",
      "train loss:0.003877724830254392\n",
      "train loss:0.005660971035194807\n",
      "train loss:0.0036035139544334854\n",
      "train loss:0.014467833614869403\n",
      "train loss:0.009953890649746699\n",
      "train loss:0.002108378266941763\n",
      "train loss:0.005644952057562982\n",
      "train loss:0.0029406874598851174\n",
      "train loss:0.0024473907105753852\n",
      "train loss:0.037457596874175755\n",
      "train loss:0.0020005534537047274\n",
      "train loss:0.014046787381873543\n",
      "train loss:0.004441928649583793\n",
      "train loss:0.0012137775198060813\n",
      "train loss:0.0021876569077791713\n",
      "train loss:0.0036634621506441926\n",
      "train loss:0.0017723059401218793\n",
      "train loss:0.007651693624762452\n",
      "train loss:0.008356695376452953\n",
      "train loss:0.0036156540507972313\n",
      "train loss:0.007481837913790677\n",
      "train loss:0.0055238491637558665\n",
      "train loss:0.0024499369694003324\n",
      "train loss:0.004209381666058263\n",
      "train loss:0.004549573385217219\n",
      "train loss:0.004210649975837976\n",
      "train loss:0.0008149859213653313\n",
      "train loss:0.008953927892638222\n",
      "train loss:0.0014731805448264844\n",
      "train loss:0.011613326057690049\n",
      "train loss:0.0013481968197614057\n",
      "train loss:0.0027587411624723905\n",
      "train loss:0.0009975556390698162\n",
      "train loss:0.008032333561323365\n",
      "train loss:0.0019924806424830846\n",
      "train loss:0.007424529017217458\n",
      "train loss:0.004949622142822446\n",
      "train loss:0.0010732058252421652\n",
      "train loss:0.001259536266858437\n",
      "train loss:0.03959490520686406\n",
      "train loss:0.0069033623513489436\n",
      "train loss:0.005168429469718412\n",
      "train loss:0.011644010199688066\n",
      "train loss:0.002291452729631144\n",
      "train loss:0.0011188539978909885\n",
      "train loss:0.0043722578340271\n",
      "train loss:0.005729710613228638\n",
      "train loss:0.002928149014524393\n",
      "train loss:0.006165013536405905\n",
      "train loss:0.0024388565005298134\n",
      "train loss:0.0024552219958356215\n",
      "train loss:0.0037601148377668947\n",
      "train loss:0.0070566984823894055\n",
      "train loss:0.007485706098886332\n",
      "train loss:0.014784867896449052\n",
      "train loss:0.002086159122833234\n",
      "train loss:0.0007199707385002439\n",
      "train loss:0.0002858908579786652\n",
      "=== epoch:12, train acc:0.996, test acc:0.986 ===\n",
      "train loss:0.010408317820928699\n",
      "train loss:0.006522892501180679\n",
      "train loss:0.006500250054204886\n",
      "train loss:0.03220667589478423\n",
      "train loss:0.006309521828005505\n",
      "train loss:0.003596435940464509\n",
      "train loss:0.04183483136841312\n",
      "train loss:0.003148947799080496\n",
      "train loss:0.004620148891020275\n",
      "train loss:0.0026686097001094367\n",
      "train loss:0.001781609133730109\n",
      "train loss:0.004110997746371374\n",
      "train loss:0.003619363289796671\n",
      "train loss:0.002846742447125223\n",
      "train loss:0.005813015175952564\n",
      "train loss:0.0004934857797886819\n",
      "train loss:0.004946777783121994\n",
      "train loss:0.008005812037584534\n",
      "train loss:0.013412206716247831\n",
      "train loss:0.0012465768098265046\n",
      "train loss:0.005872559716668118\n",
      "train loss:0.006529701581353515\n",
      "train loss:0.007345883472647259\n",
      "train loss:0.00997088390081171\n",
      "train loss:0.001728805796857445\n",
      "train loss:0.004539369340542484\n",
      "train loss:0.00660935293829498\n",
      "train loss:0.0011103610165247558\n",
      "train loss:0.0020636144935532283\n",
      "train loss:0.0031959454153905205\n",
      "train loss:0.004252641945524196\n",
      "train loss:0.0015943477399328622\n",
      "train loss:0.0009440336865388136\n",
      "train loss:0.01910652544929267\n",
      "train loss:0.00910381953388859\n",
      "train loss:0.0026703742936854944\n",
      "train loss:0.0013463367964299039\n",
      "train loss:0.004339676274267825\n",
      "train loss:0.005298415291986306\n",
      "train loss:0.01961380210627982\n",
      "train loss:0.027354817185464408\n",
      "train loss:0.001929462729504382\n",
      "train loss:0.004333802077202071\n",
      "train loss:0.008378386687125025\n",
      "train loss:0.007963126014835922\n",
      "train loss:0.0065384391703710186\n",
      "train loss:0.006934856785588322\n",
      "train loss:0.006907988754547415\n",
      "train loss:0.049617585660429134\n",
      "train loss:0.005212665275633417\n",
      "train loss:0.004015941545979268\n",
      "train loss:0.0006112180051985056\n",
      "train loss:0.005539789366653406\n",
      "train loss:0.0017171449713485646\n",
      "train loss:0.008029815262618834\n",
      "train loss:0.0028352588265760145\n",
      "train loss:0.0012931911658193983\n",
      "train loss:0.0030633624851718892\n",
      "train loss:0.0008100269763665593\n",
      "train loss:0.004866958160275765\n",
      "train loss:0.013653215009485069\n",
      "train loss:0.01202762286775792\n",
      "train loss:0.0010167404597308499\n",
      "train loss:0.015592152530674554\n",
      "train loss:0.009938300663996667\n",
      "train loss:0.016647761913973966\n",
      "train loss:0.0019280964410727647\n",
      "train loss:0.007434487886127035\n",
      "train loss:0.007841579305228224\n",
      "train loss:0.008413244042772381\n",
      "train loss:0.02005987483320045\n",
      "train loss:0.0005301886882485573\n",
      "train loss:0.005603679079172073\n",
      "train loss:0.00804203884173626\n",
      "train loss:0.0004754454552540776\n",
      "train loss:0.0101466641372662\n",
      "train loss:0.0009080852288152446\n",
      "train loss:0.006697351223325531\n",
      "train loss:0.0008796281498909682\n",
      "train loss:0.014969727565848247\n",
      "train loss:0.010188953447598369\n",
      "train loss:0.004775934551828589\n",
      "train loss:0.0016051193074112147\n",
      "train loss:0.0036376789116534854\n",
      "train loss:0.005451630739032931\n",
      "train loss:0.0011372789218133303\n",
      "train loss:0.0026411561174882604\n",
      "train loss:0.018686894174298804\n",
      "train loss:0.019347644090767963\n",
      "train loss:0.001617993222765464\n",
      "train loss:0.006692778901939544\n",
      "train loss:0.0006594825491930962\n",
      "train loss:0.002459562763589657\n",
      "train loss:0.028233793887864594\n",
      "train loss:0.0010375755598706906\n",
      "train loss:0.004073620320314233\n",
      "train loss:0.0006837792417774235\n",
      "train loss:0.005190348112256147\n",
      "train loss:0.010003795934851987\n",
      "train loss:0.007688107040591407\n",
      "train loss:0.06848257373349666\n",
      "train loss:0.0011179039182890435\n",
      "train loss:0.009044651490846883\n",
      "train loss:0.0033256467465108347\n",
      "train loss:0.0038919034273237657\n",
      "train loss:0.014202572100059341\n",
      "train loss:0.010141852651346232\n",
      "train loss:0.003021161255704495\n",
      "train loss:0.0011716305018761278\n",
      "train loss:0.012055328966021992\n",
      "train loss:0.01666880114251917\n",
      "train loss:0.007745738333142471\n",
      "train loss:0.01252596497616853\n",
      "train loss:0.006407034178478891\n",
      "train loss:0.005865446286108795\n",
      "train loss:0.00455282572393462\n",
      "train loss:0.004756339315316308\n",
      "train loss:0.00202164375825472\n",
      "train loss:0.0008754489104361888\n",
      "train loss:0.006281599444536868\n",
      "train loss:0.0006224504827768148\n",
      "train loss:0.010061797305080016\n",
      "train loss:0.00556398270064702\n",
      "train loss:0.003450193023709213\n",
      "train loss:0.003127841741650456\n",
      "train loss:0.0022279363795028873\n",
      "train loss:0.0006947163619947267\n",
      "train loss:0.0006339016261157132\n",
      "train loss:0.00524690082354575\n",
      "train loss:0.003702599983382426\n",
      "train loss:0.0024556431538376292\n",
      "train loss:0.001410042891219184\n",
      "train loss:0.006102246041654892\n",
      "train loss:0.008585529450392643\n",
      "train loss:0.0071476109753258335\n",
      "train loss:0.0032376978071706835\n",
      "train loss:0.004001422341838533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0010856561374916827\n",
      "train loss:0.0009880620309674667\n",
      "train loss:0.003740889345446669\n",
      "train loss:0.00479851554733515\n",
      "train loss:0.001563408987911935\n",
      "train loss:0.002092914879666774\n",
      "train loss:0.002817533701643027\n",
      "train loss:0.003612134349438289\n",
      "train loss:0.0002380604624401601\n",
      "train loss:0.006419230618829335\n",
      "train loss:0.0007740057595061328\n",
      "train loss:0.0010889559534666478\n",
      "train loss:0.0012463233699816622\n",
      "train loss:0.0020239974338196074\n",
      "train loss:0.01406217795377705\n",
      "train loss:0.0008374695395258992\n",
      "train loss:0.0020614926849899353\n",
      "train loss:0.002783139473600871\n",
      "train loss:0.004564341222025192\n",
      "train loss:0.0024755304338326786\n",
      "train loss:0.0009640349703658915\n",
      "train loss:0.0009295262402500483\n",
      "train loss:0.005298993622913203\n",
      "train loss:0.0012106801533031564\n",
      "train loss:0.0034075019759881287\n",
      "train loss:0.015242822208711933\n",
      "train loss:0.0016782513296782597\n",
      "train loss:0.005913679104300581\n",
      "train loss:0.0008418863465993255\n",
      "train loss:0.0005566700981759753\n",
      "train loss:0.000734480507841342\n",
      "train loss:0.0011572062756383685\n",
      "train loss:0.006219379168298102\n",
      "train loss:0.002390467972591277\n",
      "train loss:0.000987865984471604\n",
      "train loss:0.0074723280723976125\n",
      "train loss:0.004976661938917774\n",
      "train loss:0.008205993057063292\n",
      "train loss:0.0005525403816444005\n",
      "train loss:0.00043857783969735575\n",
      "train loss:0.014347591710845606\n",
      "train loss:0.0011927981597327471\n",
      "train loss:0.0013579022757913828\n",
      "train loss:0.0025298478125970634\n",
      "train loss:0.0012399236933804821\n",
      "train loss:0.01237213698930936\n",
      "train loss:0.025665340673941647\n",
      "train loss:0.03829458315462238\n",
      "train loss:0.004092529841133468\n",
      "train loss:0.00583630165621587\n",
      "train loss:0.0017508181934504372\n",
      "train loss:0.008243637473430173\n",
      "train loss:0.0009228809334885118\n",
      "train loss:0.002592745338311578\n",
      "train loss:0.01911227956983091\n",
      "train loss:0.0019771910912458807\n",
      "train loss:0.0038262380424566754\n",
      "train loss:0.0014985811912165484\n",
      "train loss:0.002037971859411814\n",
      "train loss:0.0022648839040914723\n",
      "train loss:0.0059062936120855445\n",
      "train loss:0.001407109981220442\n",
      "train loss:0.0014895987210788509\n",
      "train loss:0.0024588846228964715\n",
      "train loss:0.000860100709014767\n",
      "train loss:0.002364927362429026\n",
      "train loss:0.012189224049233352\n",
      "train loss:0.005176007700564322\n",
      "train loss:0.001669564435650596\n",
      "train loss:0.0016277076340918642\n",
      "train loss:0.009837832743403252\n",
      "train loss:0.0031778453123076245\n",
      "train loss:0.0019317195472886043\n",
      "train loss:0.007599766124915983\n",
      "train loss:0.006932397734806834\n",
      "train loss:0.004676214792589368\n",
      "train loss:0.02282374625495951\n",
      "train loss:0.0038335959890375975\n",
      "train loss:0.006719543833011855\n",
      "train loss:0.0009158802382704512\n",
      "train loss:0.00535927312290733\n",
      "train loss:0.0046687597261829555\n",
      "train loss:0.0020112753658696114\n",
      "train loss:0.008112624435995879\n",
      "train loss:0.006569062998500006\n",
      "train loss:0.004655606950140783\n",
      "train loss:0.010246067682987851\n",
      "train loss:0.0005302310513110465\n",
      "train loss:0.016437101216458683\n",
      "train loss:0.003285777705331699\n",
      "train loss:0.003793499378695103\n",
      "train loss:0.002242546433909564\n",
      "train loss:0.03574726717416517\n",
      "train loss:0.0037501393859458755\n",
      "train loss:0.0020878999177943044\n",
      "train loss:0.0032963531056376255\n",
      "train loss:0.0025293965631340916\n",
      "train loss:0.002367560132413977\n",
      "train loss:0.000840233150291183\n",
      "train loss:0.00943817059250924\n",
      "train loss:0.015711542895397505\n",
      "train loss:0.02634980238669749\n",
      "train loss:0.008382647790575367\n",
      "train loss:0.0018198768637051274\n",
      "train loss:0.001520340659960028\n",
      "train loss:0.00045456816232945953\n",
      "train loss:0.0017168441335004016\n",
      "train loss:0.001775597004120345\n",
      "train loss:0.0016067329356617421\n",
      "train loss:0.009685937642621562\n",
      "train loss:0.004236744000950735\n",
      "train loss:0.0032936530599868563\n",
      "train loss:0.007573359498811617\n",
      "train loss:0.003070183827999082\n",
      "train loss:0.006025997887557168\n",
      "train loss:0.011941837393431558\n",
      "train loss:0.0033818106450857082\n",
      "train loss:0.0012689881576924747\n",
      "train loss:0.0033230454093122214\n",
      "train loss:0.028170611730233698\n",
      "train loss:0.0012811886739692985\n",
      "train loss:0.009837449371063156\n",
      "train loss:0.001054983264522988\n",
      "train loss:0.0011898632649917633\n",
      "train loss:0.0033608846779517483\n",
      "train loss:0.002217167594306255\n",
      "train loss:0.00418259488370993\n",
      "train loss:0.004260584640296982\n",
      "train loss:0.003533067969679118\n",
      "train loss:0.012651996621049773\n",
      "train loss:0.0007720972220232107\n",
      "train loss:0.010449221580287453\n",
      "train loss:0.01181193394569348\n",
      "train loss:0.00341280245470171\n",
      "train loss:0.0011431704544999323\n",
      "train loss:0.0023093237603715056\n",
      "train loss:0.0029749888427344374\n",
      "train loss:0.00775333247941022\n",
      "train loss:0.00686430754901581\n",
      "train loss:0.0027623810679156696\n",
      "train loss:0.014956576595980884\n",
      "train loss:0.006005353708765159\n",
      "train loss:0.005517404803858134\n",
      "train loss:0.0007858338604771603\n",
      "train loss:0.011826486464261668\n",
      "train loss:0.010428302606485123\n",
      "train loss:0.018813580042357347\n",
      "train loss:0.0015722379825561128\n",
      "train loss:0.010330419699734063\n",
      "train loss:0.0017431560044963155\n",
      "train loss:0.007375362685996894\n",
      "train loss:0.001564059642866027\n",
      "train loss:0.0020610777853188682\n",
      "train loss:0.004116478154514697\n",
      "train loss:0.004725204036675504\n",
      "train loss:0.005177244577247924\n",
      "train loss:0.0003231787090882679\n",
      "train loss:0.0015907433410409216\n",
      "train loss:0.0007078889697077165\n",
      "train loss:0.002144018508392793\n",
      "train loss:0.005220278581308743\n",
      "train loss:0.003265947240137562\n",
      "train loss:0.002407131909679617\n",
      "train loss:0.0010933133351711329\n",
      "train loss:0.0007245818796588317\n",
      "train loss:0.004997205978995656\n",
      "train loss:0.0009451137279633397\n",
      "train loss:0.0026528896560901434\n",
      "train loss:0.0019318666821901338\n",
      "train loss:0.00035083702146640526\n",
      "train loss:0.002115589681998397\n",
      "train loss:0.0019913709548390387\n",
      "train loss:0.001529492146090319\n",
      "train loss:0.0035551917141649876\n",
      "train loss:0.010789561480806209\n",
      "train loss:0.0033525439331270825\n",
      "train loss:0.00413675098879406\n",
      "train loss:0.003484510659484365\n",
      "train loss:0.002856905757139188\n",
      "train loss:0.0002688852280109016\n",
      "train loss:0.01312406338860645\n",
      "train loss:0.00560930342903045\n",
      "train loss:0.00033688797376392167\n",
      "train loss:0.030607129390241194\n",
      "train loss:0.0032942096702988162\n",
      "train loss:0.0015750798436576924\n",
      "train loss:0.001760645444424965\n",
      "train loss:0.0009564249267504858\n",
      "train loss:0.002130377551054745\n",
      "train loss:0.0030041154224202233\n",
      "train loss:0.0040105148093538415\n",
      "train loss:0.023687319425899755\n",
      "train loss:0.009348583855568337\n",
      "train loss:0.0027830957575739716\n",
      "train loss:0.00911812247465797\n",
      "train loss:0.0033894054608899094\n",
      "train loss:0.0032006594382260217\n",
      "train loss:0.004677973893910469\n",
      "train loss:0.014201373913853677\n",
      "train loss:0.0061074592663851466\n",
      "train loss:0.0042706163118003985\n",
      "train loss:0.0034634918516125174\n",
      "train loss:0.0022582346577215474\n",
      "train loss:0.0006773901838140864\n",
      "train loss:0.026518980787911976\n",
      "train loss:0.012245192850934292\n",
      "train loss:0.0011160935308781256\n",
      "train loss:0.0047251092194114394\n",
      "train loss:0.01990821997147317\n",
      "train loss:0.032331335159084526\n",
      "train loss:0.020521383656279805\n",
      "train loss:0.0006432320733858335\n",
      "train loss:0.0025090966951244508\n",
      "train loss:0.009084852467896731\n",
      "train loss:0.0026338963174819797\n",
      "train loss:0.006475230616771217\n",
      "train loss:0.00035613619286860537\n",
      "train loss:0.00684702441161655\n",
      "train loss:0.06122660224886549\n",
      "train loss:0.002187485910256388\n",
      "train loss:0.04476319533812121\n",
      "train loss:0.0023547345075324365\n",
      "train loss:0.0008907855918049084\n",
      "train loss:0.0025669176085938122\n",
      "train loss:0.006871658050632688\n",
      "train loss:0.010644954490770608\n",
      "train loss:0.0035672129491816267\n",
      "train loss:0.007734327839865882\n",
      "train loss:0.007778220040325889\n",
      "train loss:0.005629644656548239\n",
      "train loss:0.0019120454872740738\n",
      "train loss:0.02223684563391581\n",
      "train loss:0.0069996611041180405\n",
      "train loss:0.041039319948170366\n",
      "train loss:0.0032689625562357795\n",
      "train loss:0.006193185906994625\n",
      "train loss:0.0042433425943279824\n",
      "train loss:0.0006607496770590994\n",
      "train loss:0.028750423598240742\n",
      "train loss:0.005200595027651792\n",
      "train loss:0.022524274193421095\n",
      "train loss:0.005659955227589609\n",
      "train loss:0.0008587745204246558\n",
      "train loss:0.005429152988082201\n",
      "train loss:0.012491424028478105\n",
      "train loss:0.0028328445893024846\n",
      "train loss:0.00446669506569084\n",
      "train loss:0.009790699900469418\n",
      "train loss:0.003716221880149059\n",
      "train loss:0.0030495187350054243\n",
      "train loss:0.006288624349849027\n",
      "train loss:0.005589273342571545\n",
      "train loss:0.004720128721733111\n",
      "train loss:0.010881186575416056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002001439512434665\n",
      "train loss:0.003404852736105135\n",
      "train loss:0.0032306279761344704\n",
      "train loss:0.020223636310635604\n",
      "train loss:0.0014875310763801247\n",
      "train loss:0.0014731021922909384\n",
      "train loss:0.014408531202031827\n",
      "train loss:0.0022404577784856726\n",
      "train loss:0.001913316756905963\n",
      "train loss:0.0060685811415877085\n",
      "train loss:0.0004193038626278977\n",
      "train loss:0.0008575683479277036\n",
      "train loss:0.0035579873375579827\n",
      "train loss:0.004372333188198523\n",
      "train loss:0.003168058236901974\n",
      "train loss:0.01233702784438638\n",
      "train loss:0.02560181523437093\n",
      "train loss:0.005548995330031991\n",
      "train loss:0.011585689658593759\n",
      "train loss:0.0011536793702108564\n",
      "train loss:0.002893363586098676\n",
      "train loss:0.023791668901688993\n",
      "train loss:0.001956981926973817\n",
      "train loss:0.06427736651656268\n",
      "train loss:0.014127247089675532\n",
      "train loss:0.03609622300917088\n",
      "train loss:0.005051734375881023\n",
      "train loss:0.052356053961604754\n",
      "train loss:0.0073772064579669385\n",
      "train loss:0.016657573067707793\n",
      "train loss:0.001141067545592059\n",
      "train loss:0.0031309409932814385\n",
      "train loss:0.004263911189256944\n",
      "train loss:0.0025913252218669174\n",
      "train loss:0.0009149370585688882\n",
      "train loss:0.00523001267595542\n",
      "train loss:0.005664274466679045\n",
      "train loss:0.005366667224274452\n",
      "train loss:0.004704731392142935\n",
      "train loss:0.005072829576064107\n",
      "train loss:0.007489773327372702\n",
      "train loss:0.0034980066829029166\n",
      "train loss:0.000867042501102249\n",
      "train loss:0.006453194309124559\n",
      "train loss:0.0025403725092422056\n",
      "train loss:0.01566986764161439\n",
      "train loss:0.0007636803639704012\n",
      "train loss:0.006409460388743143\n",
      "train loss:0.00802360825713832\n",
      "train loss:0.021899208504284083\n",
      "train loss:0.0009562920999209947\n",
      "train loss:0.008989627483203349\n",
      "train loss:0.004613808469635366\n",
      "train loss:0.02336779676414085\n",
      "train loss:0.0057714872382514035\n",
      "train loss:0.0025298526776150413\n",
      "train loss:0.0045327554996470835\n",
      "train loss:0.0026611113279883065\n",
      "train loss:0.010593148928634541\n",
      "train loss:0.005293130184268111\n",
      "train loss:0.008343523751097\n",
      "train loss:0.012136114658820725\n",
      "train loss:0.0076925473953562825\n",
      "train loss:0.0014581443745879676\n",
      "train loss:0.007443320443987369\n",
      "train loss:0.0028251430920579936\n",
      "train loss:0.0011814068487668225\n",
      "train loss:0.008562299336310104\n",
      "train loss:0.0016891948936518025\n",
      "train loss:0.002428765103497026\n",
      "train loss:0.0008630897424832325\n",
      "train loss:0.0010427937948434\n",
      "train loss:0.026111146471174195\n",
      "train loss:0.005798002534607116\n",
      "train loss:0.0018032364796137779\n",
      "train loss:0.0044027622544581925\n",
      "train loss:0.006403834308657784\n",
      "train loss:0.0032156752428737206\n",
      "train loss:0.012724970779848226\n",
      "train loss:0.002463768267111057\n",
      "train loss:0.002138905380639531\n",
      "train loss:0.007217890556060853\n",
      "train loss:0.0015421038072337386\n",
      "train loss:0.004535283776742104\n",
      "train loss:0.0031977458222258604\n",
      "train loss:0.06315930399060479\n",
      "train loss:0.00181253454422026\n",
      "train loss:0.0016147823443417577\n",
      "train loss:0.001533980957773311\n",
      "train loss:0.005150800366048874\n",
      "train loss:0.01184955818417143\n",
      "train loss:0.012172842383335538\n",
      "train loss:0.0008628776356565949\n",
      "train loss:0.002717347708408771\n",
      "train loss:0.007352041117779977\n",
      "train loss:0.025448800158758958\n",
      "train loss:0.0019908743764615704\n",
      "train loss:0.002214825981880104\n",
      "train loss:0.0005604769995901897\n",
      "train loss:0.007001929737384695\n",
      "train loss:0.005932881128657205\n",
      "train loss:0.01953490313481489\n",
      "train loss:0.003890933895025462\n",
      "train loss:0.005813661029089267\n",
      "train loss:0.00532960309942812\n",
      "train loss:0.008914794996579026\n",
      "train loss:0.010015770859497777\n",
      "train loss:0.00027218400713397177\n",
      "train loss:0.0006067828027935482\n",
      "train loss:0.0003382325619810513\n",
      "train loss:0.004008739679957773\n",
      "train loss:0.003813897064351016\n",
      "train loss:0.0012432287814546496\n",
      "train loss:0.0026000518295841556\n",
      "train loss:0.0015670404518891073\n",
      "train loss:0.0020011812834525113\n",
      "train loss:0.015815021343764505\n",
      "train loss:0.0013480062519087746\n",
      "train loss:0.03835313931826628\n",
      "train loss:0.039174104615671106\n",
      "train loss:0.003649464210316139\n",
      "train loss:0.001439100070190262\n",
      "train loss:0.003169142657543999\n",
      "train loss:0.0008063689853064819\n",
      "train loss:0.010516362751430636\n",
      "train loss:0.01137348890535731\n",
      "train loss:0.0005539240242492587\n",
      "train loss:0.0005688205194536662\n",
      "train loss:0.0031563606428958294\n",
      "train loss:0.008740611210202106\n",
      "train loss:0.0152823631820806\n",
      "train loss:0.003493581347780704\n",
      "train loss:0.0063140368156956094\n",
      "train loss:0.002220903483901864\n",
      "train loss:0.0019718065518838594\n",
      "train loss:0.0013950038778108062\n",
      "train loss:0.0034732446865477083\n",
      "train loss:0.0020558416670681816\n",
      "train loss:0.002174661882013344\n",
      "train loss:0.012164774793277043\n",
      "train loss:0.0019683613224414434\n",
      "train loss:0.012813819854643105\n",
      "train loss:0.0026265016125518125\n",
      "train loss:0.007201354365897189\n",
      "train loss:0.014760206235812357\n",
      "train loss:0.006747142521664545\n",
      "train loss:0.012605282912616138\n",
      "train loss:0.012765250733240524\n",
      "train loss:0.0029562697303406747\n",
      "train loss:0.00040759548579433473\n",
      "train loss:0.004306239180690513\n",
      "train loss:0.005042579443260653\n",
      "train loss:0.002807942604430121\n",
      "train loss:0.001155455694407146\n",
      "train loss:0.010103477958300702\n",
      "train loss:0.005785176952621155\n",
      "train loss:0.006935621135361674\n",
      "train loss:0.0025021585479900917\n",
      "train loss:0.002819450803706219\n",
      "train loss:0.002800845391588143\n",
      "train loss:0.0036273755773182075\n",
      "train loss:0.00047441897825659953\n",
      "train loss:0.008425604086327466\n",
      "train loss:0.009854589413019038\n",
      "train loss:0.02603410915988669\n",
      "train loss:0.010385097774455551\n",
      "train loss:0.0032176365738385217\n",
      "train loss:0.0019024614297932399\n",
      "train loss:0.0011844663942759614\n",
      "train loss:0.005699846607195981\n",
      "train loss:0.032583461085337405\n",
      "train loss:0.003550010514872401\n",
      "train loss:0.0011753650539224813\n",
      "train loss:0.0058719858956107355\n",
      "train loss:0.0037212026501522964\n",
      "train loss:0.0016637529468018436\n",
      "train loss:0.0010144261551651656\n",
      "train loss:0.02249192901708492\n",
      "train loss:0.02960524609934184\n",
      "train loss:0.005728736987834581\n",
      "train loss:0.0006360743643592132\n",
      "train loss:0.0007354217795119075\n",
      "train loss:0.004085829790768385\n",
      "train loss:0.00019858891103443347\n",
      "train loss:0.0016910503741205786\n",
      "train loss:0.0023747893043217015\n",
      "train loss:0.014240560975818148\n",
      "train loss:0.012513396595723819\n",
      "train loss:0.003841514227886138\n",
      "train loss:0.005705779192282076\n",
      "train loss:0.006138106238637343\n",
      "train loss:0.006949085344133684\n",
      "train loss:0.001482447703265233\n",
      "train loss:0.006840125248883424\n",
      "train loss:0.021747342639534182\n",
      "train loss:0.001637241752927224\n",
      "train loss:0.003877313456476702\n",
      "train loss:0.0040930531011704055\n",
      "train loss:0.002683644725099587\n",
      "train loss:0.008166126014514042\n",
      "train loss:0.006301529988919767\n",
      "train loss:0.002233908663387484\n",
      "train loss:0.005063133287735911\n",
      "train loss:0.013253749351245408\n",
      "train loss:0.0016191066695808232\n",
      "train loss:0.008616027894180225\n",
      "train loss:0.002706907828541\n",
      "train loss:0.0028878176182687075\n",
      "train loss:0.0029824899348942484\n",
      "=== epoch:13, train acc:0.997, test acc:0.991 ===\n",
      "train loss:0.006120188853995422\n",
      "train loss:0.0036746665562441137\n",
      "train loss:0.004259082862315696\n",
      "train loss:0.04209272108736114\n",
      "train loss:0.0011500573673995649\n",
      "train loss:0.00443205991404767\n",
      "train loss:0.0018114039036866442\n",
      "train loss:0.0014927242875980371\n",
      "train loss:0.0038831905868930883\n",
      "train loss:0.0010565360688595342\n",
      "train loss:0.007105690681092648\n",
      "train loss:0.0069314243646409505\n",
      "train loss:0.004977354677516256\n",
      "train loss:0.003978259811682785\n",
      "train loss:0.0006681249545863942\n",
      "train loss:0.01610481868496871\n",
      "train loss:0.003739247635010422\n",
      "train loss:0.01317586850110599\n",
      "train loss:0.001954058345044396\n",
      "train loss:0.0019123653600213039\n",
      "train loss:0.008821393835788529\n",
      "train loss:0.0048034314999008225\n",
      "train loss:0.0028236109540445815\n",
      "train loss:0.000618861485469081\n",
      "train loss:0.0012485742052163863\n",
      "train loss:0.00046394228956618734\n",
      "train loss:0.007181308780289565\n",
      "train loss:0.00024645169301980253\n",
      "train loss:0.005661792559005283\n",
      "train loss:0.0008731974197803782\n",
      "train loss:0.00496014687567267\n",
      "train loss:0.0002712045586615773\n",
      "train loss:0.022334784498771004\n",
      "train loss:0.004245398423149616\n",
      "train loss:0.003303411077446652\n",
      "train loss:0.01104602778631035\n",
      "train loss:0.004098940496470553\n",
      "train loss:0.0019232868573472908\n",
      "train loss:0.0046951766305161815\n",
      "train loss:0.00039535514997183585\n",
      "train loss:0.001954035641285476\n",
      "train loss:0.002046566215061573\n",
      "train loss:0.001005314434666125\n",
      "train loss:0.0007803965124136956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0004488613857973844\n",
      "train loss:0.002051594818025156\n",
      "train loss:0.003867607594463085\n",
      "train loss:0.0028730991908961488\n",
      "train loss:0.003364022530328249\n",
      "train loss:0.005818287931055693\n",
      "train loss:0.0012460110664967588\n",
      "train loss:0.004081330181290991\n",
      "train loss:0.003691984677018561\n",
      "train loss:0.0047423879073656226\n",
      "train loss:0.0009467391938714542\n",
      "train loss:0.007595574349137335\n",
      "train loss:0.0040296459018048045\n",
      "train loss:0.004075670109574781\n",
      "train loss:0.011079070935966957\n",
      "train loss:0.0036519211295973734\n",
      "train loss:0.029200607085207584\n",
      "train loss:0.0013527400125392885\n",
      "train loss:0.011138711785063033\n",
      "train loss:0.006277785019342064\n",
      "train loss:0.0010619319475027084\n",
      "train loss:0.005440513254230437\n",
      "train loss:0.00665964621814215\n",
      "train loss:0.006985954038523043\n",
      "train loss:0.000684221094537928\n",
      "train loss:0.001426158115544567\n",
      "train loss:0.010446198017466353\n",
      "train loss:0.0014889266246574774\n",
      "train loss:0.012433274519919072\n",
      "train loss:0.007477343270999468\n",
      "train loss:0.029255598665825458\n",
      "train loss:0.0020007513455272113\n",
      "train loss:0.0008175811453458601\n",
      "train loss:0.0008440018218244541\n",
      "train loss:0.009653219728565029\n",
      "train loss:0.0007571627623147865\n",
      "train loss:0.008587699014973124\n",
      "train loss:0.022808886267588754\n",
      "train loss:0.0082277860956894\n",
      "train loss:0.00021470659625554022\n",
      "train loss:0.005607923363685865\n",
      "train loss:0.0037137171674955127\n",
      "train loss:0.017609704474167053\n",
      "train loss:0.0034769038298742474\n",
      "train loss:0.0005448998014056566\n",
      "train loss:0.0018829971190091484\n",
      "train loss:0.0038881387763001858\n",
      "train loss:0.0036104214449784932\n",
      "train loss:0.003262821903189203\n",
      "train loss:0.0028447552173667457\n",
      "train loss:0.0024799626022892728\n",
      "train loss:0.0038839970916878137\n",
      "train loss:0.008940062742015033\n",
      "train loss:0.0010120976358081542\n",
      "train loss:0.0005636954230150755\n",
      "train loss:0.02059146505328472\n",
      "train loss:0.004990062192305275\n",
      "train loss:0.004163220225275526\n",
      "train loss:0.03063828742787273\n",
      "train loss:0.002007477503347119\n",
      "train loss:0.0033304939603823564\n",
      "train loss:0.004109846284312622\n",
      "train loss:0.006700431283439053\n",
      "train loss:0.0025329876446307594\n",
      "train loss:0.0004410525063361149\n",
      "train loss:0.0009371165746479128\n",
      "train loss:0.004487036124088384\n",
      "train loss:0.026581250547047554\n",
      "train loss:0.01762962993212457\n",
      "train loss:0.01956371854702841\n",
      "train loss:0.004989741306587014\n",
      "train loss:0.003856879534126935\n",
      "train loss:0.0007466784041199709\n",
      "train loss:0.0055627036112943975\n",
      "train loss:0.008807225217100726\n",
      "train loss:0.003066350016225923\n",
      "train loss:0.006693933425878101\n",
      "train loss:0.0036706313152280916\n",
      "train loss:0.0411475374331233\n",
      "train loss:0.0019097677499026258\n",
      "train loss:0.003205572514996326\n",
      "train loss:0.0012305836834264876\n",
      "train loss:0.00035743965289002306\n",
      "train loss:0.004426195766188134\n",
      "train loss:0.0011879794137598682\n",
      "train loss:0.001474408682575242\n",
      "train loss:0.0017906294302966563\n",
      "train loss:0.020946579560650866\n",
      "train loss:0.004441432204216202\n",
      "train loss:0.007915435468809425\n",
      "train loss:0.0032261501394372193\n",
      "train loss:0.0004833632113356221\n",
      "train loss:0.003650375759461858\n",
      "train loss:0.00047066369343476557\n",
      "train loss:0.00045514004970119675\n",
      "train loss:0.006355130351885654\n",
      "train loss:0.0017173907969500767\n",
      "train loss:0.0010947953149117306\n",
      "train loss:0.004866736981368726\n",
      "train loss:0.001286255252296722\n",
      "train loss:0.0021793294537043677\n",
      "train loss:0.0012340894854829271\n",
      "train loss:0.003604282453817057\n",
      "train loss:0.0017315213257679458\n",
      "train loss:0.004307662857450598\n",
      "train loss:0.0067557269417815\n",
      "train loss:0.0002498647528079089\n",
      "train loss:0.0013890375949151181\n",
      "train loss:0.0012755888906105298\n",
      "train loss:0.0017013579288825504\n",
      "train loss:0.04439223798229983\n",
      "train loss:0.010349146009661777\n",
      "train loss:0.008532336391145125\n",
      "train loss:0.004857889287555338\n",
      "train loss:0.0017297288234582578\n",
      "train loss:0.002502643739602785\n",
      "train loss:0.0064675849655555385\n",
      "train loss:0.0006844061064288448\n",
      "train loss:0.0022438502408222913\n",
      "train loss:0.0052865971912033115\n",
      "train loss:0.0007531209226100945\n",
      "train loss:0.015479484713858807\n",
      "train loss:0.0007565565598482918\n",
      "train loss:0.020653346416695445\n",
      "train loss:0.007269913565912294\n",
      "train loss:0.0009722267908775019\n",
      "train loss:0.006287233959244461\n",
      "train loss:0.0014669334495340904\n",
      "train loss:0.015343159372837683\n",
      "train loss:0.011315525938723345\n",
      "train loss:0.009710884522770667\n",
      "train loss:0.004815911978592002\n",
      "train loss:0.0008590661795036215\n",
      "train loss:0.001645936024584038\n",
      "train loss:0.000339398963073367\n",
      "train loss:0.0017811399031074646\n",
      "train loss:0.004808792594140191\n",
      "train loss:0.006868657125190734\n",
      "train loss:0.006310645526202395\n",
      "train loss:0.005138746690711707\n",
      "train loss:0.008391124234266419\n",
      "train loss:0.00033775266718436697\n",
      "train loss:0.0002252912988150321\n",
      "train loss:0.0012162388001688835\n",
      "train loss:0.0028631071555118696\n",
      "train loss:0.0035112977894131412\n",
      "train loss:0.005503114743330777\n",
      "train loss:0.001863796080115297\n",
      "train loss:0.0002745056914112491\n",
      "train loss:0.0006874030365749287\n",
      "train loss:0.003320390352707431\n",
      "train loss:0.0015665381627229674\n",
      "train loss:0.003542963214968512\n",
      "train loss:0.0005480553227041839\n",
      "train loss:0.0037998870576350955\n",
      "train loss:0.0011173711923413232\n",
      "train loss:0.006418877155450871\n",
      "train loss:0.002803409403773817\n",
      "train loss:0.00937227520247673\n",
      "train loss:0.050220540389210325\n",
      "train loss:0.0004108106150315813\n",
      "train loss:0.003611905347757502\n",
      "train loss:0.020808337354497677\n",
      "train loss:0.006799525058307454\n",
      "train loss:0.0036408649869857108\n",
      "train loss:0.029410474714749536\n",
      "train loss:0.0005941219400699712\n",
      "train loss:0.006543483755759391\n",
      "train loss:0.005348689576098314\n",
      "train loss:0.0003661288329387334\n",
      "train loss:0.008356766651889627\n",
      "train loss:0.009687246711708043\n",
      "train loss:0.0024474444901392244\n",
      "train loss:0.007905946267498985\n",
      "train loss:0.0052162215189455905\n",
      "train loss:0.0012101676143108848\n",
      "train loss:0.007770070200528129\n",
      "train loss:0.0008659538237446733\n",
      "train loss:0.004696455630599266\n",
      "train loss:0.005722298005822728\n",
      "train loss:0.0018547882244374409\n",
      "train loss:0.011397058273784389\n",
      "train loss:0.0037419381904513827\n",
      "train loss:0.0005424107389983945\n",
      "train loss:0.007351491273097101\n",
      "train loss:0.00219629474661039\n",
      "train loss:0.010932639057258704\n",
      "train loss:0.004644438684533753\n",
      "train loss:0.00015267887914410957\n",
      "train loss:0.0012486135992318481\n",
      "train loss:0.011917918456979704\n",
      "train loss:0.0015197907311772162\n",
      "train loss:0.014774948320678554\n",
      "train loss:0.0020899680702800684\n",
      "train loss:0.00467720612005464\n",
      "train loss:0.004884596914514013\n",
      "train loss:0.004642634094946025\n",
      "train loss:0.012919908136443331\n",
      "train loss:0.0037045837749929067\n",
      "train loss:0.011687599429994294\n",
      "train loss:0.002782446373528519\n",
      "train loss:0.0015871849341098424\n",
      "train loss:0.022233266378091615\n",
      "train loss:0.006947268404982414\n",
      "train loss:0.0038668364744524624\n",
      "train loss:0.0020253902931641372\n",
      "train loss:0.0009733804076874309\n",
      "train loss:0.005093060732630164\n",
      "train loss:0.001846511873948511\n",
      "train loss:0.002836111615421781\n",
      "train loss:0.014174040916432477\n",
      "train loss:0.0009314829293055727\n",
      "train loss:0.007473745249817492\n",
      "train loss:0.005394731096822639\n",
      "train loss:0.0023595781881703757\n",
      "train loss:0.0065507844997836785\n",
      "train loss:0.00020313360500666885\n",
      "train loss:0.0014158980117420375\n",
      "train loss:0.012761695164226903\n",
      "train loss:0.0039392551892207806\n",
      "train loss:0.006063255153540201\n",
      "train loss:0.0034577052006263377\n",
      "train loss:0.004918218397455131\n",
      "train loss:0.002363210691078444\n",
      "train loss:0.002052835659824308\n",
      "train loss:0.00313926837721111\n",
      "train loss:0.0007805466603476432\n",
      "train loss:0.00019145933298517836\n",
      "train loss:0.0019295709098108742\n",
      "train loss:0.019306461538746864\n",
      "train loss:0.0029352744301507235\n",
      "train loss:0.00262460898039861\n",
      "train loss:0.0013791812447476314\n",
      "train loss:0.00697539649428138\n",
      "train loss:0.003932885271601929\n",
      "train loss:0.029033364175720576\n",
      "train loss:0.0021631342280954945\n",
      "train loss:0.0016218136804869922\n",
      "train loss:0.0009546744726794611\n",
      "train loss:0.005862873586109024\n",
      "train loss:0.0008497963669903075\n",
      "train loss:0.008931625872434857\n",
      "train loss:0.003475993560271705\n",
      "train loss:0.010148190501150938\n",
      "train loss:0.0006974271078559415\n",
      "train loss:0.0068690177939764495\n",
      "train loss:0.0011601221028078694\n",
      "train loss:0.003703833715926149\n",
      "train loss:0.005954125898429959\n",
      "train loss:0.003287599215322643\n",
      "train loss:0.0001339342515239806\n",
      "train loss:0.01256817742905679\n",
      "train loss:0.005364911789075313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0008882035942411738\n",
      "train loss:0.001792712383642349\n",
      "train loss:0.0009920910287768714\n",
      "train loss:0.0006701814815193506\n",
      "train loss:0.0047724773752522145\n",
      "train loss:0.0015575480431393232\n",
      "train loss:0.014730975169777555\n",
      "train loss:0.0013581245267369486\n",
      "train loss:0.01095572618699078\n",
      "train loss:0.006134437295957824\n",
      "train loss:0.0007360495066833335\n",
      "train loss:0.0006768246621490433\n",
      "train loss:0.0002921675241518721\n",
      "train loss:0.005989454580567766\n",
      "train loss:0.004244252022714662\n",
      "train loss:0.005773388823541749\n",
      "train loss:0.0008620944596799947\n",
      "train loss:0.0036287920150126275\n",
      "train loss:0.0013719442509390115\n",
      "train loss:0.0008099428598400558\n",
      "train loss:0.000254097498857572\n",
      "train loss:0.0034710723448763215\n",
      "train loss:0.0002725140167315228\n",
      "train loss:0.0015447096942707624\n",
      "train loss:0.0014468391267923055\n",
      "train loss:0.0034819342211283894\n",
      "train loss:0.0025944342820695535\n",
      "train loss:0.014412602162405667\n",
      "train loss:0.013294096970834\n",
      "train loss:8.016899788255875e-05\n",
      "train loss:0.013094981932311433\n",
      "train loss:0.003926465732753551\n",
      "train loss:0.01362610057902651\n",
      "train loss:0.002425076075461641\n",
      "train loss:0.0035226481652751275\n",
      "train loss:0.002500392472205071\n",
      "train loss:0.0026781211097804607\n",
      "train loss:0.009926173937993865\n",
      "train loss:0.0027790246962154292\n",
      "train loss:0.0016914673731106152\n",
      "train loss:0.005353112106392635\n",
      "train loss:0.000710462806407046\n",
      "train loss:0.0006719483250303318\n",
      "train loss:0.0048583554091457745\n",
      "train loss:0.002023577205218013\n",
      "train loss:0.006451638910048831\n",
      "train loss:0.01647866690170386\n",
      "train loss:0.0003249214705049872\n",
      "train loss:0.0010777703559736048\n",
      "train loss:0.005069526927079182\n",
      "train loss:0.0012946711894174575\n",
      "train loss:0.0044168255276556\n",
      "train loss:0.0025436114714058235\n",
      "train loss:0.003310708518942011\n",
      "train loss:0.004614685535515928\n",
      "train loss:0.00631097298669317\n",
      "train loss:0.0005146554669928737\n",
      "train loss:0.0010433399432804662\n",
      "train loss:0.005675968618258634\n",
      "train loss:0.001241854541215229\n",
      "train loss:0.006147029124291033\n",
      "train loss:0.007235578259317124\n",
      "train loss:0.0025347117967836853\n",
      "train loss:0.006954730370858048\n",
      "train loss:0.0017979309923590128\n",
      "train loss:0.004916133897045511\n",
      "train loss:0.0026788823227717096\n",
      "train loss:0.005234248176965907\n",
      "train loss:0.00329538587009849\n",
      "train loss:0.001719672035129728\n",
      "train loss:0.0036888859618704833\n",
      "train loss:0.011533178284801868\n",
      "train loss:0.0018115725780897905\n",
      "train loss:0.001124648935861789\n",
      "train loss:0.0022283686349398673\n",
      "train loss:0.0004528471867847984\n",
      "train loss:0.002362261782422664\n",
      "train loss:0.00044926403756846277\n",
      "train loss:0.0011931615250273227\n",
      "train loss:0.013402514257828482\n",
      "train loss:0.024403851026011742\n",
      "train loss:0.0015863367672165971\n",
      "train loss:0.017626332026221783\n",
      "train loss:0.000724474546843741\n",
      "train loss:0.003669493054372025\n",
      "train loss:0.0005354232024154951\n",
      "train loss:0.0030203674354539072\n",
      "train loss:0.0019360355226954512\n",
      "train loss:0.0032980125964982626\n",
      "train loss:0.0002907034434587274\n",
      "train loss:0.003604680587128843\n",
      "train loss:0.004365081103223842\n",
      "train loss:0.0023897788795920454\n",
      "train loss:0.013227350623210636\n",
      "train loss:0.0004614762979861487\n",
      "train loss:0.015327125764722864\n",
      "train loss:0.03611289365224633\n",
      "train loss:0.001530822568482184\n",
      "train loss:0.003193797734594405\n",
      "train loss:0.0021176699772699555\n",
      "train loss:0.0026087659367797357\n",
      "train loss:0.0017318531859644448\n",
      "train loss:0.003573367959364025\n",
      "train loss:0.00574058811861479\n",
      "train loss:0.0014046498631111947\n",
      "train loss:0.003892590578614937\n",
      "train loss:8.554052108646503e-05\n",
      "train loss:0.003251388648915844\n",
      "train loss:0.001051997768697743\n",
      "train loss:0.0003349274701033382\n",
      "train loss:0.002375822579025895\n",
      "train loss:0.0010494510636293935\n",
      "train loss:0.04520552683376443\n",
      "train loss:0.0020556095399145748\n",
      "train loss:0.0002880990633993433\n",
      "train loss:0.0035078502354429887\n",
      "train loss:0.002069899574604296\n",
      "train loss:0.001648237447096429\n",
      "train loss:0.004319922397508047\n",
      "train loss:0.003889874886809688\n",
      "train loss:0.00022663394954641197\n",
      "train loss:0.001112071204087537\n",
      "train loss:0.0013560184504860704\n",
      "train loss:0.0022924234922058937\n",
      "train loss:0.035938206208781895\n",
      "train loss:0.004372735246863548\n",
      "train loss:0.0018856951450584463\n",
      "train loss:0.001329371418645487\n",
      "train loss:0.002435188212241312\n",
      "train loss:0.004323479309121079\n",
      "train loss:0.0054305259905559\n",
      "train loss:0.0010682709993869118\n",
      "train loss:0.009443986541867504\n",
      "train loss:0.004434481125617742\n",
      "train loss:0.0003581938321964715\n",
      "train loss:0.0003370600694757387\n",
      "train loss:0.0005236141274539217\n",
      "train loss:0.017242380098087203\n",
      "train loss:0.00041165578969424644\n",
      "train loss:0.004891258508017492\n",
      "train loss:0.0008352235038920696\n",
      "train loss:0.002666888303964035\n",
      "train loss:0.009221945249041751\n",
      "train loss:0.004951204550231132\n",
      "train loss:0.001143015493777385\n",
      "train loss:0.006239051522649648\n",
      "train loss:0.0007534441795473895\n",
      "train loss:0.0061945570982694775\n",
      "train loss:0.0013884529498149158\n",
      "train loss:0.00041006295013377834\n",
      "train loss:0.0013309948420329612\n",
      "train loss:0.0022834573994234887\n",
      "train loss:0.0022550713940194655\n",
      "train loss:0.0019744338386009377\n",
      "train loss:0.0005529491651775655\n",
      "train loss:0.002321633812911354\n",
      "train loss:0.0007168263163145436\n",
      "train loss:0.0033254631187052473\n",
      "train loss:0.0009200934727462432\n",
      "train loss:0.0022660619431848976\n",
      "train loss:0.0011144658422814167\n",
      "train loss:0.0002822218724040177\n",
      "train loss:0.0007688198770166986\n",
      "train loss:0.0004575674436734896\n",
      "train loss:0.00540357684106443\n",
      "train loss:0.006290722188251944\n",
      "train loss:0.0045267831191569815\n",
      "train loss:0.002630429194644421\n",
      "train loss:0.0026000191871598834\n",
      "train loss:0.00015046177346676192\n",
      "train loss:0.01634740151861392\n",
      "train loss:0.0009420790918822929\n",
      "train loss:0.0005662891417573937\n",
      "train loss:0.0018072439228537316\n",
      "train loss:0.0071649813124563\n",
      "train loss:0.0011607243377195018\n",
      "train loss:0.00038670419530870614\n",
      "train loss:0.0009777524611800216\n",
      "train loss:0.000518781488607506\n",
      "train loss:0.000143927707822846\n",
      "train loss:0.0018055552100810451\n",
      "train loss:0.005672016516904677\n",
      "train loss:0.02969017410782047\n",
      "train loss:0.0024555925429981603\n",
      "train loss:0.005775929794626699\n",
      "train loss:0.000621897007042594\n",
      "train loss:0.0017345865266839287\n",
      "train loss:0.0015277645537418512\n",
      "train loss:0.005829485366152218\n",
      "train loss:0.0036588401630252144\n",
      "train loss:0.002512649494112156\n",
      "train loss:0.0027566644525275556\n",
      "train loss:0.0032655918670556794\n",
      "train loss:0.000816040095886063\n",
      "train loss:0.002948450428682629\n",
      "train loss:0.0012542070020196612\n",
      "train loss:0.005105455763870765\n",
      "train loss:0.0005181547765168082\n",
      "train loss:0.0007657935442697232\n",
      "train loss:0.00027063282475449694\n",
      "train loss:0.00031685854120735865\n",
      "train loss:0.0003243824267089996\n",
      "train loss:0.0032689376781528828\n",
      "train loss:0.001369782289634406\n",
      "train loss:0.0007698486670650869\n",
      "train loss:0.0023347027609432356\n",
      "train loss:0.003867942442990697\n",
      "train loss:0.005911131851376639\n",
      "train loss:0.0018208172857053654\n",
      "train loss:0.0010303916097886934\n",
      "train loss:0.013162859745020818\n",
      "train loss:0.001295554749793626\n",
      "train loss:0.002727142747135146\n",
      "train loss:0.0051680704463890285\n",
      "train loss:0.005027883934440328\n",
      "train loss:0.005568123434616918\n",
      "train loss:0.002776186941691265\n",
      "train loss:0.002430221951853313\n",
      "train loss:0.010566008591991654\n",
      "train loss:0.0004814743564339786\n",
      "train loss:0.005630830683998456\n",
      "train loss:0.0006654529442508559\n",
      "train loss:0.0034770717755718663\n",
      "train loss:0.0008814971900131842\n",
      "train loss:0.0017540352994442354\n",
      "train loss:0.006895008546957205\n",
      "train loss:0.0007450805456476097\n",
      "train loss:0.0005079063450642842\n",
      "train loss:0.001439885280950641\n",
      "train loss:0.007335621834069752\n",
      "train loss:0.0059000853873658774\n",
      "train loss:0.004534236871357003\n",
      "train loss:0.0015960331556640838\n",
      "train loss:0.004767256328724187\n",
      "train loss:0.07931172848726445\n",
      "train loss:0.0006866192301116594\n",
      "train loss:0.006357248531132484\n",
      "train loss:0.00014846173639633173\n",
      "train loss:0.031838851892474214\n",
      "train loss:0.0009916101367542982\n",
      "train loss:0.0009469946667748793\n",
      "train loss:0.0044931543176964265\n",
      "train loss:0.002622475530952072\n",
      "train loss:0.0030219415284863447\n",
      "train loss:0.0003446529409218857\n",
      "train loss:0.0011304905469226927\n",
      "train loss:0.00031114696837679026\n",
      "train loss:0.002488159739229842\n",
      "train loss:0.0005226159678677145\n",
      "train loss:0.004055836677779495\n",
      "train loss:0.01432042784635769\n",
      "train loss:0.0016760280788632792\n",
      "train loss:0.0008736600010169446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.007435280223367889\n",
      "train loss:0.0026293163057502867\n",
      "train loss:0.0012104735463043578\n",
      "train loss:0.0020044139019653492\n",
      "train loss:0.0010505037601288873\n",
      "train loss:0.004320988080510177\n",
      "train loss:0.004029587267802865\n",
      "train loss:0.001235716791745618\n",
      "train loss:0.01103907054296485\n",
      "train loss:0.0014215255593414348\n",
      "train loss:0.0008879005830943311\n",
      "train loss:0.002584851091165424\n",
      "train loss:0.00025496808629994603\n",
      "train loss:0.0010951209171580244\n",
      "train loss:0.0007965319560327438\n",
      "train loss:0.005587426554259581\n",
      "train loss:0.04882297575190471\n",
      "train loss:0.0032995654362205774\n",
      "train loss:0.0061903976242143055\n",
      "train loss:0.0056592344635452655\n",
      "train loss:0.0009506847187924035\n",
      "train loss:0.00649867315370212\n",
      "train loss:0.0007451680658580858\n",
      "train loss:0.00012247742274346208\n",
      "train loss:0.0030253904983236707\n",
      "train loss:0.07785151047712048\n",
      "train loss:0.0030635865885382755\n",
      "train loss:0.005995463607468613\n",
      "train loss:0.0009255783290950396\n",
      "train loss:0.0011703044721657566\n",
      "train loss:0.006938665447245643\n",
      "train loss:0.02318575157704169\n",
      "train loss:0.0013133831332411761\n",
      "train loss:0.006078923567145876\n",
      "train loss:0.003926090603866109\n",
      "train loss:0.02353806114055634\n",
      "train loss:0.007715505133814726\n",
      "train loss:0.002398356235167663\n",
      "train loss:0.003552673365368297\n",
      "train loss:0.0020439972427056846\n",
      "train loss:0.0016669195524062483\n",
      "train loss:0.0010939074882908948\n",
      "train loss:0.002339962221660363\n",
      "train loss:0.0054641159183013155\n",
      "train loss:0.0016022054106155706\n",
      "train loss:0.011984479700739572\n",
      "train loss:0.004296840803573372\n",
      "train loss:0.008082797045192512\n",
      "train loss:0.012181140715042574\n",
      "train loss:0.01038677315530968\n",
      "=== epoch:14, train acc:0.997, test acc:0.987 ===\n",
      "train loss:0.0033875621325678367\n",
      "train loss:0.0026595493819004308\n",
      "train loss:0.0021446876242229617\n",
      "train loss:0.0017864203512277877\n",
      "train loss:0.0016973900260729158\n",
      "train loss:0.0005253183007278777\n",
      "train loss:0.008318215362587672\n",
      "train loss:0.001702592876923717\n",
      "train loss:0.00022283804169868367\n",
      "train loss:0.0019497211068462614\n",
      "train loss:0.009434364718565284\n",
      "train loss:0.0041838492336066175\n",
      "train loss:0.01206231371485905\n",
      "train loss:0.014999303570522626\n",
      "train loss:0.0006348822613173887\n",
      "train loss:0.000600526333795399\n",
      "train loss:0.002416796870204261\n",
      "train loss:0.0030878468316212567\n",
      "train loss:0.05043431477267338\n",
      "train loss:0.016928575810741336\n",
      "train loss:0.0038057491967923023\n",
      "train loss:0.004754548601020872\n",
      "train loss:0.00938719276303333\n",
      "train loss:0.0015320580864897262\n",
      "train loss:0.0852233924202766\n",
      "train loss:0.0023478958560973003\n",
      "train loss:0.004541927015653402\n",
      "train loss:0.001549646045830446\n",
      "train loss:0.0027227909904820186\n",
      "train loss:0.007644708408192817\n",
      "train loss:0.0008980461298624667\n",
      "train loss:0.0014322928888245972\n",
      "train loss:0.0006563983230618174\n",
      "train loss:0.0017705260590790612\n",
      "train loss:0.007668167531481561\n",
      "train loss:0.0013963201431513278\n",
      "train loss:0.0013333876850197784\n",
      "train loss:0.003548287437702308\n",
      "train loss:0.001352406420167197\n",
      "train loss:0.0024537130453643878\n",
      "train loss:0.002509623945611015\n",
      "train loss:0.004394417131701563\n",
      "train loss:0.000850281530627683\n",
      "train loss:0.0050389711220514685\n",
      "train loss:0.0026061790604213226\n",
      "train loss:0.001940024681363011\n",
      "train loss:0.0023800406114999435\n",
      "train loss:0.008473500940959973\n",
      "train loss:0.0016559024438763542\n",
      "train loss:0.0012523411758121614\n",
      "train loss:0.0008410655788202061\n",
      "train loss:0.002435300476267758\n",
      "train loss:0.00034979479288316343\n",
      "train loss:0.006457721910763818\n",
      "train loss:0.004589295053861176\n",
      "train loss:0.008184222738528783\n",
      "train loss:0.006456414447059343\n",
      "train loss:0.0048986722109108155\n",
      "train loss:0.004981405453122707\n",
      "train loss:0.00012916538108423937\n",
      "train loss:0.001009368696357303\n",
      "train loss:0.00123058867235444\n",
      "train loss:0.0003179067423378884\n",
      "train loss:0.0007420450032717006\n",
      "train loss:0.0007575950948527463\n",
      "train loss:0.005594349177488292\n",
      "train loss:0.001861173957299183\n",
      "train loss:0.00019594279859536817\n",
      "train loss:0.004495729666024399\n",
      "train loss:0.0006161261173127998\n",
      "train loss:0.0004214800495680353\n",
      "train loss:0.0021712027950225154\n",
      "train loss:0.0017749103090789929\n",
      "train loss:0.006227266040683517\n",
      "train loss:0.014177203014495057\n",
      "train loss:0.0007827323122593935\n",
      "train loss:0.006516372964519997\n",
      "train loss:0.0005373902871067087\n",
      "train loss:6.46766307563827e-05\n",
      "train loss:0.0013654278398354017\n",
      "train loss:0.011914100731912403\n",
      "train loss:0.006241799908169588\n",
      "train loss:0.0009859869860670638\n",
      "train loss:0.0045483510551503\n",
      "train loss:0.002004097554402125\n",
      "train loss:0.004512911804938164\n",
      "train loss:0.0007888059370326638\n",
      "train loss:0.004501773101253344\n",
      "train loss:0.0005335199463979174\n",
      "train loss:0.013057970841947623\n",
      "train loss:0.0007874492626564323\n",
      "train loss:0.005943600171614089\n",
      "train loss:0.002023297957811644\n",
      "train loss:0.002429974993620444\n",
      "train loss:0.0016903051765894861\n",
      "train loss:0.00035573929782577364\n",
      "train loss:0.006429867394346932\n",
      "train loss:0.010455777226335498\n",
      "train loss:0.0026108710734281688\n",
      "train loss:0.00033805650176265626\n",
      "train loss:0.008196501668322002\n",
      "train loss:0.004593853671871774\n",
      "train loss:0.0027737901825106597\n",
      "train loss:0.007089425498070315\n",
      "train loss:0.006958512595211222\n",
      "train loss:0.00431271919063882\n",
      "train loss:0.005617877006803209\n",
      "train loss:0.0013086309062128095\n",
      "train loss:0.0017044454082839858\n",
      "train loss:0.015382800337808079\n",
      "train loss:0.0006415594953280417\n",
      "train loss:0.003261367474859665\n",
      "train loss:0.0026200203360133493\n",
      "train loss:0.0008388050199901688\n",
      "train loss:0.0036153429880041244\n",
      "train loss:0.0005309049179246383\n",
      "train loss:0.007312019699946795\n",
      "train loss:0.0023861558139579154\n",
      "train loss:0.0028665341985111216\n",
      "train loss:0.0021599716215280136\n",
      "train loss:0.0012538898041060179\n",
      "train loss:0.004963152940048638\n",
      "train loss:0.002728926298078017\n",
      "train loss:0.0005245036010463868\n",
      "train loss:0.0022200931553019807\n",
      "train loss:0.030205118741503303\n",
      "train loss:0.0021194947304187485\n",
      "train loss:0.013918241565087124\n",
      "train loss:0.0009736217893286028\n",
      "train loss:0.0010486027745579074\n",
      "train loss:0.0040901074352756635\n",
      "train loss:0.006240312604829917\n",
      "train loss:0.00046229834819128574\n",
      "train loss:0.0012106701437070008\n",
      "train loss:0.0011238159396320072\n",
      "train loss:0.0031381353172072134\n",
      "train loss:0.0012154183022277435\n",
      "train loss:0.0035479994224824314\n",
      "train loss:0.000564849730253655\n",
      "train loss:0.005651259046881713\n",
      "train loss:0.011389182348283367\n",
      "train loss:0.0024980104913412977\n",
      "train loss:0.0057595227159845655\n",
      "train loss:0.006604916005394317\n",
      "train loss:0.0032300776539198215\n",
      "train loss:0.006034088183123204\n",
      "train loss:0.007951758018898686\n",
      "train loss:0.08055338111605007\n",
      "train loss:0.0005517620859695258\n",
      "train loss:0.0018516951677250695\n",
      "train loss:0.006893645920722088\n",
      "train loss:0.0011215394559232056\n",
      "train loss:0.000965075829736098\n",
      "train loss:0.005181517060098642\n",
      "train loss:0.0030158833932705364\n",
      "train loss:0.003552357154526979\n",
      "train loss:0.0061511546713709595\n",
      "train loss:0.00232420534590177\n",
      "train loss:0.01527763400541792\n",
      "train loss:0.0024748906743032955\n",
      "train loss:0.0014184683157371703\n",
      "train loss:0.002455788590617772\n",
      "train loss:0.001238525185413207\n",
      "train loss:0.0005856911050085757\n",
      "train loss:0.0323341043956704\n",
      "train loss:0.003418298838874058\n",
      "train loss:0.00018383942533919988\n",
      "train loss:0.0019410967392983938\n",
      "train loss:0.0015560881364450408\n",
      "train loss:0.00781908314800462\n",
      "train loss:0.0044762035721406445\n",
      "train loss:0.00966636611690571\n",
      "train loss:0.0022088465372505123\n",
      "train loss:0.00026236090862916014\n",
      "train loss:0.0008732471910235462\n",
      "train loss:0.003074275857697538\n",
      "train loss:0.0038156332732055902\n",
      "train loss:0.0005184869066081687\n",
      "train loss:0.0011403589480727917\n",
      "train loss:0.000910391977055209\n",
      "train loss:0.003352507342928861\n",
      "train loss:0.004659225340296829\n",
      "train loss:0.0237886832819002\n",
      "train loss:0.0013256009558995552\n",
      "train loss:0.01200439190170859\n",
      "train loss:0.00378884233747402\n",
      "train loss:0.0010740502122045866\n",
      "train loss:0.0011099514888336338\n",
      "train loss:0.00492921920582585\n",
      "train loss:0.0009523180781575015\n",
      "train loss:0.0030628929772125763\n",
      "train loss:0.000904279071581809\n",
      "train loss:0.000813383864030811\n",
      "train loss:0.0010346617555941084\n",
      "train loss:0.0007258953677617024\n",
      "train loss:0.009019391044240672\n",
      "train loss:0.0028842175606944146\n",
      "train loss:0.0004792893699375008\n",
      "train loss:0.003330572847009861\n",
      "train loss:0.0017244439935538592\n",
      "train loss:0.0032631604452099173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0027031061721808055\n",
      "train loss:0.0015030498666833184\n",
      "train loss:0.0019666771375350185\n",
      "train loss:0.0009217072189112098\n",
      "train loss:0.004973472513471584\n",
      "train loss:0.0011334430880690011\n",
      "train loss:0.0006721410469723179\n",
      "train loss:0.0010318273247518367\n",
      "train loss:0.005091162174551101\n",
      "train loss:0.0068584170045105555\n",
      "train loss:0.0321216396169849\n",
      "train loss:0.0038661546368268023\n",
      "train loss:0.0034798204513077093\n",
      "train loss:0.008072312145292583\n",
      "train loss:0.0012130204404027492\n",
      "train loss:0.0009917700127288981\n",
      "train loss:0.0002839505133551401\n",
      "train loss:0.049503111834706466\n",
      "train loss:0.0025632008700706525\n",
      "train loss:0.0002515515504031407\n",
      "train loss:0.0013212767592354535\n",
      "train loss:0.0005702752424946205\n",
      "train loss:0.001032066958597419\n",
      "train loss:0.003568031696614847\n",
      "train loss:0.02290703520345208\n",
      "train loss:0.0038542201162649454\n",
      "train loss:0.006031874566564454\n",
      "train loss:0.005322465612730352\n",
      "train loss:0.0007538709553115425\n",
      "train loss:0.11342951476209048\n",
      "train loss:0.0006744179814319176\n",
      "train loss:0.0027128559545028783\n",
      "train loss:0.0016589938480717197\n",
      "train loss:0.00773148024766977\n",
      "train loss:0.0007750613755135242\n",
      "train loss:0.007527338582098752\n",
      "train loss:0.0009785750547705036\n",
      "train loss:0.0012819099416851115\n",
      "train loss:0.002982313744156263\n",
      "train loss:0.002205235049334427\n",
      "train loss:0.0010352834665786359\n",
      "train loss:0.0016126460575572037\n",
      "train loss:0.0007972599982642337\n",
      "train loss:0.0019471669152005917\n",
      "train loss:0.0034521726289402878\n",
      "train loss:0.0013459156595613897\n",
      "train loss:0.006848880116307292\n",
      "train loss:0.0008435254347847012\n",
      "train loss:0.004617518089587333\n",
      "train loss:0.007387998450122933\n",
      "train loss:0.002266094187524692\n",
      "train loss:0.0005697065991859304\n",
      "train loss:0.0007223669759569974\n",
      "train loss:0.0013570005172609224\n",
      "train loss:0.00043490707344680344\n",
      "train loss:0.005359992525385796\n",
      "train loss:0.002978986849259077\n",
      "train loss:0.00047363505075545764\n",
      "train loss:0.004548379285440535\n",
      "train loss:0.0009462168800040282\n",
      "train loss:0.0016685909285728826\n",
      "train loss:0.0010061524577042991\n",
      "train loss:0.009995023745070893\n",
      "train loss:0.004308665552536073\n",
      "train loss:0.0026117554003147556\n",
      "train loss:0.004123530208867587\n",
      "train loss:0.0031436119438745004\n",
      "train loss:0.00139937225626146\n",
      "train loss:0.009065966577375396\n",
      "train loss:0.0030354225940887403\n",
      "train loss:0.002233147009856355\n",
      "train loss:0.006685713607680774\n",
      "train loss:0.00038949981506501566\n",
      "train loss:0.002536152323436526\n",
      "train loss:0.0003748114745648014\n",
      "train loss:0.005997854555723762\n",
      "train loss:0.00975089405438805\n",
      "train loss:0.0005078429878595977\n",
      "train loss:0.0021111817024302686\n",
      "train loss:0.00047851254658675963\n",
      "train loss:0.000462590677638064\n",
      "train loss:0.0030992392731813145\n",
      "train loss:0.005310978707043319\n",
      "train loss:0.002956792659002671\n",
      "train loss:0.002016876673034455\n",
      "train loss:0.0023953715734609258\n",
      "train loss:0.001019759789082893\n",
      "train loss:0.0008038244151847457\n",
      "train loss:0.0016615759575021568\n",
      "train loss:0.0019306243189168195\n",
      "train loss:0.006946563749569959\n",
      "train loss:0.0038546993253979994\n",
      "train loss:0.0010183265591266924\n",
      "train loss:0.035181291744740155\n",
      "train loss:0.0006438525944503168\n",
      "train loss:0.008167787230810403\n",
      "train loss:0.0025776026951184485\n",
      "train loss:0.0006589450742520881\n",
      "train loss:0.002248082562493959\n",
      "train loss:0.00244562199883011\n",
      "train loss:0.0025548573628210785\n",
      "train loss:0.0026444419209788205\n",
      "train loss:0.004755057241553667\n",
      "train loss:0.007973871005468189\n",
      "train loss:0.002644504405287346\n",
      "train loss:0.004844748040530851\n",
      "train loss:0.0040467015648158675\n",
      "train loss:0.00020246433221090025\n",
      "train loss:0.0011026057464735652\n",
      "train loss:0.00043914609485760795\n",
      "train loss:0.0006683538792744926\n",
      "train loss:0.0004982823899735504\n",
      "train loss:0.0035815402745300253\n",
      "train loss:0.002221367817959873\n",
      "train loss:0.015529837210872866\n",
      "train loss:0.0033811580841638673\n",
      "train loss:0.003243185352668686\n",
      "train loss:0.00030392729490598283\n",
      "train loss:0.001551634946878064\n",
      "train loss:0.00018335013486259945\n",
      "train loss:0.001254707398873075\n",
      "train loss:0.0006029183937133112\n",
      "train loss:0.003353478906263429\n",
      "train loss:0.0037110703735002263\n",
      "train loss:0.0006905847934952017\n",
      "train loss:0.0008375328271024495\n",
      "train loss:0.002745079837658671\n",
      "train loss:0.001692760665234146\n",
      "train loss:0.00029972796684730964\n",
      "train loss:0.0036290766281739228\n",
      "train loss:0.000520903953206004\n",
      "train loss:0.0033903838430935566\n",
      "train loss:0.00021623311901073375\n",
      "train loss:0.024010056661067914\n",
      "train loss:0.00022232259300162266\n",
      "train loss:0.00466571419970851\n",
      "train loss:0.0006153235398405058\n",
      "train loss:0.002975277273812186\n",
      "train loss:0.0006757995369407943\n",
      "train loss:0.0003961430487214573\n",
      "train loss:0.00020787010396580187\n",
      "train loss:0.0020728564058140075\n",
      "train loss:0.01405272514112076\n",
      "train loss:0.0018100169817245255\n",
      "train loss:0.0010046929263588529\n",
      "train loss:0.0038291830634512576\n",
      "train loss:0.0025345499491012616\n",
      "train loss:0.00041798059449734424\n",
      "train loss:0.0029432325937096913\n",
      "train loss:0.012354555716949808\n",
      "train loss:0.0029793213535558066\n",
      "train loss:0.0015916384045729173\n",
      "train loss:0.0016600227117637939\n",
      "train loss:0.008854409130076256\n",
      "train loss:0.00970352655695664\n",
      "train loss:0.004252388594305249\n",
      "train loss:0.0020005071613795255\n",
      "train loss:0.008553433116790984\n",
      "train loss:0.004276265536618399\n",
      "train loss:0.0008237011832473383\n",
      "train loss:0.008067017848658235\n",
      "train loss:0.016062952911729197\n",
      "train loss:0.001668117633693997\n",
      "train loss:0.0029548823088427606\n",
      "train loss:0.00200809110586062\n",
      "train loss:0.000989981233698799\n",
      "train loss:0.0035125242541447087\n",
      "train loss:0.0008131406762702565\n",
      "train loss:0.010327004991633169\n",
      "train loss:0.0009852692556118522\n",
      "train loss:0.00333027636577167\n",
      "train loss:0.007884239673506557\n",
      "train loss:0.0018413429962701594\n",
      "train loss:0.00046828354220575507\n",
      "train loss:0.0025309746665041193\n",
      "train loss:0.0006502503958288586\n",
      "train loss:0.003734712143853107\n",
      "train loss:0.007493787500468666\n",
      "train loss:0.002373746993332842\n",
      "train loss:0.0004328070407691907\n",
      "train loss:0.001141830752663314\n",
      "train loss:0.00033406752264201036\n",
      "train loss:0.0005484848541560391\n",
      "train loss:0.0034154976352081877\n",
      "train loss:0.0003891682214868628\n",
      "train loss:0.002969304398783918\n",
      "train loss:0.0005047024993874501\n",
      "train loss:0.0005448803945117578\n",
      "train loss:0.0006080402237792033\n",
      "train loss:0.00032344204723867425\n",
      "train loss:0.0027815293852165297\n",
      "train loss:0.003273204854666591\n",
      "train loss:0.005320375288124299\n",
      "train loss:0.011090046821275436\n",
      "train loss:0.006656181211281808\n",
      "train loss:0.00047634809486225176\n",
      "train loss:0.0034122742748646205\n",
      "train loss:0.0028655534287954313\n",
      "train loss:0.014143071120361643\n",
      "train loss:0.003127804705804556\n",
      "train loss:0.0009471598041519468\n",
      "train loss:0.0017042086418365004\n",
      "train loss:0.0011379234454340526\n",
      "train loss:0.002575167931119231\n",
      "train loss:0.0048019388223561384\n",
      "train loss:0.004187087061840484\n",
      "train loss:0.0011405982301576018\n",
      "train loss:0.000173974946723405\n",
      "train loss:0.004959925869630378\n",
      "train loss:0.0012072578098265014\n",
      "train loss:0.0010676746293516008\n",
      "train loss:0.0006518288619657171\n",
      "train loss:0.0021868331574544193\n",
      "train loss:7.819902327366875e-05\n",
      "train loss:0.0009588150956986127\n",
      "train loss:0.0017793623818900134\n",
      "train loss:0.018430929591173602\n",
      "train loss:0.002553827782144742\n",
      "train loss:0.0012963378384948398\n",
      "train loss:0.0021974321730045274\n",
      "train loss:0.0008172615766403012\n",
      "train loss:0.0415539052432608\n",
      "train loss:0.003541465393408815\n",
      "train loss:0.002555636300778202\n",
      "train loss:0.0019030227794845406\n",
      "train loss:0.000662408645293604\n",
      "train loss:0.0013917515812753164\n",
      "train loss:0.0016265085371379815\n",
      "train loss:0.008518199877322868\n",
      "train loss:0.0016702221158456565\n",
      "train loss:0.004894502710959148\n",
      "train loss:0.0009766027311036447\n",
      "train loss:0.0005484567040630808\n",
      "train loss:0.0016150815197612056\n",
      "train loss:0.0003647463926134816\n",
      "train loss:0.00014237820702196432\n",
      "train loss:0.006586991953509377\n",
      "train loss:0.0004895816910643614\n",
      "train loss:0.0022123080342822147\n",
      "train loss:0.0015978276384191064\n",
      "train loss:0.0009011361927623093\n",
      "train loss:0.003886757192363848\n",
      "train loss:0.001954842283641382\n",
      "train loss:0.0016709975540908355\n",
      "train loss:0.02633146961927308\n",
      "train loss:0.006676411528609582\n",
      "train loss:0.008667779190467979\n",
      "train loss:0.0032631510417995887\n",
      "train loss:0.0028130245968787304\n",
      "train loss:0.0007777665598515285\n",
      "train loss:0.0005849936337072522\n",
      "train loss:0.0039065956097233965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002817069315517276\n",
      "train loss:0.003990775047655854\n",
      "train loss:0.04537640617025465\n",
      "train loss:0.0016053806846125778\n",
      "train loss:0.00574951860613122\n",
      "train loss:0.0015601008939980904\n",
      "train loss:0.0006900151208792233\n",
      "train loss:0.0007003310856438926\n",
      "train loss:0.002065073865885152\n",
      "train loss:0.001875362703029214\n",
      "train loss:0.001102066981336055\n",
      "train loss:0.0008469987662536666\n",
      "train loss:0.017865483211365617\n",
      "train loss:0.00035014300473508794\n",
      "train loss:0.0005781517479727576\n",
      "train loss:0.002897330688670878\n",
      "train loss:0.001196706948638484\n",
      "train loss:0.0010879252610664538\n",
      "train loss:0.004431480983182375\n",
      "train loss:0.001298923238312714\n",
      "train loss:0.0015327834955144717\n",
      "train loss:0.002363779824093803\n",
      "train loss:0.0015449446944872552\n",
      "train loss:0.0008403159899264089\n",
      "train loss:0.006067518868696725\n",
      "train loss:0.0037310243677273476\n",
      "train loss:0.002711001762391956\n",
      "train loss:0.0008346348376104713\n",
      "train loss:0.003316582387924622\n",
      "train loss:0.0008514649090227774\n",
      "train loss:0.005044604371532496\n",
      "train loss:0.0007349648554924482\n",
      "train loss:0.002181422775658563\n",
      "train loss:0.011312943741739674\n",
      "train loss:0.003649509142192744\n",
      "train loss:0.0006867909870759026\n",
      "train loss:0.007488022524038243\n",
      "train loss:0.0007259796270260765\n",
      "train loss:0.0007875076271684513\n",
      "train loss:0.003711847641509296\n",
      "train loss:0.007627358820908835\n",
      "train loss:0.003398996414757709\n",
      "train loss:0.004908946065671044\n",
      "train loss:0.0012667782614143067\n",
      "train loss:0.0038210097212558413\n",
      "train loss:0.007758469678699194\n",
      "train loss:0.00557157761334188\n",
      "train loss:0.0015596125399973016\n",
      "train loss:0.014188634115377892\n",
      "train loss:0.003899708098263425\n",
      "train loss:0.0016876981427961049\n",
      "train loss:0.0561585519713944\n",
      "train loss:0.0002290191932151354\n",
      "train loss:0.004669698078929291\n",
      "train loss:0.000881418255754256\n",
      "train loss:0.004236432640306062\n",
      "train loss:0.0028838163163811925\n",
      "train loss:0.0012718780440913327\n",
      "train loss:0.013395283413127903\n",
      "train loss:0.0032252107553856564\n",
      "train loss:0.006958552997800249\n",
      "train loss:0.001698934733405854\n",
      "train loss:0.00048550126547203324\n",
      "train loss:0.0012168386452356453\n",
      "train loss:0.0028793181355257764\n",
      "train loss:0.002869400308601049\n",
      "train loss:0.002206036642491147\n",
      "train loss:0.015835428570469365\n",
      "train loss:0.0032857864882579195\n",
      "train loss:0.004292918555543962\n",
      "train loss:0.0033358836688237325\n",
      "train loss:0.0007875350238823145\n",
      "train loss:0.0037007415032092035\n",
      "train loss:0.009041177703055958\n",
      "train loss:0.0008129251490090062\n",
      "train loss:0.0006192569493558312\n",
      "train loss:0.0011019232521346008\n",
      "train loss:0.003182813623996084\n",
      "train loss:0.0010935659282503068\n",
      "train loss:0.0017243533279654244\n",
      "train loss:0.001201553758551085\n",
      "train loss:0.0026184137693797214\n",
      "train loss:0.003942604901960738\n",
      "train loss:0.002189601728885884\n",
      "train loss:0.0008344453713221427\n",
      "train loss:0.000206875897189864\n",
      "train loss:0.005188218313617297\n",
      "train loss:0.00045267629219204216\n",
      "train loss:0.0002875757919160754\n",
      "train loss:0.004559980134036245\n",
      "train loss:0.003431205963103917\n",
      "train loss:0.002816843691634352\n",
      "train loss:0.007399881473480844\n",
      "train loss:0.0012891484850492364\n",
      "train loss:0.0016440700755414146\n",
      "train loss:0.0017251722630905143\n",
      "train loss:0.007128025229653809\n",
      "train loss:4.583528188305043e-05\n",
      "train loss:0.0017355808799647005\n",
      "train loss:0.0033381242114036303\n",
      "train loss:0.0010257238362994343\n",
      "train loss:0.011071672159105045\n",
      "train loss:0.005214446845735843\n",
      "train loss:0.005610048883019272\n",
      "train loss:0.00085750878731708\n",
      "train loss:0.010535395691447347\n",
      "train loss:0.0003627976091357599\n",
      "train loss:0.0017827777269505704\n",
      "train loss:0.010835130219091126\n",
      "train loss:0.0006911461564645041\n",
      "train loss:0.0001946549608680092\n",
      "train loss:0.0039005442093413907\n",
      "train loss:0.0028144807297185064\n",
      "train loss:0.004084714620931023\n",
      "train loss:0.01242032909288616\n",
      "train loss:0.006633135501010304\n",
      "train loss:0.0013947094757666989\n",
      "train loss:0.0008437519003329918\n",
      "train loss:0.002385732742411011\n",
      "train loss:0.0010424461708700805\n",
      "train loss:0.0005034298369801589\n",
      "train loss:0.0015161076827046804\n",
      "train loss:0.00015535522672339722\n",
      "train loss:0.0003361012566787107\n",
      "train loss:0.001139011954982708\n",
      "train loss:0.00264396594281012\n",
      "train loss:0.00038734659933639307\n",
      "train loss:0.011424152458290218\n",
      "train loss:0.0006996649071775221\n",
      "train loss:0.0004977193681235357\n",
      "train loss:0.00458865308465322\n",
      "train loss:0.00035797187702077014\n",
      "train loss:0.0071879357741984175\n",
      "train loss:0.001589016881636838\n",
      "train loss:0.007466505977346421\n",
      "train loss:0.0021929849511932403\n",
      "train loss:0.00020247265892441946\n",
      "train loss:0.004590580640803456\n",
      "train loss:0.0005208028015484298\n",
      "train loss:0.014547730401346532\n",
      "train loss:0.0016215600434557134\n",
      "train loss:0.0002590375051009498\n",
      "train loss:0.0024619456646081954\n",
      "train loss:0.005694635888770327\n",
      "train loss:0.004198297693649664\n",
      "train loss:0.0025969746407470463\n",
      "train loss:0.003993139744275718\n",
      "=== epoch:15, train acc:0.997, test acc:0.986 ===\n",
      "train loss:0.0015719171090459517\n",
      "train loss:0.0033704200460635708\n",
      "train loss:0.0004257415025133515\n",
      "train loss:0.0031753645840338226\n",
      "train loss:0.0025670139446009703\n",
      "train loss:0.0014923127033022383\n",
      "train loss:0.0032585651469842574\n",
      "train loss:0.0021207204910845055\n",
      "train loss:0.005732973634109454\n",
      "train loss:0.002100118680221409\n",
      "train loss:0.00490808123599026\n",
      "train loss:0.0014940911137027175\n",
      "train loss:0.019027072795742745\n",
      "train loss:0.00022453152007192997\n",
      "train loss:0.0007306307385019336\n",
      "train loss:0.001986313406117866\n",
      "train loss:0.008717988575822051\n",
      "train loss:0.000261955636803579\n",
      "train loss:0.005906794066653125\n",
      "train loss:0.0016509948009533425\n",
      "train loss:0.0022795883807329837\n",
      "train loss:0.0004424620489580368\n",
      "train loss:0.0006132011628744714\n",
      "train loss:0.0030003669154175907\n",
      "train loss:0.0035452042808090493\n",
      "train loss:0.00046874975715654923\n",
      "train loss:0.0005602386554444921\n",
      "train loss:0.0007966947612735442\n",
      "train loss:0.0012654411061480421\n",
      "train loss:0.0003926215087522921\n",
      "train loss:0.002455250265783965\n",
      "train loss:0.001365360190391544\n",
      "train loss:0.00010915894999352148\n",
      "train loss:0.0019688171562859684\n",
      "train loss:0.0025552795858073472\n",
      "train loss:0.013559055381073198\n",
      "train loss:0.00022672901524042248\n",
      "train loss:0.002958678160140738\n",
      "train loss:0.018281355167852616\n",
      "train loss:0.001082259207249165\n",
      "train loss:0.018846180100757504\n",
      "train loss:0.001745108464424391\n",
      "train loss:0.010110150160659652\n",
      "train loss:0.0019445049694195404\n",
      "train loss:0.009679268373947187\n",
      "train loss:0.0004018773761194477\n",
      "train loss:0.0013322554465906502\n",
      "train loss:0.0031915864949974204\n",
      "train loss:0.012613771283859692\n",
      "train loss:0.0020472421392642303\n",
      "train loss:0.0024477854292481445\n",
      "train loss:0.003637120647794322\n",
      "train loss:0.0004320112575718701\n",
      "train loss:0.0016870633832162035\n",
      "train loss:0.008064628659851586\n",
      "train loss:0.0011736014652338272\n",
      "train loss:0.048592078713280265\n",
      "train loss:0.003070967495741395\n",
      "train loss:0.012362089933312921\n",
      "train loss:0.0009751042222127829\n",
      "train loss:0.0013569829231353731\n",
      "train loss:0.0018855122955924975\n",
      "train loss:0.0062264375827274674\n",
      "train loss:0.0002403939752831508\n",
      "train loss:0.0012050407216429996\n",
      "train loss:0.00041516194743888184\n",
      "train loss:0.002164913991983768\n",
      "train loss:0.009915346319819062\n",
      "train loss:0.0022028557031754507\n",
      "train loss:0.0021429056942454936\n",
      "train loss:0.0005974495707277226\n",
      "train loss:0.0034294799484916134\n",
      "train loss:0.010674428030723717\n",
      "train loss:0.003468269163594932\n",
      "train loss:0.002689575974993811\n",
      "train loss:0.0008748614014771858\n",
      "train loss:0.004257793031518307\n",
      "train loss:0.0006953272331186354\n",
      "train loss:0.0195273754571571\n",
      "train loss:0.0015423860798664537\n",
      "train loss:0.0020866203944133197\n",
      "train loss:0.0015456444757559569\n",
      "train loss:0.001931998898216177\n",
      "train loss:0.00470252674277162\n",
      "train loss:0.001134107314431014\n",
      "train loss:0.00806267501521636\n",
      "train loss:0.00375503910563956\n",
      "train loss:0.0012921862755931146\n",
      "train loss:0.0004530430444458448\n",
      "train loss:0.0003026859174340818\n",
      "train loss:0.002943896384159921\n",
      "train loss:0.0055009412642897226\n",
      "train loss:0.0006508708799174375\n",
      "train loss:0.0006372686017624953\n",
      "train loss:0.006989525996008721\n",
      "train loss:0.0003421462266840601\n",
      "train loss:0.008925956727449766\n",
      "train loss:0.0023107364459553138\n",
      "train loss:0.0006378179470365179\n",
      "train loss:0.001255190904198583\n",
      "train loss:0.0005046175118373701\n",
      "train loss:0.005578153275955874\n",
      "train loss:0.00037937178797032574\n",
      "train loss:0.003536132598799395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00045960791227952276\n",
      "train loss:0.0037813751311193728\n",
      "train loss:0.004512640944256185\n",
      "train loss:0.0012536758534195788\n",
      "train loss:0.002298067129450413\n",
      "train loss:0.0002469012177561125\n",
      "train loss:0.0037310765562549404\n",
      "train loss:0.0003158270912071539\n",
      "train loss:0.0015837110819605748\n",
      "train loss:0.0017204325624292716\n",
      "train loss:0.0006154950162433745\n",
      "train loss:0.002801737472534263\n",
      "train loss:0.0010320895567540696\n",
      "train loss:0.00035550075226351685\n",
      "train loss:0.007993686661484258\n",
      "train loss:0.0016807834085714338\n",
      "train loss:0.000899709986118701\n",
      "train loss:0.0013072904962576734\n",
      "train loss:0.0016505490995518946\n",
      "train loss:0.0006823687902169479\n",
      "train loss:0.00213365853191102\n",
      "train loss:0.0014911538410029707\n",
      "train loss:0.004851068948323041\n",
      "train loss:0.0008724591475075086\n",
      "train loss:0.0011230221482019286\n",
      "train loss:0.0015078001582466503\n",
      "train loss:0.001719709128394163\n",
      "train loss:0.003449065204106276\n",
      "train loss:0.022850631204681216\n",
      "train loss:0.000843327943849157\n",
      "train loss:0.0005989079486149571\n",
      "train loss:0.0007069104830729536\n",
      "train loss:0.0016585873141695226\n",
      "train loss:0.007052787624032369\n",
      "train loss:0.0013912450874285756\n",
      "train loss:0.0004747530364341068\n",
      "train loss:0.020017554203328264\n",
      "train loss:0.02625979698252797\n",
      "train loss:0.00042825699203436727\n",
      "train loss:0.002505379619775538\n",
      "train loss:0.005943811638632443\n",
      "train loss:0.0027972630000110492\n",
      "train loss:0.0005306416608601405\n",
      "train loss:0.003145765087535499\n",
      "train loss:0.00019383124111275383\n",
      "train loss:0.0075157777312916795\n",
      "train loss:0.006821964032539795\n",
      "train loss:0.00042056644477664773\n",
      "train loss:0.004768372648873805\n",
      "train loss:0.0002484890507550728\n",
      "train loss:0.0014134012896049538\n",
      "train loss:0.0002069328367587058\n",
      "train loss:0.0008199705341332675\n",
      "train loss:0.004052842632399129\n",
      "train loss:0.0026007560153566674\n",
      "train loss:0.0019689150737048854\n",
      "train loss:0.0009578568103687361\n",
      "train loss:0.0003873123240618051\n",
      "train loss:0.0004913108975042357\n",
      "train loss:0.0014174574856626715\n",
      "train loss:0.004023786286555608\n",
      "train loss:0.0009469597801015452\n",
      "train loss:0.0010328953745998475\n",
      "train loss:0.0064098979036075355\n",
      "train loss:0.0010731983073670659\n",
      "train loss:0.002655343517205958\n",
      "train loss:0.004793796820257325\n",
      "train loss:0.0002400419803498358\n",
      "train loss:0.00089884280044311\n",
      "train loss:0.0007467497268648804\n",
      "train loss:0.004307306421194001\n",
      "train loss:0.004858813534451708\n",
      "train loss:0.0009832138729396005\n",
      "train loss:0.003797851346976652\n",
      "train loss:0.0009201064309744841\n",
      "train loss:0.0004902317669928534\n",
      "train loss:0.0003198681645150898\n",
      "train loss:0.001175309002642194\n",
      "train loss:0.0012971199043244855\n",
      "train loss:0.0012014729115687153\n",
      "train loss:0.0042635263412021925\n",
      "train loss:0.0015630824902819922\n",
      "train loss:0.00022115634431264737\n",
      "train loss:0.0009484070953168882\n",
      "train loss:0.0048611293678176475\n",
      "train loss:0.0014862915064647114\n",
      "train loss:0.007118820932158772\n",
      "train loss:0.0007413776443463145\n",
      "train loss:0.0035870244026576905\n",
      "train loss:0.00037958105684501414\n",
      "train loss:0.0026756927818038334\n",
      "train loss:0.0010136171674688353\n",
      "train loss:0.0001369080656331737\n",
      "train loss:0.0020985237450596088\n",
      "train loss:0.0003167797501484371\n",
      "train loss:0.005502322028896735\n",
      "train loss:0.0011878875671641146\n",
      "train loss:0.00020224737796600367\n",
      "train loss:0.0001403168002317836\n",
      "train loss:0.0014912337450118818\n",
      "train loss:0.0029632736573515723\n",
      "train loss:0.00403491970513467\n",
      "train loss:0.01591917388325585\n",
      "train loss:0.00898293218240768\n",
      "train loss:0.0010460474776241729\n",
      "train loss:0.001528839374512747\n",
      "train loss:0.0015055591053842671\n",
      "train loss:0.002656883740816811\n",
      "train loss:0.00513890903896453\n",
      "train loss:0.011324845053357775\n",
      "train loss:0.004649744755392551\n",
      "train loss:0.0007302370043126323\n",
      "train loss:0.011272752818612224\n",
      "train loss:0.00039310732941437524\n",
      "train loss:0.0002767250924555992\n",
      "train loss:0.00817221732741961\n",
      "train loss:0.0013537718385915685\n",
      "train loss:0.0021036908131280008\n",
      "train loss:0.006277345758405214\n",
      "train loss:0.007375555367613548\n",
      "train loss:0.005194152428138194\n",
      "train loss:0.00038123571146975025\n",
      "train loss:0.0032635540628804995\n",
      "train loss:0.0005048207908097971\n",
      "train loss:0.0057692365717055705\n",
      "train loss:0.0004381117945928841\n",
      "train loss:0.00011542505364057789\n",
      "train loss:0.0010072958714345056\n",
      "train loss:0.0034279140492153486\n",
      "train loss:0.0027329746714281054\n",
      "train loss:0.0007546589260250765\n",
      "train loss:0.0007116397671460992\n",
      "train loss:0.058093112457221464\n",
      "train loss:0.003005381879228869\n",
      "train loss:0.002669741156079764\n",
      "train loss:0.00571300122918846\n",
      "train loss:0.0010964893600948918\n",
      "train loss:0.0006176492126335628\n",
      "train loss:0.002123196829393064\n",
      "train loss:0.005577011847735835\n",
      "train loss:0.0039752419262259284\n",
      "train loss:0.005120917507707665\n",
      "train loss:0.01392593169202882\n",
      "train loss:0.000937429764759247\n",
      "train loss:0.0027868597362288145\n",
      "train loss:0.002292987503159287\n",
      "train loss:0.0013526646717804808\n",
      "train loss:0.0037971087198843804\n",
      "train loss:0.004432371638530547\n",
      "train loss:0.0007854037429336334\n",
      "train loss:0.001555082777221192\n",
      "train loss:0.002523195984809833\n",
      "train loss:0.0005874255910822812\n",
      "train loss:0.004886168692238531\n",
      "train loss:0.0005438812973424598\n",
      "train loss:0.0005830573062832316\n",
      "train loss:0.0004914456696104143\n",
      "train loss:0.002236280947258325\n",
      "train loss:0.0007283554503474231\n",
      "train loss:0.003992885616061052\n",
      "train loss:0.0007624911092215269\n",
      "train loss:0.0009831372342687214\n",
      "train loss:0.0019357057109135798\n",
      "train loss:0.00342518182896461\n",
      "train loss:0.002709707384049443\n",
      "train loss:0.002591794951658984\n",
      "train loss:0.0008562540819249796\n",
      "train loss:0.0049338276413796265\n",
      "train loss:0.021603667989731807\n",
      "train loss:0.003548970819413137\n",
      "train loss:0.044287161284720114\n",
      "train loss:0.0012727436679414268\n",
      "train loss:0.0012110488022213845\n",
      "train loss:0.003041112271408243\n",
      "train loss:0.007580655228109532\n",
      "train loss:0.002203856398401252\n",
      "train loss:0.0009226792583214681\n",
      "train loss:0.0004991851155801803\n",
      "train loss:0.0006216057832470098\n",
      "train loss:0.004942226692505608\n",
      "train loss:0.0033811329624310305\n",
      "train loss:0.002027267237215676\n",
      "train loss:0.005591774525618286\n",
      "train loss:0.002431285324843492\n",
      "train loss:0.0005907284858960063\n",
      "train loss:0.00479411130940591\n",
      "train loss:0.008324928628274674\n",
      "train loss:0.0002866516974467385\n",
      "train loss:0.004938000450415841\n",
      "train loss:0.0008697924399196678\n",
      "train loss:0.0012861312166349429\n",
      "train loss:0.00243584958597649\n",
      "train loss:0.003576988358672148\n",
      "train loss:0.002263689419044843\n",
      "train loss:0.005870049262823248\n",
      "train loss:0.0005214585882940078\n",
      "train loss:0.006384049967444912\n",
      "train loss:0.020380690011526873\n",
      "train loss:0.0015169371377163356\n",
      "train loss:0.004120417356683847\n",
      "train loss:0.002732073990412815\n",
      "train loss:0.016443349637334036\n",
      "train loss:0.0008999838423989309\n",
      "train loss:0.0035484381417451977\n",
      "train loss:0.00569145996255859\n",
      "train loss:0.0035247426633370654\n",
      "train loss:0.0004385556844454036\n",
      "train loss:0.0008998931975219982\n",
      "train loss:0.0062365041873629614\n",
      "train loss:0.006367780164957965\n",
      "train loss:0.01468772368554617\n",
      "train loss:0.0021047147276148977\n",
      "train loss:0.0003181927355669031\n",
      "train loss:0.00039741024292389514\n",
      "train loss:0.0012873969870422566\n",
      "train loss:0.005242512383982203\n",
      "train loss:0.0009353464459342889\n",
      "train loss:0.000902259508579844\n",
      "train loss:0.0009439329099273938\n",
      "train loss:0.003142481475820574\n",
      "train loss:0.000217825325583875\n",
      "train loss:0.0006382681128020205\n",
      "train loss:0.00043535202601804537\n",
      "train loss:0.020677924751326442\n",
      "train loss:0.002216630352054111\n",
      "train loss:0.002310632561944168\n",
      "train loss:0.000897446990117789\n",
      "train loss:0.0006937500777246876\n",
      "train loss:0.0011340967029281866\n",
      "train loss:0.003495029393163816\n",
      "train loss:0.003989641481330138\n",
      "train loss:0.003437497149878192\n",
      "train loss:0.001764997641461082\n",
      "train loss:0.000610704126343002\n",
      "train loss:0.0007353596855221284\n",
      "train loss:0.002387740925499774\n",
      "train loss:0.0007949313537678169\n",
      "train loss:0.0027424353185821443\n",
      "train loss:0.00013932719789741803\n",
      "train loss:0.0006165796347565471\n",
      "train loss:0.03163017188092191\n",
      "train loss:0.016774581235544355\n",
      "train loss:0.0006783291457126719\n",
      "train loss:0.0015207636928535803\n",
      "train loss:0.000645837735866102\n",
      "train loss:0.002728753113282818\n",
      "train loss:0.006631864237600066\n",
      "train loss:0.013513489003625789\n",
      "train loss:0.002680461556446005\n",
      "train loss:0.0006882895933331874\n",
      "train loss:0.0007571681676758517\n",
      "train loss:0.0006814196520374892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0004059853241746721\n",
      "train loss:0.0034088255775089242\n",
      "train loss:0.0005893431870322203\n",
      "train loss:0.001310301424250869\n",
      "train loss:0.0005661244962080599\n",
      "train loss:0.004748590410312866\n",
      "train loss:0.0028126601136880098\n",
      "train loss:0.0010961324534805557\n",
      "train loss:0.0003411766700944996\n",
      "train loss:0.004201247382609097\n",
      "train loss:0.0032563562164438244\n",
      "train loss:0.010218006982154233\n",
      "train loss:0.0002598773151794472\n",
      "train loss:0.0006850106484678649\n",
      "train loss:0.003904374352532041\n",
      "train loss:0.0029972144093695125\n",
      "train loss:0.0028171308907986403\n",
      "train loss:0.0008433939720770971\n",
      "train loss:0.026764480799965285\n",
      "train loss:0.004206838048857049\n",
      "train loss:0.000929773618778157\n",
      "train loss:0.0028926475783062596\n",
      "train loss:0.005605501410228347\n",
      "train loss:0.00032819784920604757\n",
      "train loss:0.00026205255800441354\n",
      "train loss:0.0020217192671157114\n",
      "train loss:0.0198391207877768\n",
      "train loss:0.0013133563609389026\n",
      "train loss:0.00038089517638336334\n",
      "train loss:0.0027044864697868595\n",
      "train loss:0.00012982306111368854\n",
      "train loss:0.006178161915121883\n",
      "train loss:0.00209863785706977\n",
      "train loss:0.000988832314422276\n",
      "train loss:0.0010209974946190506\n",
      "train loss:0.001853814556872736\n",
      "train loss:0.0036732582733430695\n",
      "train loss:0.004701998463389131\n",
      "train loss:0.004598158846912483\n",
      "train loss:0.0033866660909118804\n",
      "train loss:0.0006743543821194456\n",
      "train loss:0.000380993373500589\n",
      "train loss:0.001470903130915059\n",
      "train loss:0.0014711567542112511\n",
      "train loss:0.0037115681054005274\n",
      "train loss:0.004622640122370435\n",
      "train loss:0.0004207852025738446\n",
      "train loss:0.0019904396562418513\n",
      "train loss:0.0028363026786198714\n",
      "train loss:0.0026952865361258072\n",
      "train loss:0.006466547435255246\n",
      "train loss:0.004290328082581904\n",
      "train loss:0.002886764917327893\n",
      "train loss:0.0006110794989140046\n",
      "train loss:0.0006491927862605976\n",
      "train loss:0.00035423291207431354\n",
      "train loss:0.00013196913769152245\n",
      "train loss:0.0005362416383295771\n",
      "train loss:0.0028184378669625556\n",
      "train loss:0.0011997054237266064\n",
      "train loss:0.004854809947427105\n",
      "train loss:0.0016321181760945087\n",
      "train loss:0.0018008780711428402\n",
      "train loss:0.008035994163902528\n",
      "train loss:0.005433653231941376\n",
      "train loss:0.00023757589581179908\n",
      "train loss:0.0007434935809338637\n",
      "train loss:0.004182481220700372\n",
      "train loss:0.00023551836643157138\n",
      "train loss:0.001660491857838438\n",
      "train loss:0.0033994264713568256\n",
      "train loss:0.001670769989721665\n",
      "train loss:0.006908902699459977\n",
      "train loss:0.010547089145692707\n",
      "train loss:0.00018922450592074542\n",
      "train loss:0.0011482697721551405\n",
      "train loss:0.00034258185273080335\n",
      "train loss:0.0010714941627029586\n",
      "train loss:0.0016977581703522804\n",
      "train loss:0.006918384701829125\n",
      "train loss:0.00023328652617628484\n",
      "train loss:0.003950969458216388\n",
      "train loss:0.0002663478154528261\n",
      "train loss:0.0011891852043400292\n",
      "train loss:0.0027338923273970066\n",
      "train loss:0.005856991513941154\n",
      "train loss:0.0028422421685119254\n",
      "train loss:0.0002776161857636079\n",
      "train loss:0.0031661563419418315\n",
      "train loss:0.0003354366053584913\n",
      "train loss:3.458542341119837e-05\n",
      "train loss:0.003660478985127391\n",
      "train loss:0.004182699671417145\n",
      "train loss:0.0027255045059291568\n",
      "train loss:0.0005320944413862011\n",
      "train loss:0.003977150834810497\n",
      "train loss:0.0007126482614117481\n",
      "train loss:0.0037421952593193098\n",
      "train loss:0.0032183693143711186\n",
      "train loss:0.014390373776784305\n",
      "train loss:0.0010330568479031332\n",
      "train loss:0.002148566682777218\n",
      "train loss:0.0032693353394374768\n",
      "train loss:0.0011630621184087289\n",
      "train loss:0.0006086043172250087\n",
      "train loss:0.00442439354125772\n",
      "train loss:0.0013260293673213307\n",
      "train loss:0.004307375749220981\n",
      "train loss:0.0008039509815216319\n",
      "train loss:0.0038335545044879756\n",
      "train loss:0.0023106647148391003\n",
      "train loss:0.005274054498684369\n",
      "train loss:0.015150746651851787\n",
      "train loss:0.0021426640792413507\n",
      "train loss:0.0017050997480165865\n",
      "train loss:0.0042033101173568\n",
      "train loss:0.0006898509539011909\n",
      "train loss:0.008171729156733327\n",
      "train loss:0.005859696025734301\n",
      "train loss:0.0005728726624477205\n",
      "train loss:0.002641340051534689\n",
      "train loss:0.009772574305831325\n",
      "train loss:0.002126874788969404\n",
      "train loss:0.01464462265990049\n",
      "train loss:0.00041590032829558405\n",
      "train loss:0.001598487067007291\n",
      "train loss:0.003241271070118901\n",
      "train loss:0.0019477131421517045\n",
      "train loss:0.0023755172651980416\n",
      "train loss:0.0006391534233847748\n",
      "train loss:0.000979554151461359\n",
      "train loss:0.001112745858288139\n",
      "train loss:0.001539102021250589\n",
      "train loss:0.0011724242920111841\n",
      "train loss:0.008017394240348766\n",
      "train loss:0.0004568724251711362\n",
      "train loss:0.009786770353473669\n",
      "train loss:0.0006615146713053268\n",
      "train loss:0.005960241153909367\n",
      "train loss:0.010451525422790485\n",
      "train loss:0.004977159629386367\n",
      "train loss:0.002033999178526547\n",
      "train loss:0.0035222675075215486\n",
      "train loss:0.001530253862911442\n",
      "train loss:0.0003904849915808942\n",
      "train loss:0.0017062379867181102\n",
      "train loss:0.0005672841145370769\n",
      "train loss:0.0016862614077705537\n",
      "train loss:0.003235851489561272\n",
      "train loss:0.0015281414804038166\n",
      "train loss:0.004423416831880532\n",
      "train loss:0.0014598501943708987\n",
      "train loss:0.001362326436850068\n",
      "train loss:0.0015342517561145208\n",
      "train loss:0.0009855978217179833\n",
      "train loss:0.001360108916753298\n",
      "train loss:0.00028670228642680817\n",
      "train loss:0.0016659836473410436\n",
      "train loss:0.0009221004348523408\n",
      "train loss:0.0006472271515016079\n",
      "train loss:0.004549182298490857\n",
      "train loss:0.0007822668649254991\n",
      "train loss:0.0011595183886172673\n",
      "train loss:0.00338385585931079\n",
      "train loss:0.00020144339557254154\n",
      "train loss:0.0006242784828698823\n",
      "train loss:0.015431584608907372\n",
      "train loss:0.01900158988225583\n",
      "train loss:0.00418501059644292\n",
      "train loss:0.0005925699770761912\n",
      "train loss:0.0005701528145134464\n",
      "train loss:0.000529576926466044\n",
      "train loss:0.018044840074847697\n",
      "train loss:0.00014188770064290604\n",
      "train loss:0.001873969366159909\n",
      "train loss:4.0840419343713015e-05\n",
      "train loss:0.000313711981457481\n",
      "train loss:0.010395756740923932\n",
      "train loss:0.0024000151379084244\n",
      "train loss:0.0005674091083527341\n",
      "train loss:0.0012602676982380286\n",
      "train loss:0.00043471670879412233\n",
      "train loss:0.013466090964787084\n",
      "train loss:0.00046509941017240625\n",
      "train loss:0.0035767783139173913\n",
      "train loss:0.0020363028216453093\n",
      "train loss:0.0021070879213176815\n",
      "train loss:0.0005651530336367169\n",
      "train loss:0.003345518231444149\n",
      "train loss:0.0004737329843107078\n",
      "train loss:0.0017710314508609134\n",
      "train loss:0.0008161274293459768\n",
      "train loss:0.014008063782676812\n",
      "train loss:0.000623078887161607\n",
      "train loss:0.0032880231982196956\n",
      "train loss:0.0012585921720897578\n",
      "train loss:0.002693455395962169\n",
      "train loss:0.007212241138450853\n",
      "train loss:0.0022184823426591505\n",
      "train loss:0.0019834467426376114\n",
      "train loss:0.00026539369256505863\n",
      "train loss:0.000594932934878127\n",
      "train loss:0.001155329166853362\n",
      "train loss:0.0007532818263197783\n",
      "train loss:0.003411120728499296\n",
      "train loss:0.002470326621505795\n",
      "train loss:8.824421750627848e-05\n",
      "train loss:0.0014206835786622453\n",
      "train loss:0.0023167456428202994\n",
      "train loss:0.0007183809753663301\n",
      "train loss:0.003208564086435836\n",
      "train loss:0.006965103356024393\n",
      "train loss:0.00031544727451369645\n",
      "train loss:0.0024329105491376775\n",
      "train loss:0.0019595503067657487\n",
      "train loss:0.0038733540910082386\n",
      "train loss:0.001990859842867319\n",
      "train loss:0.002140300312489838\n",
      "train loss:0.0029604563136197914\n",
      "train loss:0.0020941177091270834\n",
      "train loss:0.0014331846194260201\n",
      "train loss:0.005229019969135115\n",
      "train loss:0.002385420580271891\n",
      "train loss:0.0011594301903493137\n",
      "train loss:0.00020397672053904984\n",
      "train loss:0.002398853212942284\n",
      "train loss:0.003281196575498893\n",
      "train loss:0.0004927314033078686\n",
      "train loss:0.00023378854527730328\n",
      "train loss:0.0012211250976500226\n",
      "train loss:0.00019976397847310475\n",
      "train loss:0.0003095998620868198\n",
      "train loss:0.0034413004415003463\n",
      "train loss:0.0006956637179396867\n",
      "train loss:0.0012998571848781982\n",
      "train loss:0.00013901439048605483\n",
      "train loss:0.0008797778298208155\n",
      "train loss:0.012840786529278971\n",
      "train loss:0.006287790052613132\n",
      "train loss:0.002682913841081642\n",
      "train loss:0.0034885642843468993\n",
      "train loss:0.0020185737318609\n",
      "train loss:0.0004262100207968057\n",
      "train loss:0.0007375181522531631\n",
      "=== epoch:16, train acc:0.999, test acc:0.989 ===\n",
      "train loss:0.0031070769179111207\n",
      "train loss:0.01378395617543906\n",
      "train loss:0.05707360289573159\n",
      "train loss:0.0018903678013773198\n",
      "train loss:0.00010916463735627288\n",
      "train loss:0.00030350226070980594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002282824464389102\n",
      "train loss:0.0013118626408832046\n",
      "train loss:0.0017903294454186419\n",
      "train loss:0.0005308028884346884\n",
      "train loss:0.0008826125407975526\n",
      "train loss:0.0028854862639540514\n",
      "train loss:0.0001392272264114629\n",
      "train loss:0.006093884757771709\n",
      "train loss:0.0012130083731564261\n",
      "train loss:0.0025413877826073157\n",
      "train loss:0.0006743053593107431\n",
      "train loss:0.0005537730001517694\n",
      "train loss:0.001312433429904431\n",
      "train loss:0.001143949707250465\n",
      "train loss:0.003287115341061165\n",
      "train loss:0.00023128816208097664\n",
      "train loss:0.001723291191844237\n",
      "train loss:0.0007136564183156842\n",
      "train loss:0.0002283610054965692\n",
      "train loss:0.002527735619466932\n",
      "train loss:0.022749975305112007\n",
      "train loss:0.0011358288222079493\n",
      "train loss:0.011638435085169785\n",
      "train loss:0.00885513747428845\n",
      "train loss:0.00445054645767341\n",
      "train loss:0.00014170062444198567\n",
      "train loss:1.5900350022512504e-05\n",
      "train loss:0.0028552883078203557\n",
      "train loss:0.0041658560319655785\n",
      "train loss:0.0013168812955484544\n",
      "train loss:9.120855335145073e-05\n",
      "train loss:0.000697573306801636\n",
      "train loss:0.0013067710473161776\n",
      "train loss:0.002421747000908937\n",
      "train loss:0.0026550762633988944\n",
      "train loss:0.0018626486109090054\n",
      "train loss:0.000745893962182602\n",
      "train loss:0.003074381944927047\n",
      "train loss:0.0003752902709235014\n",
      "train loss:0.00048211249307597\n",
      "train loss:0.014663601885903014\n",
      "train loss:0.0007643284683148131\n",
      "train loss:0.00012936075724321488\n",
      "train loss:0.00026174721847027594\n",
      "train loss:0.0008808202591357059\n",
      "train loss:0.0006338459819117268\n",
      "train loss:0.012655912670374334\n",
      "train loss:0.0012892100701685496\n",
      "train loss:0.0014253083556373081\n",
      "train loss:0.002489826526483801\n",
      "train loss:0.0016236910847193197\n",
      "train loss:0.0008906673111070022\n",
      "train loss:0.004167140103485541\n",
      "train loss:0.00029289595348548647\n",
      "train loss:0.0002481515579771523\n",
      "train loss:0.0019159053058275506\n",
      "train loss:0.00574403514079868\n",
      "train loss:0.007906087046998826\n",
      "train loss:0.002127551981313934\n",
      "train loss:6.112172902217756e-05\n",
      "train loss:0.00024188255788630997\n",
      "train loss:0.002894417749500819\n",
      "train loss:0.003254685410078192\n",
      "train loss:0.00046787359662160753\n",
      "train loss:0.001140834388718885\n",
      "train loss:0.010522766856723565\n",
      "train loss:0.0017630605923138498\n",
      "train loss:0.000475525614290123\n",
      "train loss:0.0012701956470034285\n",
      "train loss:0.004867253608600664\n",
      "train loss:0.0030925190767034905\n",
      "train loss:0.0019179427062068436\n",
      "train loss:0.0007923796305909543\n",
      "train loss:0.0032954655823625393\n",
      "train loss:0.002318202026379591\n",
      "train loss:0.002008328896855408\n",
      "train loss:0.0006194902502957759\n",
      "train loss:0.0028071975822153666\n",
      "train loss:0.0015157084318020131\n",
      "train loss:0.0005362466022263361\n",
      "train loss:0.001483587851367413\n",
      "train loss:0.0011791166302985337\n",
      "train loss:0.00025749557370670936\n",
      "train loss:0.0006054904360633037\n",
      "train loss:0.002776763046218965\n",
      "train loss:0.0024210171335347585\n",
      "train loss:0.00798770463035127\n",
      "train loss:0.005235233628266575\n",
      "train loss:0.0005934492374650596\n",
      "train loss:0.0009659500223537647\n",
      "train loss:0.002449084475523595\n",
      "train loss:0.005772064218283915\n",
      "train loss:0.0008949180997261468\n",
      "train loss:0.0009173571078168732\n",
      "train loss:0.0062210348123955435\n",
      "train loss:0.0011787215574102527\n",
      "train loss:0.027369686616637693\n",
      "train loss:0.0028158620218886265\n",
      "train loss:0.00040692521883783575\n",
      "train loss:0.0026154989973371985\n",
      "train loss:0.0001266412531089213\n",
      "train loss:0.0028428818912559777\n",
      "train loss:0.0006792317197972371\n",
      "train loss:0.0009054748052560981\n",
      "train loss:0.0060251541432245126\n",
      "train loss:0.002370271660854471\n",
      "train loss:0.001625729190894836\n",
      "train loss:0.0019204907942790492\n",
      "train loss:0.0011026432300674772\n",
      "train loss:0.0035060910303777843\n",
      "train loss:0.0002169641818270039\n",
      "train loss:0.0009583014381362779\n",
      "train loss:0.00041548191328094034\n",
      "train loss:0.0045675253699889624\n",
      "train loss:0.0008439750475646081\n",
      "train loss:0.0027157146550211386\n",
      "train loss:0.001139840733696637\n",
      "train loss:0.0018143691585913093\n",
      "train loss:0.03471353697004143\n",
      "train loss:0.00033153578825341533\n",
      "train loss:0.002157443970175749\n",
      "train loss:0.0003104749509874477\n",
      "train loss:0.0004758853356330514\n",
      "train loss:0.0006664226414987675\n",
      "train loss:0.00010000229193341948\n",
      "train loss:0.0002109570518222544\n",
      "train loss:0.008825498093409113\n",
      "train loss:0.0022458564713135464\n",
      "train loss:0.007827463177752935\n",
      "train loss:0.001810641949609848\n",
      "train loss:0.003735608520350041\n",
      "train loss:0.004692508203476375\n",
      "train loss:0.0024564943094912573\n",
      "train loss:0.0038005911760376015\n",
      "train loss:0.0017903344207393262\n",
      "train loss:0.0016654126145607242\n",
      "train loss:0.00026748775266777826\n",
      "train loss:0.0008869231492899092\n",
      "train loss:0.00023485783437368954\n",
      "train loss:0.012659577989697175\n",
      "train loss:0.003938416382481149\n",
      "train loss:0.005237732587539445\n",
      "train loss:0.0047664771215643565\n",
      "train loss:0.0011945235884788092\n",
      "train loss:0.0026906931818350675\n",
      "train loss:0.004217786227144412\n",
      "train loss:0.0013222718919390472\n",
      "train loss:0.011435830784516522\n",
      "train loss:0.0013280881614271714\n",
      "train loss:0.003001183770056864\n",
      "train loss:0.040916765366890144\n",
      "train loss:0.0015837417426435524\n",
      "train loss:0.0007255349701826798\n",
      "train loss:0.002343133635307784\n",
      "train loss:0.00017320481779257147\n",
      "train loss:0.0008256754036794574\n",
      "train loss:0.0036958698067811567\n",
      "train loss:0.0001352148935571271\n",
      "train loss:0.000489491577128398\n",
      "train loss:0.0020496188592874233\n",
      "train loss:0.0007752976628215067\n",
      "train loss:0.001626281095709472\n",
      "train loss:0.0017706577734361497\n",
      "train loss:7.704495234126942e-05\n",
      "train loss:0.0026018643517035254\n",
      "train loss:0.00482474944513802\n",
      "train loss:0.0020065223971708164\n",
      "train loss:0.006089407782402089\n",
      "train loss:0.00017825532467352303\n",
      "train loss:0.00015498152982326845\n",
      "train loss:0.0002236139437244246\n",
      "train loss:0.000505746363108334\n",
      "train loss:0.0007441261571468597\n",
      "train loss:0.00011080862167150113\n",
      "train loss:0.00033104559896969256\n",
      "train loss:0.002611971324364547\n",
      "train loss:0.0039355722630694924\n",
      "train loss:0.015615743094337838\n",
      "train loss:0.001223777937449741\n",
      "train loss:0.0023916150363343333\n",
      "train loss:0.0010083374116087289\n",
      "train loss:0.002704845855088928\n",
      "train loss:0.0018487182771687127\n",
      "train loss:0.0008920447078104013\n",
      "train loss:0.001040696977514531\n",
      "train loss:0.002078958565231909\n",
      "train loss:0.00011180851405275126\n",
      "train loss:0.014257558677741512\n",
      "train loss:0.0049404686312678175\n",
      "train loss:0.002138311524984867\n",
      "train loss:0.003436395026422692\n",
      "train loss:0.00035716004632182385\n",
      "train loss:0.003661950779270949\n",
      "train loss:0.0020386178732110945\n",
      "train loss:0.0007510155125414629\n",
      "train loss:0.0031590287134969034\n",
      "train loss:0.0004940000566357678\n",
      "train loss:0.005898670854464217\n",
      "train loss:0.0007436557804998168\n",
      "train loss:0.002022309293953249\n",
      "train loss:0.0007667972964384706\n",
      "train loss:0.0065502242948872955\n",
      "train loss:0.0016485218696182234\n",
      "train loss:0.0021554727711288624\n",
      "train loss:0.00039883982389967825\n",
      "train loss:0.006987386111536789\n",
      "train loss:0.003270611602922867\n",
      "train loss:0.003924938066546419\n",
      "train loss:0.06758484679855001\n",
      "train loss:0.0008222530316325977\n",
      "train loss:0.0030434777729672286\n",
      "train loss:0.0004563778705983479\n",
      "train loss:0.003813250697634712\n",
      "train loss:0.0013535314382197906\n",
      "train loss:0.0025563952440760774\n",
      "train loss:0.005281307604213525\n",
      "train loss:0.0031600690792396107\n",
      "train loss:0.0019268500331430403\n",
      "train loss:0.0025468651029488514\n",
      "train loss:0.0005247995547291384\n",
      "train loss:0.001984043663232962\n",
      "train loss:8.291206294272579e-05\n",
      "train loss:0.0003927606014670804\n",
      "train loss:0.0006399814861620125\n",
      "train loss:0.0009612420432228108\n",
      "train loss:0.0017380450204512662\n",
      "train loss:0.0037229526677317213\n",
      "train loss:0.0055031974620812045\n",
      "train loss:0.1479386262153187\n",
      "train loss:0.002968892760459135\n",
      "train loss:0.0009283470126416649\n",
      "train loss:0.00031574490718116566\n",
      "train loss:0.00017503662259607024\n",
      "train loss:0.0037111702098628365\n",
      "train loss:0.0011014074610563361\n",
      "train loss:0.0018550984867335525\n",
      "train loss:0.0026641719623222994\n",
      "train loss:0.002879070000369208\n",
      "train loss:0.0030186324062114072\n",
      "train loss:0.00027381467614213907\n",
      "train loss:0.001632898515698548\n",
      "train loss:0.01136311400069755\n",
      "train loss:0.0008855170618716659\n",
      "train loss:0.0007341289995390153\n",
      "train loss:0.0011000163547906891\n",
      "train loss:0.00024008402804659781\n",
      "train loss:0.002773957194006271\n",
      "train loss:0.0009007107753518602\n",
      "train loss:0.0015418283404845076\n",
      "train loss:0.001751897523486696\n",
      "train loss:0.0009852982964714775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.000554811259245536\n",
      "train loss:0.001590515939106914\n",
      "train loss:0.002397020928463659\n",
      "train loss:0.009409977791815774\n",
      "train loss:0.001323293397059469\n",
      "train loss:0.004161394878055813\n",
      "train loss:0.0009284076054390417\n",
      "train loss:0.0015336548556171131\n",
      "train loss:0.013730923616392374\n",
      "train loss:0.0064149545956559365\n",
      "train loss:0.0013115964298954055\n",
      "train loss:0.00231086851647889\n",
      "train loss:0.0015078155385264106\n",
      "train loss:0.0034990345466394583\n",
      "train loss:0.0012818329254373389\n",
      "train loss:0.0001572141262307106\n",
      "train loss:0.00012003030362628982\n",
      "train loss:0.0007861098006332126\n",
      "train loss:0.0013132948039750044\n",
      "train loss:0.01846799951543472\n",
      "train loss:0.0019274391577023308\n",
      "train loss:0.0026333295680689844\n",
      "train loss:0.000616386430778296\n",
      "train loss:0.0015992848409562526\n",
      "train loss:0.0004974330026537526\n",
      "train loss:0.002718103615079971\n",
      "train loss:0.0004933830717797207\n",
      "train loss:0.0016038864215461818\n",
      "train loss:0.0026085790236300543\n",
      "train loss:0.00237289438723361\n",
      "train loss:0.0049492072132327385\n",
      "train loss:0.0017017653352123835\n",
      "train loss:0.0004982275465471258\n",
      "train loss:0.00030430395276715897\n",
      "train loss:0.0038142873881603697\n",
      "train loss:0.0033129430511335506\n",
      "train loss:0.0020052041236550914\n",
      "train loss:0.007362395488902609\n",
      "train loss:0.000262303614552851\n",
      "train loss:0.0025656123878599994\n",
      "train loss:0.0004365465126513075\n",
      "train loss:0.0008336606016030998\n",
      "train loss:0.002735811493401959\n",
      "train loss:0.006521342622743109\n",
      "train loss:0.001475557843862705\n",
      "train loss:0.0028261181701326995\n",
      "train loss:0.0011569953804898845\n",
      "train loss:0.0033504960878834715\n",
      "train loss:0.0036295672130718833\n",
      "train loss:0.0009870987234622704\n",
      "train loss:0.02076967989205406\n",
      "train loss:0.00312891826869543\n",
      "train loss:0.0011577953313760528\n",
      "train loss:0.0008452403921005296\n",
      "train loss:0.012113688706303806\n",
      "train loss:0.0006716097710550076\n",
      "train loss:0.00041962743208705765\n",
      "train loss:0.0005475601766772731\n",
      "train loss:0.005677052366245095\n",
      "train loss:0.0018689003652406508\n",
      "train loss:0.0004970218105454971\n",
      "train loss:0.003804320374182716\n",
      "train loss:0.0021074415529131127\n",
      "train loss:0.0005866490884351089\n",
      "train loss:0.0012273021155108823\n",
      "train loss:0.003684364286076914\n",
      "train loss:0.003957021892958668\n",
      "train loss:0.0018481861729349213\n",
      "train loss:0.0025255336408070515\n",
      "train loss:0.0010902931315724502\n",
      "train loss:0.0006548486889183461\n",
      "train loss:0.0015205812885491937\n",
      "train loss:0.001304943410062045\n",
      "train loss:0.00036974683798999674\n",
      "train loss:0.0025797671653248954\n",
      "train loss:0.0015291682791061586\n",
      "train loss:0.004009554223676658\n",
      "train loss:0.0005504380008341365\n",
      "train loss:0.0005494846675242684\n",
      "train loss:0.0008507559996989747\n",
      "train loss:0.00022710861031442252\n",
      "train loss:6.239415565141289e-05\n",
      "train loss:0.006015412465997668\n",
      "train loss:0.008457377917304748\n",
      "train loss:0.0009310826763489128\n",
      "train loss:0.0037307384463881876\n",
      "train loss:0.0032644990898592434\n",
      "train loss:0.00030978063676712666\n",
      "train loss:0.01227137222478452\n",
      "train loss:0.0028590035375844875\n",
      "train loss:0.022098158094444282\n",
      "train loss:0.0008612339815331866\n",
      "train loss:0.004193470066652822\n",
      "train loss:0.000573029393644115\n",
      "train loss:0.0021754608255475667\n",
      "train loss:0.00673573464943446\n",
      "train loss:0.0021379178975206737\n",
      "train loss:0.0012384212972597344\n",
      "train loss:0.0027619799785467487\n",
      "train loss:0.007797640357323792\n",
      "train loss:0.000741207328570163\n",
      "train loss:0.0013089080786709115\n",
      "train loss:0.0005780798522191808\n",
      "train loss:0.0035454358779401845\n",
      "train loss:0.0019848643017030113\n",
      "train loss:0.0010652039178483507\n",
      "train loss:0.0010581049264021336\n",
      "train loss:0.00016960400762755054\n",
      "train loss:0.00025188526410408445\n",
      "train loss:0.0005530239524287351\n",
      "train loss:0.002718855204431041\n",
      "train loss:0.0003237285766617024\n",
      "train loss:0.0003994927206847126\n",
      "train loss:0.003784398857531754\n",
      "train loss:0.0029229395233302236\n",
      "train loss:0.01902595848759767\n",
      "train loss:0.0027933371409713664\n",
      "train loss:2.2616892969544816e-05\n",
      "train loss:0.0005158365334220586\n",
      "train loss:0.0037654521132238807\n",
      "train loss:0.003156872206413799\n",
      "train loss:0.0003853114779740981\n",
      "train loss:3.1523443227386694e-05\n",
      "train loss:0.0009170629007313637\n",
      "train loss:0.0003594840416238037\n",
      "train loss:0.000677296099697103\n",
      "train loss:0.0024727948365908126\n",
      "train loss:0.003287946468511158\n",
      "train loss:0.0014041703594853208\n",
      "train loss:0.0008103521618540343\n",
      "train loss:0.0001806436643422689\n",
      "train loss:0.0005962229972478681\n",
      "train loss:0.0030795361132103473\n",
      "train loss:0.006493766453885774\n",
      "train loss:0.0024452056711222704\n",
      "train loss:0.0008172586461273526\n",
      "train loss:0.0010125807844526432\n",
      "train loss:0.0013314459952763105\n",
      "train loss:0.0005131773587376096\n",
      "train loss:0.0003301907730637371\n",
      "train loss:0.00017942807763782272\n",
      "train loss:0.008707850055939343\n",
      "train loss:0.00010147282289079658\n",
      "train loss:0.0013148669185221117\n",
      "train loss:0.0024245273632406655\n",
      "train loss:0.000531765510593215\n",
      "train loss:0.00037651391829139256\n",
      "train loss:0.00018436089684455988\n",
      "train loss:0.00036447732568731543\n",
      "train loss:0.0012389843162100968\n",
      "train loss:7.997373883067309e-05\n",
      "train loss:0.00422182817327472\n",
      "train loss:0.0005455349503662519\n",
      "train loss:9.88037210523565e-05\n",
      "train loss:0.001542841470230523\n",
      "train loss:0.0009481307329958768\n",
      "train loss:0.0006876051617202828\n",
      "train loss:0.0007108355556274804\n",
      "train loss:0.00010792525623744132\n",
      "train loss:0.00035045621146203855\n",
      "train loss:0.0004681672358064896\n",
      "train loss:0.00992204177053981\n",
      "train loss:0.0006319998214887775\n",
      "train loss:0.00032175340716369656\n",
      "train loss:0.00014531502718896655\n",
      "train loss:0.00011798043799705836\n",
      "train loss:0.00044678877342453215\n",
      "train loss:0.00046401087187077355\n",
      "train loss:0.005060045272230554\n",
      "train loss:0.00011405498747777097\n",
      "train loss:0.00848056210069826\n",
      "train loss:0.0015470713861461174\n",
      "train loss:0.0002478157730984332\n",
      "train loss:0.004074800592473002\n",
      "train loss:0.00010455923110947776\n",
      "train loss:0.0004679275988651506\n",
      "train loss:0.0009761277892900488\n",
      "train loss:0.00042113777785368373\n",
      "train loss:0.002561849292850551\n",
      "train loss:4.656185034755101e-05\n",
      "train loss:0.0006989900920622244\n",
      "train loss:0.0006010617257854571\n",
      "train loss:0.0008272089790552008\n",
      "train loss:0.0040511270262016934\n",
      "train loss:0.001752161288443274\n",
      "train loss:0.02105268328401729\n",
      "train loss:0.00034664960843174187\n",
      "train loss:0.00083627746592213\n",
      "train loss:0.00021142544754575155\n",
      "train loss:0.0001191273844351653\n",
      "train loss:0.0006641407789738415\n",
      "train loss:0.0013128293392015732\n",
      "train loss:0.0019183965356028934\n",
      "train loss:0.0008902350261908616\n",
      "train loss:0.0017465111544654518\n",
      "train loss:0.0020712026541197855\n",
      "train loss:5.039232811338689e-05\n",
      "train loss:0.0005409391877528673\n",
      "train loss:0.0009058090615582886\n",
      "train loss:0.0006816939001165057\n",
      "train loss:0.0009484395739106162\n",
      "train loss:0.002613119066922472\n",
      "train loss:0.00036965650449213914\n",
      "train loss:0.0011176842398519312\n",
      "train loss:0.0017617604733253774\n",
      "train loss:0.000858550176081067\n",
      "train loss:0.005193537179913252\n",
      "train loss:0.0005067199677256549\n",
      "train loss:0.0006268389840952052\n",
      "train loss:0.0005286977860239684\n",
      "train loss:0.005644756005792928\n",
      "train loss:0.0018270665029372782\n",
      "train loss:0.00046066422495226293\n",
      "train loss:0.0011211287691718017\n",
      "train loss:0.002619884844975656\n",
      "train loss:0.00031643357506957055\n",
      "train loss:0.0005089489298127469\n",
      "train loss:0.0005314443090160981\n",
      "train loss:0.0015831998761438315\n",
      "train loss:0.0006997164509364919\n",
      "train loss:0.0004955544614478933\n",
      "train loss:0.0004726500427827052\n",
      "train loss:8.383538716012387e-05\n",
      "train loss:0.0004556712992985834\n",
      "train loss:0.0014142692743443677\n",
      "train loss:0.0032642178167105883\n",
      "train loss:0.0006648100760437652\n",
      "train loss:0.002716361382632717\n",
      "train loss:0.020884946044186687\n",
      "train loss:0.004630497861492382\n",
      "train loss:0.019504575010909832\n",
      "train loss:0.0004225760160312659\n",
      "train loss:6.692385623170977e-05\n",
      "train loss:0.00011895542925284777\n",
      "train loss:0.002213363043056224\n",
      "train loss:0.003873648176545468\n",
      "train loss:0.00021795709874637969\n",
      "train loss:0.0011877177019809764\n",
      "train loss:0.0010972777904004081\n",
      "train loss:0.0009594977380153746\n",
      "train loss:0.00048045917424228616\n",
      "train loss:0.0031606982870026\n",
      "train loss:0.0006928971572273692\n",
      "train loss:0.0010191814638346487\n",
      "train loss:0.00013395982165676575\n",
      "train loss:0.0012135275319893062\n",
      "train loss:0.0001281844421575702\n",
      "train loss:0.0004468346916033345\n",
      "train loss:0.00498310178545348\n",
      "train loss:0.0014703059709754093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0014765599056946277\n",
      "train loss:0.0002034819172209385\n",
      "train loss:0.0030355853528155163\n",
      "train loss:0.0020475915946877644\n",
      "train loss:0.004935116583021803\n",
      "train loss:0.0017076593159694375\n",
      "train loss:0.00031790666083289195\n",
      "train loss:0.0006198385218369768\n",
      "train loss:0.007011293277452663\n",
      "train loss:0.0024197551344104363\n",
      "train loss:0.0011087319323043834\n",
      "train loss:0.00021811122649278042\n",
      "train loss:0.0012553507232472504\n",
      "train loss:0.0006301664366232896\n",
      "train loss:0.00014872069136251587\n",
      "train loss:0.0015645592940543912\n",
      "train loss:0.002714804390702226\n",
      "train loss:0.0007263051040878039\n",
      "train loss:0.0011648070865806451\n",
      "train loss:0.007497028597684958\n",
      "train loss:0.0009665716981950244\n",
      "train loss:6.731341646112548e-05\n",
      "train loss:0.00015681265431278333\n",
      "train loss:0.003262562160495871\n",
      "train loss:6.81367954553166e-05\n",
      "train loss:0.0003700825223137233\n",
      "train loss:0.0029000780976804904\n",
      "train loss:0.00017714770172734407\n",
      "train loss:0.0010787518617555246\n",
      "train loss:0.0002883538394782483\n",
      "train loss:0.0002475142115771498\n",
      "train loss:0.0006283535143455708\n",
      "train loss:0.0036702531937760387\n",
      "train loss:0.004036130767706892\n",
      "train loss:0.000986403289776056\n",
      "train loss:0.008529124314041242\n",
      "train loss:0.0003233657958332535\n",
      "train loss:0.0006923333631180427\n",
      "train loss:0.0012696764510447584\n",
      "train loss:0.0002405740195566897\n",
      "train loss:0.00010450009331333715\n",
      "train loss:0.0071985951751391995\n",
      "train loss:8.785188987703584e-05\n",
      "train loss:0.006190930689237973\n",
      "train loss:0.0005166146672497396\n",
      "train loss:0.002701211009488222\n",
      "train loss:0.0037170502141568185\n",
      "train loss:0.001468962103675231\n",
      "train loss:0.0004323163952247635\n",
      "train loss:0.003472053515427483\n",
      "train loss:0.0035992188482157224\n",
      "train loss:0.0003705848130070137\n",
      "train loss:0.0015913071566484285\n",
      "train loss:0.0005770150805061179\n",
      "train loss:3.345293948683316e-05\n",
      "train loss:0.0034590743440208477\n",
      "train loss:0.00820494535374774\n",
      "train loss:0.001228200899821414\n",
      "train loss:0.0023022221619008656\n",
      "train loss:0.0014832180398326304\n",
      "train loss:0.00626395866418789\n",
      "train loss:0.0053639165851778105\n",
      "train loss:0.0010306049808382308\n",
      "train loss:0.0064918061680680796\n",
      "train loss:0.0009424859737755411\n",
      "train loss:0.0009288620701524214\n",
      "train loss:0.00034957325259756347\n",
      "train loss:0.00011951668999471764\n",
      "train loss:0.0012659230648294653\n",
      "train loss:0.0008218947652249984\n",
      "train loss:0.002182851752147663\n",
      "train loss:0.0016155642462105204\n",
      "train loss:0.0011539938142570098\n",
      "train loss:0.0011379446290882744\n",
      "train loss:0.0008787018080719457\n",
      "train loss:0.006367428456226509\n",
      "train loss:0.007594189068093841\n",
      "train loss:0.0013766122559958013\n",
      "train loss:0.001119012259911423\n",
      "train loss:0.0025887450123567805\n",
      "train loss:0.0009884742389818745\n",
      "train loss:0.004025712407057778\n",
      "train loss:0.0012898656390815904\n",
      "train loss:0.0030809623703390906\n",
      "train loss:0.0022470951028794373\n",
      "train loss:0.001351700471814297\n",
      "train loss:0.00020964656188757918\n",
      "train loss:0.00190253365405486\n",
      "train loss:0.0010722905801990245\n",
      "train loss:0.00075908679105196\n",
      "train loss:0.001168814112665884\n",
      "train loss:0.0024076604661123087\n",
      "train loss:0.0015672306981291961\n",
      "=== epoch:17, train acc:0.996, test acc:0.987 ===\n",
      "train loss:0.0012505706639734692\n",
      "train loss:0.0006995107087880119\n",
      "train loss:0.0005547638843713402\n",
      "train loss:0.0020161540944857257\n",
      "train loss:0.001300380384105842\n",
      "train loss:0.0008583542162195573\n",
      "train loss:0.001785378090366423\n",
      "train loss:0.0009480022882965934\n",
      "train loss:0.0013415698643715929\n",
      "train loss:0.0006288131973286522\n",
      "train loss:7.293348517743665e-05\n",
      "train loss:0.0006900300879942034\n",
      "train loss:0.0010169862700400456\n",
      "train loss:0.0019284508693616417\n",
      "train loss:0.001856616076633461\n",
      "train loss:0.0032863269617505885\n",
      "train loss:0.002251850902342263\n",
      "train loss:0.0008872933269507848\n",
      "train loss:0.0017233666532915546\n",
      "train loss:0.00243005940236188\n",
      "train loss:0.0026831261754734865\n",
      "train loss:0.003203788373449945\n",
      "train loss:0.00012846119440982086\n",
      "train loss:0.000386876549220938\n",
      "train loss:0.0007091551323960602\n",
      "train loss:0.0011312527891072215\n",
      "train loss:0.0004992270687671197\n",
      "train loss:0.0008012833059954844\n",
      "train loss:0.0006155451805621996\n",
      "train loss:0.00023563375326577735\n",
      "train loss:0.0003567228305404245\n",
      "train loss:0.0007013410775184418\n",
      "train loss:0.002145034529646039\n",
      "train loss:0.011723680086906618\n",
      "train loss:0.001312574590421959\n",
      "train loss:0.015590660311617916\n",
      "train loss:0.0020028527619662963\n",
      "train loss:0.007606398593523938\n",
      "train loss:0.03238297656714474\n",
      "train loss:0.004279885173643648\n",
      "train loss:0.0013028805350309871\n",
      "train loss:0.0016133595020034446\n",
      "train loss:0.0006921477069765597\n",
      "train loss:0.00013593344526327121\n",
      "train loss:0.004262930230657419\n",
      "train loss:0.007493505978573067\n",
      "train loss:0.0010789970683023587\n",
      "train loss:0.0005204541034239382\n",
      "train loss:0.00030804746084887803\n",
      "train loss:0.0077579427309007595\n",
      "train loss:0.0036364986129059063\n",
      "train loss:0.0030832718739482795\n",
      "train loss:0.0001607288104366586\n",
      "train loss:0.002610987433959734\n",
      "train loss:0.006336072893018249\n",
      "train loss:0.0004184051312000674\n",
      "train loss:0.0003884906993279886\n",
      "train loss:0.0019891619157195815\n",
      "train loss:0.003227178396679098\n",
      "train loss:0.00039207493338320955\n",
      "train loss:0.0006278651185994922\n",
      "train loss:0.0002715518514614898\n",
      "train loss:0.0026151995990360707\n",
      "train loss:0.00010299037105946843\n",
      "train loss:0.00047071444842682574\n",
      "train loss:0.002352728223484338\n",
      "train loss:0.0011150124837379456\n",
      "train loss:0.0008227965681580987\n",
      "train loss:0.002161952952329768\n",
      "train loss:0.005942190260376179\n",
      "train loss:0.0013801305855912311\n",
      "train loss:0.010511143090200894\n",
      "train loss:0.0015739806960015762\n",
      "train loss:0.003183736298012488\n",
      "train loss:0.01748239533349686\n",
      "train loss:0.00033365622356895463\n",
      "train loss:0.0012976831419640135\n",
      "train loss:0.00021102026766754538\n",
      "train loss:0.013445914151184221\n",
      "train loss:0.005991409453290261\n",
      "train loss:0.0004807585646040865\n",
      "train loss:0.00032343036033276274\n",
      "train loss:0.00022556421074809767\n",
      "train loss:0.003037128690474953\n",
      "train loss:5.2584157196425815e-05\n",
      "train loss:0.0018005882882495036\n",
      "train loss:0.007728295903729781\n",
      "train loss:0.003050340521078758\n",
      "train loss:0.0001370361085129445\n",
      "train loss:0.0012648553452779129\n",
      "train loss:0.00016483640750181492\n",
      "train loss:0.00043176973827024353\n",
      "train loss:0.013157211378090887\n",
      "train loss:0.002628450101709699\n",
      "train loss:0.04322387773620464\n",
      "train loss:0.004981261151629165\n",
      "train loss:0.0004611400899581846\n",
      "train loss:0.0024995463970651035\n",
      "train loss:0.0027985293652810508\n",
      "train loss:0.0056637936697091565\n",
      "train loss:0.002987625959148883\n",
      "train loss:0.0014074832534378935\n",
      "train loss:0.002791536977644706\n",
      "train loss:0.0019068240011100189\n",
      "train loss:0.004571906982843404\n",
      "train loss:0.007809637793663684\n",
      "train loss:0.0057047908868318505\n",
      "train loss:0.0038510917466094974\n",
      "train loss:0.0026369897606278057\n",
      "train loss:0.0015971594113970112\n",
      "train loss:0.049254328677450665\n",
      "train loss:0.003438507947136947\n",
      "train loss:0.00128888229459665\n",
      "train loss:0.0009517846199545807\n",
      "train loss:0.007680357740137329\n",
      "train loss:0.006245168686625675\n",
      "train loss:0.0010579646296335953\n",
      "train loss:0.003986696401803355\n",
      "train loss:0.004910551053501066\n",
      "train loss:0.000491762315843158\n",
      "train loss:0.002197380173011224\n",
      "train loss:0.007318730212983171\n",
      "train loss:0.0034414643507732655\n",
      "train loss:0.0094394965297609\n",
      "train loss:0.03127089039633927\n",
      "train loss:0.00046754183204832247\n",
      "train loss:9.41602811916618e-05\n",
      "train loss:0.0023785312632431175\n",
      "train loss:0.003315046107221427\n",
      "train loss:0.002140155900184886\n",
      "train loss:0.005594202750055415\n",
      "train loss:0.0005620963627710738\n",
      "train loss:0.0005924161980579876\n",
      "train loss:0.00014163614422333114\n",
      "train loss:0.001702901915960601\n",
      "train loss:0.0024387133765259297\n",
      "train loss:0.0010605654535587909\n",
      "train loss:0.0003817818973342616\n",
      "train loss:0.0054151168629843\n",
      "train loss:0.002186543439076934\n",
      "train loss:0.006743438038397275\n",
      "train loss:0.00010469378456322151\n",
      "train loss:0.005607749859761114\n",
      "train loss:0.01135436724826995\n",
      "train loss:0.006230781244146758\n",
      "train loss:0.0007081498217657395\n",
      "train loss:0.00013496858187239007\n",
      "train loss:0.0045823240327358865\n",
      "train loss:0.018090526506841884\n",
      "train loss:0.0006411580678766051\n",
      "train loss:0.011765514060135696\n",
      "train loss:0.0008680295244719027\n",
      "train loss:0.0007308813702046725\n",
      "train loss:0.002141580265901587\n",
      "train loss:0.0015881766009782736\n",
      "train loss:0.014007601818226663\n",
      "train loss:0.008051157940783373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0015747798354797087\n",
      "train loss:0.0024683608969437647\n",
      "train loss:0.005969971102384207\n",
      "train loss:0.0030038860356826017\n",
      "train loss:0.007727005614061908\n",
      "train loss:0.0015406606078362895\n",
      "train loss:0.0008135574290656823\n",
      "train loss:0.0025741354539712985\n",
      "train loss:0.007480339776778445\n",
      "train loss:0.0023458811294005\n",
      "train loss:0.0015168574065539946\n",
      "train loss:0.043733111228524156\n",
      "train loss:0.0007966277669221637\n",
      "train loss:0.0002719439326260711\n",
      "train loss:0.0009868399609951853\n",
      "train loss:0.002608807167932662\n",
      "train loss:3.44379490605316e-05\n",
      "train loss:0.0040072208792114265\n",
      "train loss:0.00018829153384990904\n",
      "train loss:0.0012364629018249843\n",
      "train loss:0.004609574026692665\n",
      "train loss:0.0006954063160238377\n",
      "train loss:0.0013700599368747493\n",
      "train loss:0.010602332695348809\n",
      "train loss:0.0025227507485013788\n",
      "train loss:0.0168088348273403\n",
      "train loss:0.002840986138963047\n",
      "train loss:0.002235644057987615\n",
      "train loss:0.04694254531722507\n",
      "train loss:0.0005383507961507524\n",
      "train loss:0.006000025118375253\n",
      "train loss:0.0012933805100242247\n",
      "train loss:0.010547386890687994\n",
      "train loss:0.0003641149039465701\n",
      "train loss:0.0009771604084423315\n",
      "train loss:0.0015300379897437383\n",
      "train loss:0.0006725440099124635\n",
      "train loss:0.021715974191525794\n",
      "train loss:0.002145839001254919\n",
      "train loss:0.014906680323036279\n",
      "train loss:0.0011486797457827122\n",
      "train loss:0.0011572921636383788\n",
      "train loss:0.00021097350110212777\n",
      "train loss:0.0003550016948421497\n",
      "train loss:0.0019744791849441797\n",
      "train loss:0.015448298633745553\n",
      "train loss:0.004614040267353486\n",
      "train loss:0.00014596124996610498\n",
      "train loss:0.003695607010517894\n",
      "train loss:0.007255037301822611\n",
      "train loss:0.039066320490079846\n",
      "train loss:0.0012206381657774892\n",
      "train loss:0.0008747715366054652\n",
      "train loss:0.000531166914288557\n",
      "train loss:0.003294009383922906\n",
      "train loss:0.01602310133868384\n",
      "train loss:0.00014681137170704443\n",
      "train loss:0.0009505836595355178\n",
      "train loss:0.0013776902461189\n",
      "train loss:0.006402911424716174\n",
      "train loss:0.0036399068726032237\n",
      "train loss:0.0016656444533984587\n",
      "train loss:0.00030325917513214376\n",
      "train loss:0.0022247847655547126\n",
      "train loss:0.011478102079084628\n",
      "train loss:0.0028194152929262267\n",
      "train loss:0.005884840695774877\n",
      "train loss:0.00017010709938754406\n",
      "train loss:0.00018207761553339953\n",
      "train loss:0.001986931974341619\n",
      "train loss:0.004060681486060273\n",
      "train loss:0.002641303720673138\n",
      "train loss:0.0008200706684331335\n",
      "train loss:0.0013551593494257382\n",
      "train loss:0.00595904716579264\n",
      "train loss:0.003410940004452817\n",
      "train loss:0.00044150726715548957\n",
      "train loss:0.000354404030642856\n",
      "train loss:0.021413518121805798\n",
      "train loss:0.001551984258685412\n",
      "train loss:0.003716470470906736\n",
      "train loss:0.0008429518038821049\n",
      "train loss:0.0004098370491782234\n",
      "train loss:0.0018972011735861225\n",
      "train loss:0.002434184700659383\n",
      "train loss:0.0010388232637744243\n",
      "train loss:0.006168398731049832\n",
      "train loss:0.0005252674813968331\n",
      "train loss:0.007616184450423006\n",
      "train loss:0.0004424525722021663\n",
      "train loss:0.00013655156873235424\n",
      "train loss:0.0020481608529139537\n",
      "train loss:0.013234497779750087\n",
      "train loss:0.0014139577138387637\n",
      "train loss:0.0005872136177862215\n",
      "train loss:0.0014170864157865223\n",
      "train loss:0.0034298991051428247\n",
      "train loss:0.0009171825713395848\n",
      "train loss:0.0020653932400674507\n",
      "train loss:0.008650714783513008\n",
      "train loss:0.007864194324462748\n",
      "train loss:0.001096722187715499\n",
      "train loss:0.0016968495488490062\n",
      "train loss:0.0005142302126736184\n",
      "train loss:0.006009453036026339\n",
      "train loss:0.0045165709227577774\n",
      "train loss:0.0038358903601064974\n",
      "train loss:0.0034312295746506904\n",
      "train loss:0.01763125311813495\n",
      "train loss:0.0007711483667468148\n",
      "train loss:0.003709240305112116\n",
      "train loss:0.0037904009115533855\n",
      "train loss:0.0054782574917537005\n",
      "train loss:0.00012627324941968766\n",
      "train loss:0.0030152554757602967\n",
      "train loss:0.002126762849580612\n",
      "train loss:0.0024024917558751256\n",
      "train loss:0.0005980091720703477\n",
      "train loss:0.0015675721360196696\n",
      "train loss:0.0049020275746354345\n",
      "train loss:0.0006035627514212063\n",
      "train loss:0.0058783687266172205\n",
      "train loss:0.001060118764991015\n",
      "train loss:0.0054265059269882135\n",
      "train loss:0.05895870948623206\n",
      "train loss:0.0021343461258422087\n",
      "train loss:0.008255073096746623\n",
      "train loss:0.0016857821641217783\n",
      "train loss:0.0008345020517788653\n",
      "train loss:0.05001376914896101\n",
      "train loss:0.0008265721017835404\n",
      "train loss:0.0020754988552245906\n",
      "train loss:0.0008266410873313912\n",
      "train loss:0.00032027852444022455\n",
      "train loss:0.0016742478414697565\n",
      "train loss:0.002012572498364378\n",
      "train loss:0.001659427380436365\n",
      "train loss:0.00526459887304957\n",
      "train loss:0.0030539918713104303\n",
      "train loss:0.001586890508662233\n",
      "train loss:0.0029106509077524855\n",
      "train loss:0.002109478438783996\n",
      "train loss:0.00012612252892691377\n",
      "train loss:0.000847602272215912\n",
      "train loss:7.77896875559197e-05\n",
      "train loss:0.0019709738917845702\n",
      "train loss:0.0006749323510727545\n",
      "train loss:0.0004207685768005314\n",
      "train loss:0.005805631421764563\n",
      "train loss:0.01854510663468605\n",
      "train loss:0.000521051339634532\n",
      "train loss:0.0003075752103787092\n",
      "train loss:0.0004692755708687387\n",
      "train loss:0.00013187220775377038\n",
      "train loss:0.0006618451190919048\n",
      "train loss:0.00040601902598571253\n",
      "train loss:0.00040570650871446534\n",
      "train loss:0.0032138071536759578\n",
      "train loss:0.0009808752013774043\n",
      "train loss:0.0007331969659587831\n",
      "train loss:0.0019597210743288653\n",
      "train loss:0.015513806697208993\n",
      "train loss:0.00021267059542685017\n",
      "train loss:0.0007869444928798025\n",
      "train loss:0.00043063764305391485\n",
      "train loss:0.002481747363838219\n",
      "train loss:0.002915907062803399\n",
      "train loss:0.0010724717549264109\n",
      "train loss:0.0005071393284695602\n",
      "train loss:0.0015589822781436641\n",
      "train loss:0.00020043086276138559\n",
      "train loss:0.003257118547261786\n",
      "train loss:0.0014280566180829549\n",
      "train loss:0.0006262715616213608\n",
      "train loss:0.0008769348247082493\n",
      "train loss:0.00017082856326879173\n",
      "train loss:0.001881442839057991\n",
      "train loss:0.0027273458525591803\n",
      "train loss:0.00041673710530842456\n",
      "train loss:0.0073888955846456465\n",
      "train loss:0.010728553351726067\n",
      "train loss:0.00167955475912704\n",
      "train loss:0.0006184730620805382\n",
      "train loss:0.004731894396253284\n",
      "train loss:0.0027685231444068968\n",
      "train loss:0.004898936307886031\n",
      "train loss:0.0015764428435121119\n",
      "train loss:0.00159225475753628\n",
      "train loss:0.0004902550940568405\n",
      "train loss:0.001982696949592424\n",
      "train loss:0.004746568132856693\n",
      "train loss:0.005142242120927936\n",
      "train loss:0.004215858673782063\n",
      "train loss:0.0012807155748788771\n",
      "train loss:0.0008322792443027381\n",
      "train loss:0.00017426453848896643\n",
      "train loss:0.010944582366446005\n",
      "train loss:0.000596621127582765\n",
      "train loss:0.0010720370505993692\n",
      "train loss:0.00015281880450956418\n",
      "train loss:0.0013420112610445251\n",
      "train loss:0.004772107930266242\n",
      "train loss:0.00045650708561460653\n",
      "train loss:0.002356811625901794\n",
      "train loss:0.005823243957930119\n",
      "train loss:0.0024663159769653022\n",
      "train loss:0.0011370727346189254\n",
      "train loss:0.0008607383899938221\n",
      "train loss:0.0005198427259611241\n",
      "train loss:0.00014309034810771175\n",
      "train loss:0.0009529970971597382\n",
      "train loss:0.021172929466525065\n",
      "train loss:0.0002688972815334649\n",
      "train loss:0.005623768820997104\n",
      "train loss:0.0006568450183193724\n",
      "train loss:0.006457013548858906\n",
      "train loss:0.0011808427705869054\n",
      "train loss:7.19141949822457e-05\n",
      "train loss:0.0007829099412590996\n",
      "train loss:0.0005149335661160891\n",
      "train loss:0.0013520616425901691\n",
      "train loss:0.0006881997526182019\n",
      "train loss:0.00048797302233182833\n",
      "train loss:0.0019217219615615955\n",
      "train loss:0.002686416018003017\n",
      "train loss:0.001280684896398446\n",
      "train loss:0.00038329700350957826\n",
      "train loss:0.0010352865595285531\n",
      "train loss:0.0002618210970280873\n",
      "train loss:0.004377307019702105\n",
      "train loss:0.0001941767901249156\n",
      "train loss:0.00047612078354916697\n",
      "train loss:0.0032161137137822517\n",
      "train loss:0.000988823340122865\n",
      "train loss:0.003446488474670986\n",
      "train loss:3.914624240156819e-05\n",
      "train loss:0.0009288806967657962\n",
      "train loss:0.0003186682053012812\n",
      "train loss:0.005738378107799477\n",
      "train loss:0.0017127456792362555\n",
      "train loss:0.0012481719713877406\n",
      "train loss:0.002619644997602254\n",
      "train loss:0.002031208932527228\n",
      "train loss:0.0033983686811048614\n",
      "train loss:4.637496009723315e-05\n",
      "train loss:0.0038603821730316228\n",
      "train loss:0.0016163694206950345\n",
      "train loss:8.822509238988512e-05\n",
      "train loss:0.018879346258950415\n",
      "train loss:0.005209263004466644\n",
      "train loss:0.0013156713502956163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0010988206210798416\n",
      "train loss:0.002138620060472931\n",
      "train loss:0.0018317869313153215\n",
      "train loss:0.00038649184029649995\n",
      "train loss:0.00565767023458217\n",
      "train loss:0.00039224479123915946\n",
      "train loss:0.0005237735346175782\n",
      "train loss:0.0030504000931199466\n",
      "train loss:0.010189843462873912\n",
      "train loss:0.0035107449851078994\n",
      "train loss:0.001268138099152104\n",
      "train loss:0.0036005025848298944\n",
      "train loss:0.006777408892330079\n",
      "train loss:0.0006335606752618589\n",
      "train loss:0.00028132914010289205\n",
      "train loss:0.00021561114066645986\n",
      "train loss:0.0006894202706600892\n",
      "train loss:6.361349149871939e-06\n",
      "train loss:0.0010353301134985546\n",
      "train loss:0.002760338817183909\n",
      "train loss:0.003997171274957845\n",
      "train loss:0.0002133554011791739\n",
      "train loss:0.0007502450591057788\n",
      "train loss:0.00012142658205736806\n",
      "train loss:0.0018823544102784678\n",
      "train loss:0.0011837452388755382\n",
      "train loss:0.010991681402487945\n",
      "train loss:0.0001025748861834654\n",
      "train loss:0.0026650414552048503\n",
      "train loss:0.0005299345030300957\n",
      "train loss:0.0008045904806223593\n",
      "train loss:0.00021762331339173063\n",
      "train loss:0.006675484897407808\n",
      "train loss:0.0011483035459148119\n",
      "train loss:0.002219497386173323\n",
      "train loss:0.0006716209597087304\n",
      "train loss:0.004415269115961049\n",
      "train loss:0.0011867986232486126\n",
      "train loss:0.002244029908982243\n",
      "train loss:0.0029081707798996265\n",
      "train loss:0.000549319771924775\n",
      "train loss:0.0010245598800154062\n",
      "train loss:0.0003937482227155027\n",
      "train loss:0.0006107893121568566\n",
      "train loss:0.005257921315479339\n",
      "train loss:0.002822625667882164\n",
      "train loss:0.0004992456567963627\n",
      "train loss:0.00029987111785915993\n",
      "train loss:0.0017618678781059095\n",
      "train loss:0.00021712120348118071\n",
      "train loss:0.0003292023767448627\n",
      "train loss:0.0003456321115360571\n",
      "train loss:0.0026973773009203684\n",
      "train loss:0.0016511291594480254\n",
      "train loss:0.0026180217120078003\n",
      "train loss:0.0007730446231881614\n",
      "train loss:0.0018488177219329435\n",
      "train loss:0.00028738672878970994\n",
      "train loss:0.005288217179980065\n",
      "train loss:0.0006824579804276538\n",
      "train loss:0.009160752311500346\n",
      "train loss:0.0003472434073057428\n",
      "train loss:0.0005787956667108667\n",
      "train loss:0.00020312306574103893\n",
      "train loss:0.003515790815631747\n",
      "train loss:0.003947219985763626\n",
      "train loss:0.0074762287126768955\n",
      "train loss:0.001521967692550537\n",
      "train loss:0.0020569963536853555\n",
      "train loss:0.004072148273357039\n",
      "train loss:0.0037513757348655447\n",
      "train loss:0.004116725398876335\n",
      "train loss:0.0015658412326799332\n",
      "train loss:0.00018642689432154315\n",
      "train loss:0.00018563445842220745\n",
      "train loss:7.259465932221343e-05\n",
      "train loss:0.00017897481908882046\n",
      "train loss:0.0005847128767307392\n",
      "train loss:0.0007915348344751153\n",
      "train loss:0.002673152085307535\n",
      "train loss:0.0006761031858795817\n",
      "train loss:0.0004086073373280809\n",
      "train loss:0.0016781710100967368\n",
      "train loss:0.007823268218125562\n",
      "train loss:0.00021064737142802192\n",
      "train loss:0.0004920123614043169\n",
      "train loss:0.0009596234971361761\n",
      "train loss:0.005131381456553447\n",
      "train loss:0.0002974227460240217\n",
      "train loss:0.0023374405114835136\n",
      "train loss:0.0013205734815367543\n",
      "train loss:0.0018649187031095234\n",
      "train loss:4.9438262630662406e-05\n",
      "train loss:0.0024129672401758556\n",
      "train loss:0.0009804632695322424\n",
      "train loss:0.0010813391780709616\n",
      "train loss:0.0003083996603799399\n",
      "train loss:0.001004090940821052\n",
      "train loss:0.0018020053346082126\n",
      "train loss:0.007036945965326563\n",
      "train loss:0.005210424353103831\n",
      "train loss:0.00209376902711521\n",
      "train loss:0.002905103408644582\n",
      "train loss:0.000921627493678727\n",
      "train loss:0.0014909076716655657\n",
      "train loss:0.0005348778971903889\n",
      "train loss:0.00038331519788116877\n",
      "train loss:0.0019930211587681572\n",
      "train loss:0.0010193871748062082\n",
      "train loss:0.001439218390211259\n",
      "train loss:0.0023965681106807466\n",
      "train loss:0.004909673869629889\n",
      "train loss:0.0003243788865483968\n",
      "train loss:0.003254797012930929\n",
      "train loss:0.0017289377474490417\n",
      "train loss:9.046097933008199e-05\n",
      "train loss:0.0017269184176018392\n",
      "train loss:0.0025739001972210035\n",
      "train loss:0.0016324077899929736\n",
      "train loss:0.0026188654838619047\n",
      "train loss:0.0007796278213587855\n",
      "train loss:0.00021645853057392073\n",
      "train loss:0.0012036891554978479\n",
      "train loss:0.0006579486409495945\n",
      "train loss:0.00044912730862948694\n",
      "train loss:0.001372059087146197\n",
      "train loss:0.0002666611603142653\n",
      "train loss:9.455049247310068e-05\n",
      "train loss:0.0010891941283824747\n",
      "train loss:0.00018712612134211281\n",
      "train loss:0.0015669126075355335\n",
      "train loss:0.003485996208749959\n",
      "train loss:0.0010952337040967138\n",
      "train loss:0.0010113496760445733\n",
      "train loss:0.0004161370441797842\n",
      "train loss:0.0016084343051127187\n",
      "train loss:0.0033719730172477092\n",
      "train loss:0.0008749554551064483\n",
      "train loss:0.0007734860260435645\n",
      "train loss:0.0012033491842295138\n",
      "train loss:0.001764122545925176\n",
      "train loss:0.00013683685136648346\n",
      "train loss:0.0011810362996672124\n",
      "train loss:0.005968110534616963\n",
      "train loss:0.00027379777424434403\n",
      "train loss:6.093442644211392e-05\n",
      "train loss:0.0012165117941727488\n",
      "train loss:0.001178662575711224\n",
      "train loss:0.00038673800812306106\n",
      "train loss:0.0012981645493977934\n",
      "train loss:0.022976049427808252\n",
      "train loss:0.00053095828916772\n",
      "train loss:0.003245245871417198\n",
      "train loss:0.0002474135798606038\n",
      "train loss:0.002927171855322264\n",
      "train loss:0.0015420362957041483\n",
      "train loss:0.0055370531168467685\n",
      "train loss:0.0001981498905710513\n",
      "train loss:0.003541715355765493\n",
      "train loss:0.0007176664311621704\n",
      "train loss:0.0027779687591413093\n",
      "train loss:0.0016836152051966811\n",
      "train loss:0.0004428848547941277\n",
      "train loss:4.5011915712891324e-05\n",
      "train loss:0.0011911127892274447\n",
      "train loss:0.0018091347688512591\n",
      "train loss:0.00044108310474277255\n",
      "train loss:0.0007663780820864173\n",
      "train loss:0.0013134325470976526\n",
      "train loss:0.003294441237858835\n",
      "train loss:0.0020370721964171256\n",
      "train loss:0.002259417667738259\n",
      "train loss:0.006589471631993139\n",
      "train loss:0.00012970979354094052\n",
      "train loss:4.768384506545873e-05\n",
      "train loss:0.002239541562032285\n",
      "train loss:0.0030264849819475735\n",
      "train loss:0.0008904625050892239\n",
      "train loss:0.0005741160518197623\n",
      "train loss:0.0057045536153313035\n",
      "train loss:0.0024917952999134606\n",
      "train loss:0.0006316677328608683\n",
      "train loss:0.0027899803907305066\n",
      "train loss:0.006231369924407693\n",
      "train loss:0.0010520929939273648\n",
      "train loss:0.0016056665374942763\n",
      "train loss:0.001628509286595943\n",
      "train loss:0.0003137945529112083\n",
      "train loss:0.003731315916022071\n",
      "train loss:0.002917260685233302\n",
      "train loss:0.006365768691107805\n",
      "train loss:0.0001102805847801968\n",
      "=== epoch:18, train acc:0.999, test acc:0.99 ===\n",
      "train loss:0.0009448423082306933\n",
      "train loss:0.0002990265179000474\n",
      "train loss:0.0029922817843938553\n",
      "train loss:0.0003002908561596739\n",
      "train loss:0.0011350317220597671\n",
      "train loss:0.001383224747590543\n",
      "train loss:0.000522455932341705\n",
      "train loss:0.0016993645890261283\n",
      "train loss:0.0025417060215667943\n",
      "train loss:0.0009376932247275048\n",
      "train loss:0.0014085142919801697\n",
      "train loss:0.005185260834939366\n",
      "train loss:0.0016557186218856396\n",
      "train loss:0.0004543489355195049\n",
      "train loss:0.00035665983392532235\n",
      "train loss:0.004980917361536775\n",
      "train loss:0.0003850410134119946\n",
      "train loss:0.0008118892080075143\n",
      "train loss:0.0004343633479486982\n",
      "train loss:0.0024935742912333995\n",
      "train loss:0.006832741768314844\n",
      "train loss:0.0007017158453945049\n",
      "train loss:0.005655414087501651\n",
      "train loss:0.0004953094568723548\n",
      "train loss:0.001833011104927022\n",
      "train loss:0.0007240401235148434\n",
      "train loss:0.00025841743979705846\n",
      "train loss:0.0011183376826806187\n",
      "train loss:0.001957606261826028\n",
      "train loss:0.0035029293931024192\n",
      "train loss:0.004811301455460438\n",
      "train loss:0.0008489002654178759\n",
      "train loss:0.00028223085519102787\n",
      "train loss:0.0016130515264502787\n",
      "train loss:0.0010110548649481682\n",
      "train loss:0.00023243619886689605\n",
      "train loss:0.0015885843259417372\n",
      "train loss:0.006531725289824673\n",
      "train loss:0.0009897932510619747\n",
      "train loss:0.0009337176675987303\n",
      "train loss:0.0012507855364420472\n",
      "train loss:0.0011610669300492153\n",
      "train loss:0.00037506577084331903\n",
      "train loss:0.0009547182069482256\n",
      "train loss:0.00013548144955175686\n",
      "train loss:0.0017609691599491193\n",
      "train loss:9.939256322552367e-05\n",
      "train loss:0.0019245947562688207\n",
      "train loss:0.0006934140070578084\n",
      "train loss:4.00907163191357e-05\n",
      "train loss:0.000745448076005579\n",
      "train loss:0.0013733539869219297\n",
      "train loss:0.0010462612102630177\n",
      "train loss:0.0005263889408197799\n",
      "train loss:0.0018800415024597644\n",
      "train loss:0.0008985040745846547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00047868171836781684\n",
      "train loss:0.001859933709742271\n",
      "train loss:0.0036545177714277194\n",
      "train loss:0.0021726563856041296\n",
      "train loss:0.0006240544597920683\n",
      "train loss:0.0005461148036882729\n",
      "train loss:0.002452892827500128\n",
      "train loss:0.01550616274086989\n",
      "train loss:5.92794904137724e-05\n",
      "train loss:0.0005474592557331645\n",
      "train loss:0.0009461054220679028\n",
      "train loss:9.493042903294422e-05\n",
      "train loss:0.005193899914151915\n",
      "train loss:0.0005073263768953806\n",
      "train loss:0.024049576956612747\n",
      "train loss:0.015957761926631495\n",
      "train loss:0.00459810362696554\n",
      "train loss:0.0006407925873284158\n",
      "train loss:0.0030430399109226307\n",
      "train loss:0.0003769051461324786\n",
      "train loss:0.0006205711640711208\n",
      "train loss:0.004696233959565518\n",
      "train loss:0.0001582896406284048\n",
      "train loss:0.0029232630550860357\n",
      "train loss:0.0005195918718398843\n",
      "train loss:0.0011061140250643508\n",
      "train loss:0.002878729816023911\n",
      "train loss:5.9196347260344565e-05\n",
      "train loss:0.0009240588274008516\n",
      "train loss:0.005300129187006263\n",
      "train loss:0.002370172918940866\n",
      "train loss:0.002124445595227086\n",
      "train loss:0.0016898337111721242\n",
      "train loss:0.001840203647618151\n",
      "train loss:0.0018738587093034371\n",
      "train loss:0.006345431152310856\n",
      "train loss:0.008229162484868014\n",
      "train loss:0.00025047327121027995\n",
      "train loss:0.0001938988131530816\n",
      "train loss:0.0062282662405761\n",
      "train loss:0.0016666239460274843\n",
      "train loss:7.779996392891739e-05\n",
      "train loss:0.0014808863055680104\n",
      "train loss:0.0040267705193190615\n",
      "train loss:0.001193766035665427\n",
      "train loss:0.002435568761771208\n",
      "train loss:0.006160930562487729\n",
      "train loss:0.003997964921545264\n",
      "train loss:0.003256198898474988\n",
      "train loss:0.020778460993719203\n",
      "train loss:0.0028734406270906317\n",
      "train loss:0.001328894672720421\n",
      "train loss:0.0004480530189023138\n",
      "train loss:0.004846526549564339\n",
      "train loss:0.005980966243681856\n",
      "train loss:0.0005519329608381868\n",
      "train loss:0.003231947012946167\n",
      "train loss:0.0006134609936105164\n",
      "train loss:0.0014904999479942351\n",
      "train loss:0.000840238096373351\n",
      "train loss:0.000802117259258419\n",
      "train loss:0.001917091576947933\n",
      "train loss:0.004128440583400928\n",
      "train loss:0.0019252351407091596\n",
      "train loss:0.0011649211674302454\n",
      "train loss:0.0005240741436291096\n",
      "train loss:0.0013023372335173007\n",
      "train loss:0.0019762584728930848\n",
      "train loss:0.001402600031662404\n",
      "train loss:0.000423828887115456\n",
      "train loss:0.0013216019294036965\n",
      "train loss:0.00025312197197322915\n",
      "train loss:0.0024025788204212408\n",
      "train loss:0.004761190864646827\n",
      "train loss:0.0031093200351071425\n",
      "train loss:0.00011278714963693235\n",
      "train loss:2.966241341405115e-05\n",
      "train loss:0.00030901444090147855\n",
      "train loss:0.00020082853418810245\n",
      "train loss:0.0015310676188136196\n",
      "train loss:0.001169777336515968\n",
      "train loss:0.00054894634868922\n",
      "train loss:0.004729464058513588\n",
      "train loss:0.011648740239235827\n",
      "train loss:0.001851458509111519\n",
      "train loss:8.929425181561285e-05\n",
      "train loss:0.0004614356958262482\n",
      "train loss:0.00017051366544030674\n",
      "train loss:0.00018521511547121242\n",
      "train loss:0.0005279874417631072\n",
      "train loss:0.0015679640380046938\n",
      "train loss:0.0001844948050423173\n",
      "train loss:0.008776532387917875\n",
      "train loss:0.00027051038712826685\n",
      "train loss:0.0011528910193697145\n",
      "train loss:4.951615479020445e-06\n",
      "train loss:0.002079101522591183\n",
      "train loss:0.00010683611029060066\n",
      "train loss:0.001242223278457264\n",
      "train loss:0.0005402625181057732\n",
      "train loss:0.00012441250637084753\n",
      "train loss:0.0005590158454681345\n",
      "train loss:0.0006105623048134856\n",
      "train loss:0.0005674787520403269\n",
      "train loss:0.0003434503363553452\n",
      "train loss:0.0008824027242694391\n",
      "train loss:0.0188559309855948\n",
      "train loss:0.0002708754605097391\n",
      "train loss:0.0010186099247541248\n",
      "train loss:0.00029361087280099655\n",
      "train loss:0.0006064156568471748\n",
      "train loss:0.0002397205673624319\n",
      "train loss:0.0008212669144829729\n",
      "train loss:0.00036674093853261523\n",
      "train loss:0.0023624605937719546\n",
      "train loss:0.0030846694031533605\n",
      "train loss:0.00282484321248179\n",
      "train loss:0.001634767861356718\n",
      "train loss:0.001377420983705193\n",
      "train loss:0.002136763295354209\n",
      "train loss:0.0016822641717180896\n",
      "train loss:0.0010839961576373854\n",
      "train loss:0.0003011040297771308\n",
      "train loss:0.00032064464740096154\n",
      "train loss:0.001035505602520494\n",
      "train loss:0.00015208765561259736\n",
      "train loss:0.00012770783113682534\n",
      "train loss:0.0028087263343517994\n",
      "train loss:0.0028589384808472423\n",
      "train loss:0.0020729758119922112\n",
      "train loss:0.0007428098861393038\n",
      "train loss:6.710802494663706e-05\n",
      "train loss:0.00042082261160539323\n",
      "train loss:0.000936135412989073\n",
      "train loss:0.00048027893412285264\n",
      "train loss:0.018787734620554962\n",
      "train loss:0.0010325169328048577\n",
      "train loss:0.001431454837007034\n",
      "train loss:0.001862297804769594\n",
      "train loss:0.003313423571503804\n",
      "train loss:0.0004919414706778135\n",
      "train loss:0.0011500414525128294\n",
      "train loss:0.0004801517318567752\n",
      "train loss:0.0006665750794668322\n",
      "train loss:0.00038986060114623437\n",
      "train loss:0.002763132314471095\n",
      "train loss:0.0005842818720847244\n",
      "train loss:0.002345120477436206\n",
      "train loss:0.004781683198270823\n",
      "train loss:0.0006414727790039648\n",
      "train loss:0.012089180761736215\n",
      "train loss:0.0018816471103951541\n",
      "train loss:0.0019996953665318597\n",
      "train loss:0.001768610987402345\n",
      "train loss:0.005231536734754028\n",
      "train loss:0.0032687500596845598\n",
      "train loss:0.0012586022672164408\n",
      "train loss:8.836332014013754e-05\n",
      "train loss:0.0019408626930986453\n",
      "train loss:0.008074027473762261\n",
      "train loss:0.0007634801852178628\n",
      "train loss:0.0014748747176381901\n",
      "train loss:0.0004136849045900854\n",
      "train loss:0.0007002737435719883\n",
      "train loss:0.0001581756485205914\n",
      "train loss:0.0034866454830984757\n",
      "train loss:0.004447944382156977\n",
      "train loss:0.004144223867639489\n",
      "train loss:7.252178663911636e-05\n",
      "train loss:0.0038403575522545363\n",
      "train loss:0.001789874394644664\n",
      "train loss:0.00017717447703574182\n",
      "train loss:0.000810614241459015\n",
      "train loss:0.0028866439536457777\n",
      "train loss:0.0029051636458851822\n",
      "train loss:0.0017735557880581587\n",
      "train loss:0.0017558747030330458\n",
      "train loss:0.0022614355823290305\n",
      "train loss:0.0016341260421362427\n",
      "train loss:0.0017557309419158505\n",
      "train loss:0.010581166161866183\n",
      "train loss:0.0035231566103166596\n",
      "train loss:0.0003687046001496422\n",
      "train loss:0.000889612485063521\n",
      "train loss:0.0016238983746034677\n",
      "train loss:0.0024187362781497392\n",
      "train loss:0.0009175266559972278\n",
      "train loss:5.3195674005854257e-05\n",
      "train loss:0.004763520325686913\n",
      "train loss:8.84206691814433e-05\n",
      "train loss:0.00014024651840491376\n",
      "train loss:4.873239255250583e-05\n",
      "train loss:7.963393742896911e-05\n",
      "train loss:0.0018422460109422502\n",
      "train loss:0.000564319779844697\n",
      "train loss:0.00036021491569559577\n",
      "train loss:0.0005839449589190638\n",
      "train loss:0.021639662821752136\n",
      "train loss:0.0004487561674796108\n",
      "train loss:0.001072493888317609\n",
      "train loss:0.0005795946430129941\n",
      "train loss:0.001226805360146561\n",
      "train loss:0.0010714597072615107\n",
      "train loss:0.004661360080921821\n",
      "train loss:0.00011701405722500384\n",
      "train loss:0.0004052816144027929\n",
      "train loss:0.00037677332157509463\n",
      "train loss:0.008827300246468679\n",
      "train loss:0.0038893893372438037\n",
      "train loss:0.0002699923225640187\n",
      "train loss:0.002312502728342922\n",
      "train loss:0.00325485643611337\n",
      "train loss:0.0042694045541797725\n",
      "train loss:0.002918494070674793\n",
      "train loss:0.007412098415467424\n",
      "train loss:0.0002848508369597713\n",
      "train loss:0.0020507941012815637\n",
      "train loss:0.0026057771802111703\n",
      "train loss:0.0009209791259432278\n",
      "train loss:0.0010609563701209676\n",
      "train loss:0.0022090887922569333\n",
      "train loss:0.0007868629355492365\n",
      "train loss:0.0029037736516497764\n",
      "train loss:0.005932715958841123\n",
      "train loss:0.0009733104110031185\n",
      "train loss:0.0011202331682479394\n",
      "train loss:0.000655525867181435\n",
      "train loss:0.0023642628051073027\n",
      "train loss:0.00020278862235269173\n",
      "train loss:0.0016964648466526954\n",
      "train loss:0.0006469445394490525\n",
      "train loss:0.00021021401589035792\n",
      "train loss:0.003189258983999402\n",
      "train loss:0.0013371416844500802\n",
      "train loss:0.0033552228889637383\n",
      "train loss:0.004155034026852198\n",
      "train loss:0.0009545655996158229\n",
      "train loss:0.00028844887047312746\n",
      "train loss:0.004559176771574209\n",
      "train loss:0.00011922279633874411\n",
      "train loss:0.0026722677252201876\n",
      "train loss:0.0011281117510575874\n",
      "train loss:0.0010972264991813737\n",
      "train loss:0.003384655662204467\n",
      "train loss:0.0012112819295944214\n",
      "train loss:0.001387104555306975\n",
      "train loss:0.0005194536458717182\n",
      "train loss:0.0006283072037976387\n",
      "train loss:0.07081139068311795\n",
      "train loss:0.009035233405068064\n",
      "train loss:0.0007901352352439757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00048611910873186794\n",
      "train loss:0.0003942080538451395\n",
      "train loss:0.0002649667647878878\n",
      "train loss:0.00011846301768835476\n",
      "train loss:0.0014346315219322056\n",
      "train loss:0.0019094007011245832\n",
      "train loss:0.0006036573307157213\n",
      "train loss:0.0020479591843404984\n",
      "train loss:0.0038181048954375805\n",
      "train loss:0.0014020830977327535\n",
      "train loss:0.0012395140480140896\n",
      "train loss:0.0030113462324343056\n",
      "train loss:0.005853526401654614\n",
      "train loss:0.0005635361078932698\n",
      "train loss:0.013739350354505969\n",
      "train loss:0.0019353782724515875\n",
      "train loss:0.0015554942732877747\n",
      "train loss:0.0003183458641762146\n",
      "train loss:0.0021306451345019153\n",
      "train loss:0.0033984143219918566\n",
      "train loss:0.00013742089965012948\n",
      "train loss:0.0022300477312753937\n",
      "train loss:0.002821125650540391\n",
      "train loss:0.000550744065516132\n",
      "train loss:0.0031996868814358316\n",
      "train loss:0.0033035387064274885\n",
      "train loss:0.0012744876571255132\n",
      "train loss:0.0008122597449852127\n",
      "train loss:0.030304068032542725\n",
      "train loss:0.0005845721820031432\n",
      "train loss:0.007196470785391408\n",
      "train loss:0.0034157787156131715\n",
      "train loss:0.00021186394077979902\n",
      "train loss:0.00020906264757979134\n",
      "train loss:0.00023277757072202203\n",
      "train loss:4.41033441573279e-05\n",
      "train loss:7.401701649585266e-05\n",
      "train loss:0.0007503407566176161\n",
      "train loss:0.0006345104628086069\n",
      "train loss:0.00011690694853732762\n",
      "train loss:0.0007467530935787687\n",
      "train loss:0.0019596306217481516\n",
      "train loss:0.0006843629206476083\n",
      "train loss:0.0008298036487403615\n",
      "train loss:0.003908497230139076\n",
      "train loss:0.0009413601021776318\n",
      "train loss:8.111544771176935e-05\n",
      "train loss:0.00011216981001970266\n",
      "train loss:0.0005513300006661557\n",
      "train loss:0.0009803745755132042\n",
      "train loss:6.705471796484696e-05\n",
      "train loss:0.00153507808087844\n",
      "train loss:0.0003379417809208274\n",
      "train loss:0.0016335560081667294\n",
      "train loss:0.0003733902524283826\n",
      "train loss:0.0006668769385237197\n",
      "train loss:0.00019038769656327232\n",
      "train loss:0.004558913438105537\n",
      "train loss:0.0018241267381152962\n",
      "train loss:0.0008956255580026974\n",
      "train loss:0.0018101510584798653\n",
      "train loss:0.0013160396401276752\n",
      "train loss:0.0001877364209541906\n",
      "train loss:0.0007787455989770951\n",
      "train loss:0.00028165650038567574\n",
      "train loss:0.0009366717169497678\n",
      "train loss:0.00013638290086455732\n",
      "train loss:0.001776649795938332\n",
      "train loss:0.00037795594301212566\n",
      "train loss:0.00045054766934902963\n",
      "train loss:0.00012491095554848235\n",
      "train loss:0.0011701860265363954\n",
      "train loss:0.00017069905284860973\n",
      "train loss:0.0007632960356202782\n",
      "train loss:0.00083713316688003\n",
      "train loss:0.0054833548697449715\n",
      "train loss:0.0009279415039548712\n",
      "train loss:0.003889671477402902\n",
      "train loss:0.005325446469528542\n",
      "train loss:0.0017556028570657218\n",
      "train loss:0.0005473038055056135\n",
      "train loss:0.00042179179025646896\n",
      "train loss:0.001585520531556197\n",
      "train loss:0.0012595117938648912\n",
      "train loss:0.00017982324504999317\n",
      "train loss:0.0011358751614439567\n",
      "train loss:0.00036400939675923846\n",
      "train loss:0.0027014489537331658\n",
      "train loss:0.0017041459440244808\n",
      "train loss:0.00010096312126731684\n",
      "train loss:0.0002387806906045964\n",
      "train loss:0.004562396036027455\n",
      "train loss:0.0010474296164946903\n",
      "train loss:0.002156999222795708\n",
      "train loss:0.00018699390448182715\n",
      "train loss:0.0013265217802097965\n",
      "train loss:0.001755420224431041\n",
      "train loss:6.190442598694293e-05\n",
      "train loss:8.916774761776087e-05\n",
      "train loss:0.0004977427181839571\n",
      "train loss:0.0009210616133376958\n",
      "train loss:0.00021257331544767707\n",
      "train loss:0.008716025182886063\n",
      "train loss:9.798847156297255e-05\n",
      "train loss:0.0005275954037106826\n",
      "train loss:1.52903193936444e-05\n",
      "train loss:0.0018588482386808236\n",
      "train loss:0.0010048611345004667\n",
      "train loss:0.00017786738940625904\n",
      "train loss:0.00046213067421470815\n",
      "train loss:0.0007405911438292559\n",
      "train loss:0.00255230534540323\n",
      "train loss:5.2718719819766244e-05\n",
      "train loss:0.00046013453813070456\n",
      "train loss:0.00036308222731865547\n",
      "train loss:0.0005172532078530556\n",
      "train loss:0.002033376833093953\n",
      "train loss:0.0019441510435670565\n",
      "train loss:0.0002029089940406137\n",
      "train loss:0.00014287435819216771\n",
      "train loss:0.0005536219438116542\n",
      "train loss:2.8676898966295922e-05\n",
      "train loss:0.003644313934232897\n",
      "train loss:0.0002460708965444326\n",
      "train loss:0.0005097362872309638\n",
      "train loss:0.0005207299841012721\n",
      "train loss:0.003705972476959575\n",
      "train loss:0.0002448158201736503\n",
      "train loss:0.00544401701584907\n",
      "train loss:0.00016659095364893585\n",
      "train loss:0.0013045227544765214\n",
      "train loss:0.0009436638161888861\n",
      "train loss:0.0017032416798116049\n",
      "train loss:0.0004674381766072829\n",
      "train loss:0.00115063714343405\n",
      "train loss:0.0025000695807831396\n",
      "train loss:0.000788269407638204\n",
      "train loss:0.0028926565293484795\n",
      "train loss:0.029911044258307803\n",
      "train loss:0.004136949948590959\n",
      "train loss:0.00031800831466931095\n",
      "train loss:0.00011974878253367097\n",
      "train loss:0.0008312557025888221\n",
      "train loss:0.012927112633351123\n",
      "train loss:0.005565015295904865\n",
      "train loss:0.0005024474630879468\n",
      "train loss:0.002557135625071962\n",
      "train loss:0.0020547388290755274\n",
      "train loss:0.002470257385797649\n",
      "train loss:0.00041780393918084964\n",
      "train loss:0.0004830987913750349\n",
      "train loss:0.007870854196232586\n",
      "train loss:0.00042261224741267775\n",
      "train loss:0.0015862186002763069\n",
      "train loss:0.0009097377507199111\n",
      "train loss:0.0020942383570132974\n",
      "train loss:0.0012423330503343482\n",
      "train loss:0.0021636952694638768\n",
      "train loss:0.0006366970558832609\n",
      "train loss:0.0013104642256746696\n",
      "train loss:0.0014877508474521153\n",
      "train loss:0.00020677295072133044\n",
      "train loss:0.0007572372352073461\n",
      "train loss:0.001020589478428598\n",
      "train loss:0.01032169764399237\n",
      "train loss:0.001279569856659204\n",
      "train loss:0.005697996511477059\n",
      "train loss:0.00040814198760351963\n",
      "train loss:0.002791294321958085\n",
      "train loss:0.002300810751981143\n",
      "train loss:0.0028056777960433965\n",
      "train loss:0.0018308566678315419\n",
      "train loss:0.001602491330626158\n",
      "train loss:0.0002746270945378783\n",
      "train loss:0.0003525554566720978\n",
      "train loss:0.007106964788322923\n",
      "train loss:0.026231682100646015\n",
      "train loss:0.009876428075211233\n",
      "train loss:0.0022177063257294983\n",
      "train loss:0.002307494412857115\n",
      "train loss:0.00019771398236717705\n",
      "train loss:0.0004486010024835295\n",
      "train loss:0.0004908496948949655\n",
      "train loss:0.0005789095847881842\n",
      "train loss:0.00013474003700070648\n",
      "train loss:0.0003378755529637887\n",
      "train loss:0.025222385079839378\n",
      "train loss:0.002420919901034026\n",
      "train loss:0.00413418286832874\n",
      "train loss:0.006938131147035905\n",
      "train loss:0.00023630254867634156\n",
      "train loss:0.00042461822704122564\n",
      "train loss:0.0002542445997911945\n",
      "train loss:0.0009677943851379932\n",
      "train loss:0.0021893528723014094\n",
      "train loss:0.000199307835417791\n",
      "train loss:0.0009682674716538458\n",
      "train loss:0.00027708517402473206\n",
      "train loss:0.0025740555147645418\n",
      "train loss:0.0008442330890134936\n",
      "train loss:0.00020122879939324465\n",
      "train loss:0.0023371391657509063\n",
      "train loss:0.0004689144408209218\n",
      "train loss:0.0005408095024286169\n",
      "train loss:0.001360900946305123\n",
      "train loss:0.0007531630539207385\n",
      "train loss:0.0006428157416827166\n",
      "train loss:0.000237824619145887\n",
      "train loss:0.0012806004612307997\n",
      "train loss:0.001091593112301468\n",
      "train loss:0.001381082538544339\n",
      "train loss:0.0016817914733766356\n",
      "train loss:0.0008187945821192158\n",
      "train loss:0.0033109724743453895\n",
      "train loss:0.0005084722795358342\n",
      "train loss:0.0012637644218758952\n",
      "train loss:0.0034329446369369666\n",
      "train loss:0.0020234210865240215\n",
      "train loss:0.005562024104597364\n",
      "train loss:0.00130743067547054\n",
      "train loss:8.80135590827356e-05\n",
      "train loss:0.0007182141466170635\n",
      "train loss:0.00010145157552184766\n",
      "train loss:0.0019081337245918316\n",
      "train loss:0.00038819185523910574\n",
      "train loss:0.0011667578486578099\n",
      "train loss:0.004080590401893918\n",
      "train loss:0.004648961408640353\n",
      "train loss:0.0008742076151133713\n",
      "train loss:0.000543415980392652\n",
      "train loss:0.0013494794358304217\n",
      "train loss:0.0014898279946815066\n",
      "train loss:0.0035126621565651933\n",
      "train loss:0.001512694644934669\n",
      "train loss:0.005240542935549983\n",
      "train loss:0.000727686864693893\n",
      "train loss:0.0009963496170029653\n",
      "train loss:0.0015642974087683786\n",
      "train loss:0.001409993727988752\n",
      "train loss:0.0007947147075199542\n",
      "train loss:0.0002076738581560665\n",
      "train loss:0.0003319743682205999\n",
      "train loss:0.0007915313767362555\n",
      "train loss:0.0001381579518480965\n",
      "train loss:0.002398931935845232\n",
      "train loss:0.0003252137802476074\n",
      "train loss:0.00036886504540000284\n",
      "train loss:0.0006975200674771845\n",
      "train loss:0.0015071209898179783\n",
      "train loss:0.0026139476760435455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0025765776984602723\n",
      "train loss:0.0010261897728404132\n",
      "train loss:0.00025663047605998526\n",
      "train loss:0.0015611456071367234\n",
      "train loss:0.000234039361775463\n",
      "train loss:0.0007343923963475678\n",
      "train loss:0.001957952608443154\n",
      "train loss:0.0012067652881543232\n",
      "train loss:1.4807036778982494e-05\n",
      "train loss:0.0019643770798021777\n",
      "train loss:0.0021040720634169082\n",
      "train loss:0.00017989282583097532\n",
      "train loss:0.028409976931267285\n",
      "train loss:0.0010258340047068402\n",
      "train loss:0.0024253652431181954\n",
      "train loss:0.004317348835917032\n",
      "train loss:0.0012162618021455184\n",
      "train loss:2.4614158584294007e-05\n",
      "train loss:0.00032650785702079685\n",
      "train loss:0.00012286283847403093\n",
      "train loss:0.00013004960997584482\n",
      "train loss:0.00015318177155211718\n",
      "train loss:0.00027803600565098766\n",
      "train loss:0.00036222184990905635\n",
      "train loss:0.0005483763055203867\n",
      "train loss:0.0032014050200543727\n",
      "train loss:0.0002971218685455645\n",
      "train loss:0.000127897127471653\n",
      "train loss:0.0027084798744264195\n",
      "train loss:0.0011881404205748472\n",
      "train loss:0.001090448535631437\n",
      "train loss:0.0018047299202605634\n",
      "train loss:0.004223572664884191\n",
      "train loss:0.0005026765494388188\n",
      "train loss:0.00035037403058708547\n",
      "train loss:0.0010352871089091566\n",
      "train loss:0.0016322089713211633\n",
      "train loss:0.003929322974206123\n",
      "train loss:0.000684002597922867\n",
      "train loss:0.00022433145679120494\n",
      "train loss:0.00023921251684516442\n",
      "train loss:0.0013275891819571847\n",
      "train loss:0.0020575520372146726\n",
      "=== epoch:19, train acc:0.999, test acc:0.991 ===\n",
      "train loss:0.0001116326331121797\n",
      "train loss:0.0010652497525599001\n",
      "train loss:3.119562900321188e-05\n",
      "train loss:0.0004816306310639819\n",
      "train loss:0.0011290136801363117\n",
      "train loss:8.975846088192425e-05\n",
      "train loss:6.335000955476882e-05\n",
      "train loss:0.005418197719326546\n",
      "train loss:0.002540698621956779\n",
      "train loss:0.0009623068010477674\n",
      "train loss:9.122058044334982e-05\n",
      "train loss:0.0008515752046514354\n",
      "train loss:0.0002454700119322852\n",
      "train loss:0.0004524239917898711\n",
      "train loss:0.0001342437009189856\n",
      "train loss:0.0023362115655951674\n",
      "train loss:0.0004936429145757056\n",
      "train loss:0.00023191421916629097\n",
      "train loss:9.96873997607035e-05\n",
      "train loss:0.004758009676395192\n",
      "train loss:0.002021022784895203\n",
      "train loss:0.0003052782194364905\n",
      "train loss:0.0034584506647432896\n",
      "train loss:0.0002898344705638439\n",
      "train loss:0.0004292341159617764\n",
      "train loss:6.203729635438251e-05\n",
      "train loss:0.00028110048160720475\n",
      "train loss:0.0027354182625084233\n",
      "train loss:0.0036817589243988485\n",
      "train loss:0.0014241002460843204\n",
      "train loss:0.00011764494742852336\n",
      "train loss:0.013875906254638184\n",
      "train loss:0.0004741922044993778\n",
      "train loss:0.00021641388295881155\n",
      "train loss:0.00711264932252819\n",
      "train loss:0.00464881623669493\n",
      "train loss:0.00019579694352689944\n",
      "train loss:0.006027161720678386\n",
      "train loss:0.0024138690685004027\n",
      "train loss:0.0011785741210745427\n",
      "train loss:0.002944309531717335\n",
      "train loss:0.0003119211431326186\n",
      "train loss:0.0026089045736403613\n",
      "train loss:0.00016212392911919938\n",
      "train loss:0.0001125896149971457\n",
      "train loss:0.002762206029662662\n",
      "train loss:3.538439023612905e-05\n",
      "train loss:0.003624700203654657\n",
      "train loss:0.0002285250620074223\n",
      "train loss:0.0002269582126687903\n",
      "train loss:6.735305899526763e-05\n",
      "train loss:0.004988513503149648\n",
      "train loss:0.0005844601841645449\n",
      "train loss:0.0015121468225323975\n",
      "train loss:0.00010779779472670584\n",
      "train loss:0.0006461119876345681\n",
      "train loss:0.0016618492672679714\n",
      "train loss:0.0022944679843873907\n",
      "train loss:0.0013897915044921833\n",
      "train loss:0.0015778785018666444\n",
      "train loss:0.0007031000020419995\n",
      "train loss:0.0004892568472896656\n",
      "train loss:0.002361529547247831\n",
      "train loss:0.0011019963806280777\n",
      "train loss:0.0019307473773162323\n",
      "train loss:0.012242119853763538\n",
      "train loss:0.0022365590013354187\n",
      "train loss:0.0014709429287497377\n",
      "train loss:0.0005324950449329232\n",
      "train loss:0.0015790411661645667\n",
      "train loss:8.51722856556797e-05\n",
      "train loss:0.00047778548853857114\n",
      "train loss:0.00013256275893703997\n",
      "train loss:0.003306985900503161\n",
      "train loss:0.0002513740217639667\n",
      "train loss:0.00014021389909193302\n",
      "train loss:0.0016074285690937196\n",
      "train loss:0.006842776694440195\n",
      "train loss:0.00016357777210602423\n",
      "train loss:0.0005831085673009721\n",
      "train loss:0.005349061588536526\n",
      "train loss:0.00030064154675691685\n",
      "train loss:0.00030318125718941416\n",
      "train loss:0.00032229763044646975\n",
      "train loss:0.001684931841940408\n",
      "train loss:0.00017236571317669438\n",
      "train loss:0.002108719114817477\n",
      "train loss:0.00042946316572924163\n",
      "train loss:7.28272539075356e-05\n",
      "train loss:0.0011653416904672074\n",
      "train loss:0.0023179818824864765\n",
      "train loss:8.352854513727862e-05\n",
      "train loss:0.002233533886217873\n",
      "train loss:0.004344630961987231\n",
      "train loss:0.0021096059051381403\n",
      "train loss:0.0006963992510340564\n",
      "train loss:0.0018211604348269891\n",
      "train loss:0.0012611706118663758\n",
      "train loss:0.001661111093122684\n",
      "train loss:0.004304005028085731\n",
      "train loss:0.00012705761634798152\n",
      "train loss:0.0008738020459175592\n",
      "train loss:0.000694581889484615\n",
      "train loss:0.00018511074981107818\n",
      "train loss:0.0006842758262845769\n",
      "train loss:8.278956394754716e-05\n",
      "train loss:0.0003552188810871324\n",
      "train loss:0.005046604389727339\n",
      "train loss:0.0009202906810184129\n",
      "train loss:0.0005549555112899542\n",
      "train loss:0.0006604144900859268\n",
      "train loss:0.0004664969809560929\n",
      "train loss:0.000561754070282227\n",
      "train loss:0.00015223141459609044\n",
      "train loss:0.0001580373667037434\n",
      "train loss:0.00105844863231567\n",
      "train loss:0.000449744392322725\n",
      "train loss:0.0007736805381381506\n",
      "train loss:0.0016012974576571713\n",
      "train loss:0.0004020762683804735\n",
      "train loss:2.3230085544623976e-05\n",
      "train loss:0.00021712325628851583\n",
      "train loss:0.0006679699393980702\n",
      "train loss:0.001254976042350453\n",
      "train loss:0.00030581364964001756\n",
      "train loss:0.00029513432630880643\n",
      "train loss:0.0024687398195518233\n",
      "train loss:0.0001924033957622979\n",
      "train loss:0.00011910734549425244\n",
      "train loss:0.0001438864078790372\n",
      "train loss:0.0013015674123189871\n",
      "train loss:0.001024035128698884\n",
      "train loss:0.0008084046830137849\n",
      "train loss:0.001148524700680347\n",
      "train loss:0.00028431509287172105\n",
      "train loss:2.1989349785477468e-05\n",
      "train loss:0.0002697289357685435\n",
      "train loss:0.0007333319967047224\n",
      "train loss:0.00011605234167128165\n",
      "train loss:0.004692667235927232\n",
      "train loss:0.00045915000427789945\n",
      "train loss:0.0012220262461074684\n",
      "train loss:7.365751755754852e-05\n",
      "train loss:0.00031950643160278\n",
      "train loss:0.0006622806297580711\n",
      "train loss:0.00293259511479853\n",
      "train loss:0.0004381017891623648\n",
      "train loss:0.0008774515278109747\n",
      "train loss:0.00016850959180319018\n",
      "train loss:0.0005637538875597606\n",
      "train loss:0.0005426977530306516\n",
      "train loss:0.002239218825355461\n",
      "train loss:0.0003288836344476393\n",
      "train loss:0.018720173234803895\n",
      "train loss:0.0006544907685630232\n",
      "train loss:5.70998994848914e-05\n",
      "train loss:0.00038035473216132534\n",
      "train loss:0.0005226816732593353\n",
      "train loss:7.494597192616751e-05\n",
      "train loss:0.0035921548274076647\n",
      "train loss:0.0007818493832896224\n",
      "train loss:0.006069790394468378\n",
      "train loss:6.787765469744479e-05\n",
      "train loss:0.000127785457986979\n",
      "train loss:0.0014151536979805223\n",
      "train loss:0.001049613034259126\n",
      "train loss:0.0005911437635937248\n",
      "train loss:0.008333494847192917\n",
      "train loss:0.001858177702674461\n",
      "train loss:0.0004037171250266476\n",
      "train loss:0.000246610738243346\n",
      "train loss:0.0016256159741466008\n",
      "train loss:0.0009619744883470818\n",
      "train loss:0.0010908648348929633\n",
      "train loss:0.00014022832563191032\n",
      "train loss:0.0009250040609468375\n",
      "train loss:4.626690592994615e-05\n",
      "train loss:0.0011761225920413848\n",
      "train loss:0.001191401120272538\n",
      "train loss:0.005404917935050237\n",
      "train loss:0.0012926314530549692\n",
      "train loss:0.00014658183934095786\n",
      "train loss:0.0006989122288574266\n",
      "train loss:0.0006468780351879136\n",
      "train loss:0.00013994891833594338\n",
      "train loss:0.0036008633594224616\n",
      "train loss:5.577304583427364e-05\n",
      "train loss:0.0014373497987567345\n",
      "train loss:0.0002462290946972341\n",
      "train loss:0.0004557347128714814\n",
      "train loss:0.0006785562639272411\n",
      "train loss:0.006490385838628439\n",
      "train loss:0.0007422088056010617\n",
      "train loss:0.00033755919062905765\n",
      "train loss:0.0029731892748461304\n",
      "train loss:0.0031844411568328125\n",
      "train loss:0.0003801672381564568\n",
      "train loss:0.0047226933509742375\n",
      "train loss:0.0008361074991148186\n",
      "train loss:0.00011486283857327751\n",
      "train loss:0.001564230038194534\n",
      "train loss:0.001533000050177815\n",
      "train loss:0.0005775172730451314\n",
      "train loss:0.00541405547461754\n",
      "train loss:5.2705542745644696e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0018804742689260958\n",
      "train loss:0.00020211774584849888\n",
      "train loss:0.00011929117512214909\n",
      "train loss:0.0009793250963828928\n",
      "train loss:0.0015699901926085416\n",
      "train loss:0.0004831974956814644\n",
      "train loss:0.00025266780757335556\n",
      "train loss:0.00018136903687420252\n",
      "train loss:0.0020170992156708007\n",
      "train loss:0.003945234949965569\n",
      "train loss:0.0014091489054537376\n",
      "train loss:0.00035689530923891955\n",
      "train loss:0.0003083122943436751\n",
      "train loss:0.0006951239547617323\n",
      "train loss:0.002118983445682396\n",
      "train loss:0.0022997537778680303\n",
      "train loss:0.00047991098281592945\n",
      "train loss:0.0003034723299946239\n",
      "train loss:0.003538500817124953\n",
      "train loss:0.0002397260581865399\n",
      "train loss:0.004401533387797745\n",
      "train loss:0.00025569635093094145\n",
      "train loss:0.0009667058498875288\n",
      "train loss:0.00017286541425344428\n",
      "train loss:0.0052467374919140134\n",
      "train loss:0.0019159976143621907\n",
      "train loss:0.0013693548550730184\n",
      "train loss:5.060269188636422e-05\n",
      "train loss:0.00199355795849696\n",
      "train loss:0.0005368257730388906\n",
      "train loss:0.0007194394728351249\n",
      "train loss:0.0005502078992369481\n",
      "train loss:0.004764174855378937\n",
      "train loss:4.372723525229973e-05\n",
      "train loss:9.817707822929968e-05\n",
      "train loss:0.0008465256957411579\n",
      "train loss:0.00019240437264047796\n",
      "train loss:0.006085788888745829\n",
      "train loss:0.0005934026993918519\n",
      "train loss:0.0012034785495792634\n",
      "train loss:0.0006586770011159332\n",
      "train loss:0.00012342962004289513\n",
      "train loss:0.00021754909018010252\n",
      "train loss:0.0015447480411068901\n",
      "train loss:0.001730961387400409\n",
      "train loss:0.0006879893942518217\n",
      "train loss:0.010077060364722737\n",
      "train loss:0.0012363587787806141\n",
      "train loss:0.0007986521042337294\n",
      "train loss:0.0021494329135004907\n",
      "train loss:0.0018811825493334896\n",
      "train loss:0.001303189134760682\n",
      "train loss:0.0011591076093144968\n",
      "train loss:0.0004345443229556186\n",
      "train loss:0.00018067342692918779\n",
      "train loss:9.80963110862923e-05\n",
      "train loss:0.0012419910987044168\n",
      "train loss:0.001438208118992235\n",
      "train loss:0.0017698133106256188\n",
      "train loss:0.0005853345581002793\n",
      "train loss:0.00024170102750126112\n",
      "train loss:0.0023270991320237175\n",
      "train loss:0.002496411689231481\n",
      "train loss:0.0003043541662391045\n",
      "train loss:0.0014084451170697536\n",
      "train loss:0.0010892612290987684\n",
      "train loss:0.0026212189641290806\n",
      "train loss:0.004276637027153305\n",
      "train loss:0.0005013073213977633\n",
      "train loss:0.00016964620609274418\n",
      "train loss:0.001551864075399521\n",
      "train loss:0.0008222786315410072\n",
      "train loss:0.000772766419405495\n",
      "train loss:0.00020822889241645947\n",
      "train loss:0.0006225692358017758\n",
      "train loss:0.0015321030088492299\n",
      "train loss:0.0007172958450936185\n",
      "train loss:0.0008288148775053514\n",
      "train loss:0.0016973388988827652\n",
      "train loss:0.0017197935471787195\n",
      "train loss:0.004718598904900464\n",
      "train loss:0.007929749870167709\n",
      "train loss:0.0018584876209085163\n",
      "train loss:0.0004929481090388736\n",
      "train loss:0.0056846487589201685\n",
      "train loss:0.0025582139029020064\n",
      "train loss:0.00011138734896376603\n",
      "train loss:0.0005927104471546166\n",
      "train loss:0.023168018190330625\n",
      "train loss:0.0017403910953188173\n",
      "train loss:0.0017096641795570234\n",
      "train loss:0.004183493217003328\n",
      "train loss:0.0009764113573179693\n",
      "train loss:0.000881607474290982\n",
      "train loss:0.0016745654489320721\n",
      "train loss:0.001959374865788923\n",
      "train loss:0.002527939550830145\n",
      "train loss:0.0010339016648282708\n",
      "train loss:0.0007715604345728043\n",
      "train loss:0.001706683314008071\n",
      "train loss:0.0009059203413538895\n",
      "train loss:0.007165061542208258\n",
      "train loss:0.00038135163254359334\n",
      "train loss:0.003313573021815805\n",
      "train loss:0.0014216123830410373\n",
      "train loss:0.021261303372370966\n",
      "train loss:5.8713703387551124e-05\n",
      "train loss:0.003012894129838309\n",
      "train loss:0.0007369986917344669\n",
      "train loss:0.00014528671925190365\n",
      "train loss:0.005563956474404974\n",
      "train loss:9.415027953879489e-05\n",
      "train loss:0.002382214403435802\n",
      "train loss:0.0012393124245902096\n",
      "train loss:0.0029162136135447163\n",
      "train loss:0.002934053105722682\n",
      "train loss:0.004626654899413333\n",
      "train loss:0.0004947411357544902\n",
      "train loss:0.00344174124285303\n",
      "train loss:0.0008134341190140317\n",
      "train loss:0.006073645195788723\n",
      "train loss:0.0002424527706637972\n",
      "train loss:0.00043122413536897234\n",
      "train loss:0.0004076203834924546\n",
      "train loss:0.0003764786070110273\n",
      "train loss:0.002508516376660719\n",
      "train loss:0.0008847884417669327\n",
      "train loss:0.004889512221884697\n",
      "train loss:0.0034201005119255247\n",
      "train loss:0.0037031518554614083\n",
      "train loss:0.0002670772923959931\n",
      "train loss:0.0020086813165216162\n",
      "train loss:0.0005231530437242464\n",
      "train loss:0.0020758142903341127\n",
      "train loss:0.002991715435333917\n",
      "train loss:0.00669153425837287\n",
      "train loss:0.007688146797087066\n",
      "train loss:0.0019424388124177892\n",
      "train loss:0.0012485349166741619\n",
      "train loss:0.0007720357742354488\n",
      "train loss:0.001349800174160332\n",
      "train loss:0.0014188000712350001\n",
      "train loss:0.0017912653929457675\n",
      "train loss:0.003216873759633397\n",
      "train loss:0.0003945283266417069\n",
      "train loss:0.006558413236705272\n",
      "train loss:0.0017583945072438443\n",
      "train loss:0.0003420276006593399\n",
      "train loss:0.0003682222151092887\n",
      "train loss:0.0007811140880164567\n",
      "train loss:0.0036985972468269635\n",
      "train loss:0.0020874868349802455\n",
      "train loss:0.00029571437573328556\n",
      "train loss:0.0004992891269151527\n",
      "train loss:0.0007047962883561546\n",
      "train loss:0.0007268452809139832\n",
      "train loss:0.0021253220419139517\n",
      "train loss:0.0017711783283690318\n",
      "train loss:0.0014024682476173305\n",
      "train loss:0.005377659054853766\n",
      "train loss:0.0004402377557030451\n",
      "train loss:0.001877349686044526\n",
      "train loss:0.0008614864221915916\n",
      "train loss:0.0004354307739616532\n",
      "train loss:0.0008221238767629875\n",
      "train loss:7.994821197487034e-05\n",
      "train loss:0.0005794186849231989\n",
      "train loss:0.00044251705887100867\n",
      "train loss:0.00025460332277821204\n",
      "train loss:0.0016467409282923304\n",
      "train loss:0.0010381117421734121\n",
      "train loss:0.0003569215122832713\n",
      "train loss:0.0006730500763029266\n",
      "train loss:7.211955728835556e-05\n",
      "train loss:0.006005509862608668\n",
      "train loss:3.98901932903331e-05\n",
      "train loss:2.8282515024779454e-05\n",
      "train loss:0.0003115683456559554\n",
      "train loss:0.0005445295455835828\n",
      "train loss:0.0015324747414483591\n",
      "train loss:0.0005144112647001648\n",
      "train loss:0.00014871123933577743\n",
      "train loss:0.001923011403340973\n",
      "train loss:0.008995008399249932\n",
      "train loss:0.00809921491539791\n",
      "train loss:0.0014563178024624985\n",
      "train loss:0.0002477580373199072\n",
      "train loss:0.00022341220073030391\n",
      "train loss:7.958334832365826e-05\n",
      "train loss:0.0010566288367152093\n",
      "train loss:2.7444766051499446e-05\n",
      "train loss:0.002275249712926843\n",
      "train loss:0.002498962084854146\n",
      "train loss:0.0031005874558308532\n",
      "train loss:0.0001803289447681094\n",
      "train loss:0.000581336937595173\n",
      "train loss:0.0008108389801502636\n",
      "train loss:0.0035053573320458307\n",
      "train loss:0.0017341147353827824\n",
      "train loss:0.000194783564189682\n",
      "train loss:0.0015433948896001368\n",
      "train loss:0.00046794695830982246\n",
      "train loss:0.00013875354025306551\n",
      "train loss:0.000917543300305336\n",
      "train loss:0.0017819062579891706\n",
      "train loss:0.00028167019338604316\n",
      "train loss:0.00036707651100420844\n",
      "train loss:0.0013781996424377695\n",
      "train loss:0.0018948535769539782\n",
      "train loss:0.00789023918532374\n",
      "train loss:0.000933248762277273\n",
      "train loss:0.0014207781708973433\n",
      "train loss:0.0015231291256655227\n",
      "train loss:0.00046942413211500743\n",
      "train loss:0.0006107697624411258\n",
      "train loss:0.0013907350031724624\n",
      "train loss:0.00032879819493071056\n",
      "train loss:0.0009680409996940723\n",
      "train loss:0.002007503342571624\n",
      "train loss:0.000801167221848898\n",
      "train loss:0.000216310015221889\n",
      "train loss:0.0012927121257239724\n",
      "train loss:0.000376954928377667\n",
      "train loss:0.0002227561860382207\n",
      "train loss:5.090372175071737e-05\n",
      "train loss:0.0027258882573277456\n",
      "train loss:0.0004067350703785091\n",
      "train loss:0.0029747369134630274\n",
      "train loss:0.002089488385864681\n",
      "train loss:0.0016053427561133155\n",
      "train loss:0.0006637026062792526\n",
      "train loss:9.295616332825371e-05\n",
      "train loss:0.0011154734318419431\n",
      "train loss:7.90272490841458e-05\n",
      "train loss:0.001260669009470507\n",
      "train loss:0.005859066941574013\n",
      "train loss:0.001673364106358876\n",
      "train loss:0.0006551274327514352\n",
      "train loss:0.000516949345431712\n",
      "train loss:0.002167632506199414\n",
      "train loss:0.00017653796080795652\n",
      "train loss:0.00019528440264529102\n",
      "train loss:0.0005264584335319946\n",
      "train loss:0.00033696267542483754\n",
      "train loss:0.0004558630471672434\n",
      "train loss:0.001245978364686223\n",
      "train loss:0.00037416991872908596\n",
      "train loss:0.0006310474269328787\n",
      "train loss:0.001182565633954197\n",
      "train loss:0.0007076367128962187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0009317001863832329\n",
      "train loss:0.0016919260476507818\n",
      "train loss:0.0019178996694449654\n",
      "train loss:0.00017844322722618147\n",
      "train loss:0.0013206771044505074\n",
      "train loss:0.000351415247230051\n",
      "train loss:0.0045900209580971825\n",
      "train loss:0.001555628347633832\n",
      "train loss:0.0006693949910567278\n",
      "train loss:0.0014033127559871428\n",
      "train loss:0.0007208079648723516\n",
      "train loss:0.0006057041213324531\n",
      "train loss:6.766335572368423e-05\n",
      "train loss:0.000588916087994106\n",
      "train loss:0.0007852281390420794\n",
      "train loss:0.001302017089474552\n",
      "train loss:0.0013917176490442851\n",
      "train loss:0.0020691004236749813\n",
      "train loss:0.00011952995855160463\n",
      "train loss:0.0003205489406048721\n",
      "train loss:0.0002965853930100276\n",
      "train loss:0.00031632654051220034\n",
      "train loss:0.00020101262673527292\n",
      "train loss:0.0003277605543898553\n",
      "train loss:0.0425560965605934\n",
      "train loss:0.0016901120864716986\n",
      "train loss:0.002430177298399798\n",
      "train loss:0.0012436054246479607\n",
      "train loss:0.0016884679888767118\n",
      "train loss:0.00023132901599091517\n",
      "train loss:0.000129602399196665\n",
      "train loss:0.0009255306179467269\n",
      "train loss:0.00028320859716071537\n",
      "train loss:0.00040916642754417067\n",
      "train loss:0.0016610371913222174\n",
      "train loss:0.001325353392319807\n",
      "train loss:0.0001114658136659887\n",
      "train loss:0.00018337490308454986\n",
      "train loss:0.00017646422144898037\n",
      "train loss:0.00021108442818155548\n",
      "train loss:0.00014310302769016318\n",
      "train loss:0.0011420018451962805\n",
      "train loss:0.0010302126507814246\n",
      "train loss:0.0004105856143629809\n",
      "train loss:0.0008193582741635527\n",
      "train loss:7.97596499362284e-05\n",
      "train loss:6.670653401102318e-05\n",
      "train loss:0.004115098407530315\n",
      "train loss:0.0005285373795157204\n",
      "train loss:0.0008302996459817364\n",
      "train loss:0.0021109772616882626\n",
      "train loss:0.002588309140716079\n",
      "train loss:0.00018638702092970726\n",
      "train loss:0.000992125972048504\n",
      "train loss:0.00029921251152454064\n",
      "train loss:0.0007386829474442799\n",
      "train loss:0.0017953920975832904\n",
      "train loss:4.5652552104381414e-05\n",
      "train loss:0.002488141561356006\n",
      "train loss:2.52706987717917e-05\n",
      "train loss:0.0015304333665948308\n",
      "train loss:0.002139805113619152\n",
      "train loss:0.00011344854056586012\n",
      "train loss:0.0033579682859656694\n",
      "train loss:0.00016929239207129874\n",
      "train loss:0.00019830454367232003\n",
      "train loss:0.001799929887510776\n",
      "train loss:0.0028686350051862564\n",
      "train loss:0.001314823030996266\n",
      "train loss:0.000630723455571097\n",
      "train loss:0.0011018600643484206\n",
      "train loss:0.0026396186964697437\n",
      "train loss:0.00010239425486052253\n",
      "train loss:0.00019119678467535706\n",
      "train loss:0.015492723142357074\n",
      "train loss:0.0029844660152907\n",
      "train loss:5.631803459144743e-05\n",
      "train loss:7.538036910478505e-05\n",
      "train loss:0.001930069601590532\n",
      "train loss:0.0005965761280253015\n",
      "train loss:4.003468692657241e-05\n",
      "train loss:0.003484054656826446\n",
      "train loss:7.555467741643871e-05\n",
      "train loss:0.000572167816178772\n",
      "train loss:0.009000003184916281\n",
      "train loss:0.0012451000774397869\n",
      "train loss:0.0034122853627897055\n",
      "train loss:0.0016832004686906158\n",
      "train loss:0.00046130245359491556\n",
      "train loss:0.0014201321428397799\n",
      "train loss:0.0017495926513634479\n",
      "train loss:0.00044836099861908507\n",
      "train loss:8.590815803186287e-05\n",
      "train loss:0.00042324629320814424\n",
      "train loss:0.0063077100947853525\n",
      "train loss:0.003346908097019969\n",
      "train loss:0.00048348999493251873\n",
      "train loss:0.00022327449824691384\n",
      "train loss:0.0025122318826798235\n",
      "train loss:0.00048276651519396906\n",
      "train loss:0.00486464655952253\n",
      "train loss:0.00046945483671857383\n",
      "train loss:0.00018251627309899643\n",
      "train loss:0.001407585763240986\n",
      "train loss:0.001769152240059395\n",
      "train loss:0.01478534816173386\n",
      "train loss:0.000997538969780102\n",
      "train loss:0.0014704482618483102\n",
      "train loss:1.384411679355064e-05\n",
      "train loss:0.0005666964263227715\n",
      "train loss:0.00021569234663991265\n",
      "train loss:0.0038722295172517068\n",
      "train loss:0.0018577983441581164\n",
      "train loss:0.001040259307136912\n",
      "train loss:0.0007309194296594027\n",
      "train loss:0.0002346796552290587\n",
      "train loss:0.0012495594995406466\n",
      "train loss:0.0012769833178740927\n",
      "train loss:0.00027871091555294915\n",
      "train loss:0.00012816761158430468\n",
      "train loss:0.0013797224189799173\n",
      "train loss:0.0020008171133453962\n",
      "train loss:0.00027814249288310363\n",
      "train loss:0.0003302831628047964\n",
      "train loss:0.00442641540842239\n",
      "train loss:0.00034583356815131525\n",
      "train loss:0.008437169738713446\n",
      "train loss:0.00012412336147347392\n",
      "train loss:5.3539934645485596e-05\n",
      "train loss:0.0032716214302016986\n",
      "train loss:0.016731688188682772\n",
      "train loss:0.000245567294425916\n",
      "train loss:0.0010293311998364307\n",
      "train loss:0.0016271799283439172\n",
      "train loss:0.0027242286310123222\n",
      "train loss:0.00024233778507673075\n",
      "train loss:0.0009476134725194372\n",
      "train loss:0.0007226208279367084\n",
      "train loss:0.0063879808302086585\n",
      "train loss:0.0005108159526360894\n",
      "train loss:0.0004149341155349811\n",
      "train loss:0.0034573720801784964\n",
      "train loss:0.0004698218905923585\n",
      "train loss:0.000804528604143152\n",
      "train loss:0.0015576595249074347\n",
      "=== epoch:20, train acc:0.997, test acc:0.987 ===\n",
      "train loss:0.002535826074388619\n",
      "train loss:0.001045663355502891\n",
      "train loss:0.00039796650692877774\n",
      "train loss:0.001080628562707299\n",
      "train loss:0.0006535768754648598\n",
      "train loss:0.0017325873468670957\n",
      "train loss:0.00714243265066682\n",
      "train loss:0.0030583667531139096\n",
      "train loss:0.00032311527022186605\n",
      "train loss:0.00023880652902441015\n",
      "train loss:0.0007514645659983263\n",
      "train loss:0.00040364086566938744\n",
      "train loss:0.000810620609342487\n",
      "train loss:0.00655236220929921\n",
      "train loss:0.0036821669406929113\n",
      "train loss:0.0008209600355169615\n",
      "train loss:0.0010637561761328838\n",
      "train loss:0.0006652362207736197\n",
      "train loss:0.00015916735269191486\n",
      "train loss:0.000753874037927921\n",
      "train loss:0.0019072234166249546\n",
      "train loss:0.0015023826735216688\n",
      "train loss:0.000996602585225098\n",
      "train loss:0.000125957226701832\n",
      "train loss:0.002551934384040971\n",
      "train loss:0.00019813053357303106\n",
      "train loss:0.0007823803269345983\n",
      "train loss:0.0004019777577616327\n",
      "train loss:0.009779728146849931\n",
      "train loss:0.0006347331932884979\n",
      "train loss:8.082317554072305e-05\n",
      "train loss:0.0015514288354839653\n",
      "train loss:0.00018976195175460616\n",
      "train loss:0.002327457384944767\n",
      "train loss:0.008050892710925267\n",
      "train loss:0.0027253253835468182\n",
      "train loss:0.0032996500267684897\n",
      "train loss:0.0004147544874538656\n",
      "train loss:0.003151058144889339\n",
      "train loss:0.0003654792104644161\n",
      "train loss:0.0005706347445025413\n",
      "train loss:0.001716624758228314\n",
      "train loss:0.0008865017182202579\n",
      "train loss:8.399329674859922e-05\n",
      "train loss:0.01548024809860259\n",
      "train loss:0.008925545498365188\n",
      "train loss:0.00103297582352753\n",
      "train loss:0.0047559478778177264\n",
      "train loss:0.005601763461628169\n",
      "train loss:0.0009133917494497999\n",
      "train loss:0.001296795954375809\n",
      "train loss:5.989611527677344e-05\n",
      "train loss:0.0006882142200688719\n",
      "train loss:0.0006764552787500193\n",
      "train loss:0.0005264815556284322\n",
      "train loss:0.004795517378076973\n",
      "train loss:0.0017413684623584886\n",
      "train loss:0.001384117500060081\n",
      "train loss:0.003636941429659542\n",
      "train loss:0.00015362236777260823\n",
      "train loss:0.0014500009119717662\n",
      "train loss:0.0015600092049274383\n",
      "train loss:0.0015177107549897578\n",
      "train loss:0.002070417004093365\n",
      "train loss:0.0005998366634936831\n",
      "train loss:0.00033119855248118813\n",
      "train loss:0.001994693365774854\n",
      "train loss:0.00020206834826427055\n",
      "train loss:0.0005850375414410774\n",
      "train loss:0.0005014868786435283\n",
      "train loss:0.0009494968596156252\n",
      "train loss:0.00037726514749431104\n",
      "train loss:0.02011397760592632\n",
      "train loss:0.0006932938756167467\n",
      "train loss:0.014477242889871645\n",
      "train loss:0.0012992095572405171\n",
      "train loss:0.0006476587903094136\n",
      "train loss:0.0018819207198065586\n",
      "train loss:0.0014673845077542403\n",
      "train loss:0.00025107345556139144\n",
      "train loss:0.0035320297885888174\n",
      "train loss:0.00018012363378404082\n",
      "train loss:0.0004909065790202991\n",
      "train loss:0.011757551627900445\n",
      "train loss:0.0013437211477384304\n",
      "train loss:4.023644375062684e-05\n",
      "train loss:0.0014408379278223061\n",
      "train loss:0.0019659037314294016\n",
      "train loss:0.013486015260664543\n",
      "train loss:0.0010623413524714926\n",
      "train loss:0.000976820821785676\n",
      "train loss:0.00018091239633640213\n",
      "train loss:0.00018972819063035846\n",
      "train loss:0.001505570431025504\n",
      "train loss:0.0010840097695610199\n",
      "train loss:0.006934134590884152\n",
      "train loss:0.0008936378738315005\n",
      "train loss:0.000385394008855579\n",
      "train loss:0.0010046023070508746\n",
      "train loss:0.003323064089196406\n",
      "train loss:0.00030443013302316693\n",
      "train loss:0.0008969701278534945\n",
      "train loss:0.0006428595641077094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0006964326001566008\n",
      "train loss:0.0006068234105870866\n",
      "train loss:0.003314374314985462\n",
      "train loss:0.004148968325240998\n",
      "train loss:0.0006752667801274846\n",
      "train loss:6.0371065493428025e-05\n",
      "train loss:0.007729152000055469\n",
      "train loss:0.0004252800540334018\n",
      "train loss:0.00034462950393836315\n",
      "train loss:0.00031144727052882836\n",
      "train loss:0.003699643608392605\n",
      "train loss:0.0025662736058288216\n",
      "train loss:0.0008772245765032251\n",
      "train loss:0.0003351766398124412\n",
      "train loss:0.006284908607601824\n",
      "train loss:0.0013219013603421909\n",
      "train loss:0.003982785283954873\n",
      "train loss:0.00038313047435151117\n",
      "train loss:0.003160804709834093\n",
      "train loss:9.896420752470538e-05\n",
      "train loss:0.0004039947557126213\n",
      "train loss:0.0009878061837720869\n",
      "train loss:8.13482502078668e-05\n",
      "train loss:0.0001987567957057284\n",
      "train loss:2.6463735504227934e-05\n",
      "train loss:3.864447285971996e-05\n",
      "train loss:0.0017961626409564017\n",
      "train loss:0.0012061038920272201\n",
      "train loss:0.0013157587073082708\n",
      "train loss:0.005210401669837208\n",
      "train loss:0.004043869431580074\n",
      "train loss:0.0010210947358422354\n",
      "train loss:0.0009034095408988843\n",
      "train loss:0.001670099119990398\n",
      "train loss:0.0001415542892247921\n",
      "train loss:0.004775372909508844\n",
      "train loss:0.0009548587264130888\n",
      "train loss:0.00020125842245629556\n",
      "train loss:0.003846423087335593\n",
      "train loss:0.0007349184873755056\n",
      "train loss:0.0005436229295928003\n",
      "train loss:0.00141187802117577\n",
      "train loss:0.0002030037653781756\n",
      "train loss:0.003307895868188754\n",
      "train loss:0.006010787698226982\n",
      "train loss:0.0012239930290519016\n",
      "train loss:0.0002555479018912415\n",
      "train loss:0.0005678043810399173\n",
      "train loss:0.00029574703626419473\n",
      "train loss:0.002136800101759385\n",
      "train loss:0.00034513922464026153\n",
      "train loss:0.001463678802024443\n",
      "train loss:0.0059112853896740244\n",
      "train loss:0.0006830961514257338\n",
      "train loss:0.0023845909834999085\n",
      "train loss:0.002051218787621994\n",
      "train loss:0.00036344983919290913\n",
      "train loss:0.0034044981877771746\n",
      "train loss:0.007182077882799208\n",
      "train loss:0.0005017734735225038\n",
      "train loss:0.0002599633085595994\n",
      "train loss:0.0013179527848321492\n",
      "train loss:0.0018183176274935804\n",
      "train loss:0.000500981481505117\n",
      "train loss:0.002022794970074906\n",
      "train loss:0.003249768564309698\n",
      "train loss:0.00010390058318639332\n",
      "train loss:0.00309790077382059\n",
      "train loss:0.00015678093560755782\n",
      "train loss:0.0010636756397958335\n",
      "train loss:0.0004765817711422835\n",
      "train loss:9.181839769069713e-05\n",
      "train loss:0.0010988457032224245\n",
      "train loss:0.0008133649111536362\n",
      "train loss:0.00044530847012502707\n",
      "train loss:0.0015199511820583355\n",
      "train loss:0.0012831767561729737\n",
      "train loss:0.00030227342223677255\n",
      "train loss:4.214695394571991e-05\n",
      "train loss:0.0005513537146957092\n",
      "train loss:0.0002214389573112189\n",
      "train loss:0.0007738970279511963\n",
      "train loss:0.0012786044620725268\n",
      "train loss:0.0028127729292734644\n",
      "train loss:0.0011021649411025183\n",
      "train loss:0.0022156184938314865\n",
      "train loss:0.0001992075864215367\n",
      "train loss:0.00015498897991361323\n",
      "train loss:0.002023604679056174\n",
      "train loss:0.0015520729888627732\n",
      "train loss:0.0016181876338718392\n",
      "train loss:0.00038507720345806707\n",
      "train loss:0.00014788732098105427\n",
      "train loss:0.001235245859973988\n",
      "train loss:0.0006969320241895624\n",
      "train loss:0.00015309367734345783\n",
      "train loss:9.676084058141722e-05\n",
      "train loss:0.00022556704218684828\n",
      "train loss:0.00011239526538101058\n",
      "train loss:0.0005877623959208803\n",
      "train loss:0.0004420407165365074\n",
      "train loss:9.761729833692528e-05\n",
      "train loss:0.00035538304348258583\n",
      "train loss:0.0005483078774338433\n",
      "train loss:0.0021132964681362084\n",
      "train loss:0.004774535760520186\n",
      "train loss:0.0014753270948401553\n",
      "train loss:8.71110702316183e-05\n",
      "train loss:0.0026200767641740585\n",
      "train loss:0.0009554707434484734\n",
      "train loss:7.223764512795422e-05\n",
      "train loss:0.001278356954003351\n",
      "train loss:0.0008444092642911984\n",
      "train loss:0.0014839645936194428\n",
      "train loss:0.0015201049468261093\n",
      "train loss:0.004143295342996312\n",
      "train loss:0.00021010949476833775\n",
      "train loss:1.8593685031284935e-05\n",
      "train loss:0.00013285335486441484\n",
      "train loss:0.0002702455450023973\n",
      "train loss:0.005183514752802871\n",
      "train loss:0.0009698912279222331\n",
      "train loss:0.00026550652912175606\n",
      "train loss:0.00025633433813528045\n",
      "train loss:0.0021217210901288\n",
      "train loss:0.0016029994614719753\n",
      "train loss:0.0001468124003276455\n",
      "train loss:0.0027444046742238553\n",
      "train loss:0.003419313637394705\n",
      "train loss:0.00022189478278823222\n",
      "train loss:0.0006867204961138323\n",
      "train loss:0.0002148408972862513\n",
      "train loss:0.004092607541156073\n",
      "train loss:0.00019756150171797236\n",
      "train loss:0.0035931118341146324\n",
      "train loss:4.609699820792971e-05\n",
      "train loss:4.5751658860783974e-05\n",
      "train loss:0.003955419822263585\n",
      "train loss:0.0013221717299087216\n",
      "train loss:0.0024950135465869674\n",
      "train loss:0.00017053680877473498\n",
      "train loss:0.0007459365456838945\n",
      "train loss:0.00039798636154313616\n",
      "train loss:8.280973401316092e-05\n",
      "train loss:0.0003842107893279764\n",
      "train loss:0.00041267028714715335\n",
      "train loss:0.0015675271418737334\n",
      "train loss:0.0008713209425588421\n",
      "train loss:0.0010138502705277696\n",
      "train loss:0.0034344655241976556\n",
      "train loss:0.0002589884537457949\n",
      "train loss:0.00021601289178262186\n",
      "train loss:9.926951876533283e-05\n",
      "train loss:0.0004445849500407499\n",
      "train loss:2.6281039676630923e-05\n",
      "train loss:0.004650288499709817\n",
      "train loss:0.0002274363880832726\n",
      "train loss:0.000855568949725648\n",
      "train loss:0.0005158418729380724\n",
      "train loss:0.0008784505362553396\n",
      "train loss:2.3942975947280312e-05\n",
      "train loss:0.0005520328269077611\n",
      "train loss:0.0002877831659114847\n",
      "train loss:0.0006171870942097807\n",
      "train loss:0.000957580586207285\n",
      "train loss:0.00028744517734891376\n",
      "train loss:3.675434160086451e-05\n",
      "train loss:0.0002100522713034944\n",
      "train loss:0.003270757851262216\n",
      "train loss:0.00017296328686555504\n",
      "train loss:0.0009276491424181523\n",
      "train loss:5.491407549258096e-05\n",
      "train loss:0.0013092263145957378\n",
      "train loss:0.0001836870499957881\n",
      "train loss:0.000713050807156354\n",
      "train loss:0.0006658681789476411\n",
      "train loss:0.0004505729617178002\n",
      "train loss:0.00021538440057607703\n",
      "train loss:4.917236004216078e-05\n",
      "train loss:1.3655937492262713e-05\n",
      "train loss:0.00017058948212273623\n",
      "train loss:0.0002223813597397292\n",
      "train loss:0.00042416132952553825\n",
      "train loss:0.0024822737806164145\n",
      "train loss:0.0003527088791259104\n",
      "train loss:0.00021558225202226243\n",
      "train loss:0.0011042527068830443\n",
      "train loss:0.0038336221670789224\n",
      "train loss:0.001419497789543221\n",
      "train loss:0.0009681660141487615\n",
      "train loss:0.0010966026819200386\n",
      "train loss:5.8989868779423945e-05\n",
      "train loss:0.0009346723555935154\n",
      "train loss:0.0039355722696703425\n",
      "train loss:0.0003232426643165976\n",
      "train loss:0.0009897002853280932\n",
      "train loss:8.45086711316487e-05\n",
      "train loss:9.5430141589358e-05\n",
      "train loss:0.0001847223829040939\n",
      "train loss:3.8081422962069764e-05\n",
      "train loss:0.000388199075821304\n",
      "train loss:0.003982349771059436\n",
      "train loss:0.0005463982288622533\n",
      "train loss:0.0012395452931734695\n",
      "train loss:0.00063449207377029\n",
      "train loss:0.00015015144908875987\n",
      "train loss:0.0008056059207215995\n",
      "train loss:0.00013329299053783835\n",
      "train loss:0.0008511134821633275\n",
      "train loss:0.00028597065873272405\n",
      "train loss:0.0002333241011951376\n",
      "train loss:0.008101380899565677\n",
      "train loss:0.003186661823003526\n",
      "train loss:0.00034677840881455345\n",
      "train loss:0.0007991221437282247\n",
      "train loss:0.027997577028185366\n",
      "train loss:0.018932324419203426\n",
      "train loss:0.0002610789342668328\n",
      "train loss:0.00018736845056221074\n",
      "train loss:0.0009684854153044288\n",
      "train loss:0.0013574160470274702\n",
      "train loss:0.0005204476761417677\n",
      "train loss:5.816965416312664e-05\n",
      "train loss:0.0013744316262541414\n",
      "train loss:0.002193899854048891\n",
      "train loss:0.00018868283243678475\n",
      "train loss:0.0007188274237868287\n",
      "train loss:0.0033325836733268392\n",
      "train loss:0.0010116058417690493\n",
      "train loss:0.00019411021829064283\n",
      "train loss:0.00014772255497649882\n",
      "train loss:0.0011663782448709547\n",
      "train loss:0.004740601882409217\n",
      "train loss:0.0025125182905938862\n",
      "train loss:0.0006675551359837826\n",
      "train loss:0.0004319370848824527\n",
      "train loss:0.0013607675433482947\n",
      "train loss:0.0014313520837929434\n",
      "train loss:9.005868427723135e-05\n",
      "train loss:0.0005002214790201423\n",
      "train loss:0.0009316067003238316\n",
      "train loss:0.0006512058143110542\n",
      "train loss:7.012110916003365e-05\n",
      "train loss:0.0021143186146827856\n",
      "train loss:0.005080209669902453\n",
      "train loss:0.00026248794404863044\n",
      "train loss:0.002681935452099381\n",
      "train loss:0.00027215591831141676\n",
      "train loss:0.00012036262546415396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00034109017131480284\n",
      "train loss:0.00016488719174445946\n",
      "train loss:0.0005525738486792152\n",
      "train loss:2.8904794264464145e-05\n",
      "train loss:0.00021716029428963619\n",
      "train loss:0.0022589406205603844\n",
      "train loss:0.0029915512242093987\n",
      "train loss:0.00021370072250651947\n",
      "train loss:0.0042476008226559\n",
      "train loss:0.0011923963274210745\n",
      "train loss:0.00030484885771280104\n",
      "train loss:4.8160603484968927e-05\n",
      "train loss:0.003140944613402074\n",
      "train loss:0.0063452618392761595\n",
      "train loss:0.0003578651176703988\n",
      "train loss:0.0006604890579072472\n",
      "train loss:0.00011380719292996854\n",
      "train loss:0.00026389058129198695\n",
      "train loss:0.0006059569925100536\n",
      "train loss:0.0008170012702192078\n",
      "train loss:0.0012769297909126362\n",
      "train loss:0.0007608645126942254\n",
      "train loss:0.0057200450066147435\n",
      "train loss:0.013652781961731822\n",
      "train loss:0.0018121359186855297\n",
      "train loss:6.0287726425905764e-05\n",
      "train loss:0.0001557823021486637\n",
      "train loss:0.0012504114011576424\n",
      "train loss:0.002333705979652276\n",
      "train loss:0.001882794036274321\n",
      "train loss:0.00021933411846053523\n",
      "train loss:0.00014368203080896257\n",
      "train loss:0.003449681145136677\n",
      "train loss:2.151166489560483e-05\n",
      "train loss:0.0005300889307955038\n",
      "train loss:0.0025574526552476825\n",
      "train loss:0.0007551401751138348\n",
      "train loss:0.002014917222938868\n",
      "train loss:3.6486700763430224e-05\n",
      "train loss:7.694067929779409e-05\n",
      "train loss:0.00019953604630403336\n",
      "train loss:0.006198142049598477\n",
      "train loss:0.013080503939098478\n",
      "train loss:7.152857486088528e-06\n",
      "train loss:0.0005406254643528937\n",
      "train loss:0.0012433731942662466\n",
      "train loss:0.002540002508513518\n",
      "train loss:0.0037006108888259816\n",
      "train loss:0.0010260131785644624\n",
      "train loss:0.0013444360423688294\n",
      "train loss:0.002736231848376694\n",
      "train loss:0.0008092214853125304\n",
      "train loss:0.00031765108617530394\n",
      "train loss:0.0020092242287634756\n",
      "train loss:0.0021487846425767257\n",
      "train loss:0.00015138291243272248\n",
      "train loss:0.0005255075545324991\n",
      "train loss:0.007179972229011615\n",
      "train loss:0.0009073422367110313\n",
      "train loss:5.803466563354187e-05\n",
      "train loss:0.001991642503071891\n",
      "train loss:0.001200933761142031\n",
      "train loss:0.0003064665859324286\n",
      "train loss:0.0012762030529245036\n",
      "train loss:0.0010204434040895088\n",
      "train loss:1.411501036879073e-05\n",
      "train loss:0.0003429767482660177\n",
      "train loss:0.0026255128860676854\n",
      "train loss:0.00027957738608188026\n",
      "train loss:0.00017991119844325385\n",
      "train loss:0.0018371005825593284\n",
      "train loss:0.0045524426828588965\n",
      "train loss:0.0012707842814881592\n",
      "train loss:0.0018537953051797908\n",
      "train loss:0.003251197656911846\n",
      "train loss:0.00010808969396242297\n",
      "train loss:0.0006407388795812538\n",
      "train loss:0.0007299624062610291\n",
      "train loss:0.0009753884592513426\n",
      "train loss:0.0007281806680053303\n",
      "train loss:0.0015172123272158642\n",
      "train loss:8.055402101151141e-05\n",
      "train loss:0.0037988438009408996\n",
      "train loss:0.0006104855299774295\n",
      "train loss:0.002348507011779581\n",
      "train loss:0.0005352107155450381\n",
      "train loss:0.0013011863414127197\n",
      "train loss:0.00028065404049505466\n",
      "train loss:0.0006154959238272186\n",
      "train loss:0.0029357300772306478\n",
      "train loss:0.0021443500240210947\n",
      "train loss:0.002617744416921731\n",
      "train loss:0.006348636538778902\n",
      "train loss:0.0004680365068786515\n",
      "train loss:0.00040139679733405944\n",
      "train loss:0.02160486914755764\n",
      "train loss:0.00047880766249635003\n",
      "train loss:9.4715817197473e-05\n",
      "train loss:0.0002702708896689661\n",
      "train loss:0.001102923925308516\n",
      "train loss:0.0005431493143260035\n",
      "train loss:5.3646001788150995e-05\n",
      "train loss:0.00012840955893514145\n",
      "train loss:8.752995383788004e-05\n",
      "train loss:0.024351753181649016\n",
      "train loss:0.0018798546794890278\n",
      "train loss:0.003121064707549126\n",
      "train loss:0.00046251776706134637\n",
      "train loss:0.001413351835512609\n",
      "train loss:0.0018042000157020791\n",
      "train loss:0.0012801175260371827\n",
      "train loss:0.00041277442727857453\n",
      "train loss:0.0009788180229050737\n",
      "train loss:0.00013224455581141515\n",
      "train loss:0.0003838021470643674\n",
      "train loss:0.0037564800987974992\n",
      "train loss:0.0012305431516589631\n",
      "train loss:0.00033055402056448636\n",
      "train loss:0.0008474878096673302\n",
      "train loss:0.026777629426074517\n",
      "train loss:0.003233800249419624\n",
      "train loss:6.048181066498784e-05\n",
      "train loss:0.0062202128607417115\n",
      "train loss:0.0014189518468270721\n",
      "train loss:0.00023466827855028838\n",
      "train loss:0.002078636629680212\n",
      "train loss:0.00026451360100779455\n",
      "train loss:0.0058996358742430125\n",
      "train loss:0.0009392652825980402\n",
      "train loss:7.7513186740613e-05\n",
      "train loss:0.0008192911830387859\n",
      "train loss:0.0010637941178917375\n",
      "train loss:0.00017780364618772676\n",
      "train loss:0.00017987598031368515\n",
      "train loss:0.0002717264055189842\n",
      "train loss:0.00647517981685736\n",
      "train loss:0.0002355582634487783\n",
      "train loss:0.0005664965054687885\n",
      "train loss:6.618946432191375e-05\n",
      "train loss:0.0002904302471998886\n",
      "train loss:0.0004510658834595982\n",
      "train loss:1.8680495444696876e-05\n",
      "train loss:0.0025294892051688366\n",
      "train loss:0.0022265350688810133\n",
      "train loss:0.0006257192620847967\n",
      "train loss:0.003970595722549653\n",
      "train loss:0.00023701832805089081\n",
      "train loss:0.0044381123327233716\n",
      "train loss:0.0005884925994522752\n",
      "train loss:0.0006430851001134652\n",
      "train loss:0.0017425387199954837\n",
      "train loss:0.00010432601074040561\n",
      "train loss:0.0009170322808371195\n",
      "train loss:0.0016557472956713905\n",
      "train loss:0.0010402698840839366\n",
      "train loss:9.590098968230662e-05\n",
      "train loss:0.0001397807609391502\n",
      "train loss:2.8165898479993787e-05\n",
      "train loss:0.002281982242089329\n",
      "train loss:0.0002368373427716745\n",
      "train loss:3.808484464695307e-05\n",
      "train loss:0.005817836239642538\n",
      "train loss:0.005433715004729947\n",
      "train loss:0.0015450766209050568\n",
      "train loss:0.0022461300085589607\n",
      "train loss:0.007675597014091763\n",
      "train loss:0.0009592361046497842\n",
      "train loss:0.0004279076691541232\n",
      "train loss:0.002218965205952976\n",
      "train loss:0.001939325604608533\n",
      "train loss:0.003965085433613657\n",
      "train loss:0.000665965036807571\n",
      "train loss:0.00401460907899329\n",
      "train loss:0.0015411532977769675\n",
      "train loss:0.001354128098600014\n",
      "train loss:0.0031469358106303216\n",
      "train loss:0.0007112711214121085\n",
      "train loss:0.0034051217452603626\n",
      "train loss:0.0032927962419109285\n",
      "train loss:6.887533842984398e-05\n",
      "train loss:0.003491414954005787\n",
      "train loss:0.0012120120915700902\n",
      "train loss:0.001962611029585439\n",
      "train loss:0.0015403136386296068\n",
      "train loss:0.0006264380799860915\n",
      "train loss:0.00048280064181355567\n",
      "train loss:0.0015092590624851644\n",
      "train loss:0.0029793695081607287\n",
      "train loss:0.0002753896024092364\n",
      "train loss:0.0010897751237205055\n",
      "train loss:0.0010065878639766125\n",
      "train loss:0.00012187839821522177\n",
      "train loss:0.00368776178813942\n",
      "train loss:0.0011718467629360627\n",
      "train loss:0.00020275719052890558\n",
      "train loss:0.00014583587604759146\n",
      "train loss:0.0020795958027908083\n",
      "train loss:0.00033228381009831574\n",
      "train loss:0.00021814160418413004\n",
      "train loss:0.05037417212088968\n",
      "train loss:0.0014348531337535415\n",
      "train loss:0.0002371048122671402\n",
      "train loss:0.0017940717750276078\n",
      "train loss:0.0013780775965541905\n",
      "train loss:0.0012036702275021634\n",
      "train loss:0.0007332698825450369\n",
      "train loss:0.0010335417155836369\n",
      "train loss:1.5235793971969797e-05\n",
      "train loss:0.000989410090481687\n",
      "train loss:0.0002075421034952169\n",
      "train loss:0.001205292958910622\n",
      "train loss:0.008806349218231972\n",
      "train loss:0.0013140289710708171\n",
      "train loss:0.00014533401808300344\n",
      "train loss:0.0016301646087527432\n",
      "train loss:0.003030160778506465\n",
      "train loss:0.0005684703673693938\n",
      "train loss:5.6731637694195005e-05\n",
      "train loss:5.955806713647326e-05\n",
      "train loss:9.003082313520293e-05\n",
      "train loss:0.002605162697239392\n",
      "train loss:0.0005417846416710561\n",
      "train loss:5.237266439003678e-05\n",
      "train loss:0.0015411481134107513\n",
      "train loss:0.00017320048698780735\n",
      "train loss:0.00010757490205520843\n",
      "train loss:0.002611067262091934\n",
      "train loss:0.00012191610135274488\n",
      "train loss:0.001229456849449923\n",
      "train loss:0.0018891222312186792\n",
      "train loss:0.007696580380874014\n",
      "train loss:0.0013003434103426976\n",
      "train loss:0.00018505939916412206\n",
      "train loss:0.00025612698221815785\n",
      "train loss:0.0002795652211583374\n",
      "train loss:0.0007692542836531245\n",
      "train loss:0.0002288731153510289\n",
      "train loss:0.0010565391546485732\n",
      "train loss:0.0024374832441716077\n",
      "train loss:3.45057403144227e-06\n",
      "train loss:0.00033722824649075935\n",
      "train loss:0.001372762739417135\n",
      "train loss:0.001630737030566132\n",
      "train loss:4.018867838451751e-05\n",
      "train loss:0.0001771002259328671\n",
      "train loss:0.00017177047204447172\n",
      "train loss:0.00032844401382317747\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.988\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from collections import OrderedDict\n",
    "from common.trainer import Trainer\n",
    "from common.layers import *\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                         hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보존\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 다신 여기서 이거 돌리지말자!!! \n",
    "\n",
    "# 2시간 걸렸다!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_convnet import SimpleConvNet\n",
    "\n",
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    \"\"\"\n",
    "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
    "    \"\"\"\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "network = SimpleConvNet()\n",
    "# 무작위(랜덤) 초기화 후의 가중치\n",
    "filter_show(network.params['W1'])\n",
    "\n",
    "# 학습된 가중치\n",
    "network.load_params(\"params.pkl\")\n",
    "filter_show(network.params['W1'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
