{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3.my_ann.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"18Au0XD1oU0PYgcbQN7FYPeaTPYtChs4z","authorship_tag":"ABX9TyMOnT9ktTODhG7asW85yGuE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"HfiD-agSXDTz","executionInfo":{"status":"ok","timestamp":1619260119266,"user_tz":-540,"elapsed":3614,"user":{"displayName":"이서영","photoUrl":"","userId":"08706917529998634867"}}},"source":["import torch\n","import numpy\n","from sklearn.datasets import make_blobs\n","import matplotlib.pyplot as plt"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"riBszFSJbHXy","executionInfo":{"status":"ok","timestamp":1619260535673,"user_tz":-540,"elapsed":714,"user":{"displayName":"이서영","photoUrl":"","userId":"08706917529998634867"}}},"source":["n_dim = 2\n","x_train, y_train = make_blobs(n_samples=80, n_features=n_dim,\n","                              centers=[[1,1], [-1, -1], [1, -1], [-1, 1]],\n","                                       shuffle=True,\n","                                       cluster_std = 0.3)\n","x_test , y_test = make_blobs(n_samples=20, n_features=n_dim,\n","                             centers=[[1,1], [-1,-1], [1,-1], [-1,1]],\n","                             shuffle=True, cluster_std=0.3)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GmCtxuA0c4gQ"},"source":["Q : blob이란 개념이 뭘까?\n"]},{"cell_type":"code","metadata":{"id":"Nhk6eb04cnR6","executionInfo":{"status":"ok","timestamp":1619261140801,"user_tz":-540,"elapsed":655,"user":{"displayName":"이서영","photoUrl":"","userId":"08706917529998634867"}}},"source":["def label_map(y_, from_ , to_):\n","  y = numpy.copy(y_)\n","  for f in from_:\n","    y[y_ == f] = to_\n","  return y"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"nIJZ0F3PfCyR","executionInfo":{"status":"ok","timestamp":1619261182547,"user_tz":-540,"elapsed":571,"user":{"displayName":"이서영","photoUrl":"","userId":"08706917529998634867"}}},"source":["y_train = label_map(y_train, [0,1], 0)\n","y_train = label_map(y_train, [2,3], 1)\n","y_test = label_map(y_test, [0,1], 0)\n","y_test = label_map(y_test, [2,3], 1)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"omS1d4tZfM_6","executionInfo":{"status":"ok","timestamp":1619261337409,"user_tz":-540,"elapsed":586,"user":{"displayName":"이서영","photoUrl":"","userId":"08706917529998634867"}}},"source":["def vis_data(x,y = None, c = 'r'):\n","  if y is None:\n","    y = [None] * len(x)\n","  for x_, y_ in zip(x,y):\n","    if y_ is None:\n","      plt.plot(x_[0], x_[1], \"*\",makerfacecolor='none', makerededgecolor=c)\n","    else:\n","      plt.plot(x_[0], x_[1], c+'o' if y_ == 0 else c+'+')"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":264},"id":"yUf7isgrfvTa","executionInfo":{"status":"ok","timestamp":1619261357615,"user_tz":-540,"elapsed":1057,"user":{"displayName":"이서영","photoUrl":"","userId":"08706917529998634867"}},"outputId":"3f2b5f14-9a86-4597-cc35-b38fdd4fa76c"},"source":["plt.figure()\n","vis_data(x_train, y_train, c='r')\n","plt.show()"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"P5K9H4HRf3np","executionInfo":{"status":"ok","timestamp":1619261821372,"user_tz":-540,"elapsed":612,"user":{"displayName":"이서영","photoUrl":"","userId":"08706917529998634867"}}},"source":["x_train = torch.FloatTensor(x_train)\n","x_test = torch.FloatTensor(x_test)\n","y_train = torch.FloatTensor(y_train)\n","y_test = torch.FloatTensor(y_test)"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hOsF5lzahYyC"},"source":["convert numpy vector to pytorch tensor "]},{"cell_type":"code","metadata":{"id":"8uEEVZcthdtz","executionInfo":{"status":"ok","timestamp":1619263420373,"user_tz":-540,"elapsed":600,"user":{"displayName":"이서영","photoUrl":"","userId":"08706917529998634867"}}},"source":["class NeuralNet(torch.nn.Module):\n","  def __init__(self, input_size, hidden_size):\n","    super(NeuralNet, self).__init__()\n","    self.input_size = input_size\n","    self.hidden_size = hidden_size\n","    self.linear_1 = torch.nn.Linear(self.input_size, self.hidden_size)\n","    self.relu = torch.nn.ReLU()\n","    self.linear_2 = torch.nn.Linear(self.hidden_size, 1)\n","    self.sigmoid = torch.nn.Sigmoid()\n","  \n","  def forward(self, input_tensor):\n","    linear1 = self.linear_1(input_tensor)\n","    relu = self.relu(linear1)\n","    linear2 = self.linear_2(relu)\n","    output = self.sigmoid(linear2)\n","    return output"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"N_WxFkP0kFND","executionInfo":{"status":"ok","timestamp":1619263430348,"user_tz":-540,"elapsed":783,"user":{"displayName":"이서영","photoUrl":"","userId":"08706917529998634867"}}},"source":["model = NeuralNet(2, 5)\n","LR = 0.03\n","criterion = torch.nn.BCELoss()"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"dGV9wd4BnsMp","executionInfo":{"status":"ok","timestamp":1619265843345,"user_tz":-540,"elapsed":772,"user":{"displayName":"이서영","photoUrl":"","userId":"08706917529998634867"}}},"source":["EPOCHS = 20000"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"MNvczwm2n1cK","executionInfo":{"status":"ok","timestamp":1619265843347,"user_tz":-540,"elapsed":528,"user":{"displayName":"이서영","photoUrl":"","userId":"08706917529998634867"}}},"source":["optimizer = torch.optim.SGD(model.parameters(), lr=LR)"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4OgQqhhqs_Fl"},"source":["\n","\n","```\n","for i in range(0,40000):\n","    random_tensor.requires_grad_(True)\n","    hypothesis = weird_function(random_tensor)\n","    loss = distance_loss(hypothesis, broken_image)\n","    loss.backward()\n","    with torch.no_grad():\n","        random_tensor = random_tensor - lr*random_tensor.grad\n","    if i % 1000 == 0:\n","        print('Loss at {} = {}'.format(i, loss.item()))\n","```\n","앞선 예제와 같이, 결국에는 새 가중치 = 가중치 - 학습률 * 가중치에 대한 기울기   \n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TB2FSnvZs_sc","executionInfo":{"status":"ok","timestamp":1619265844119,"user_tz":-540,"elapsed":452,"user":{"displayName":"이서영","photoUrl":"","userId":"08706917529998634867"}},"outputId":"88aa9f97-61c3-453c-aac1-0f6bbbc4d837"},"source":["model.eval()\n","test_loss_before = criterion(model(x_test).squeeze(), y_test)\n","print(type(test_loss_before))\n","print(\"before training, test loss is {}\".format(test_loss_before)) # item 안해도 뜨는데?\n","print(\"before training, test loss is {}\".format(test_loss_before.item()))"],"execution_count":31,"outputs":[{"output_type":"stream","text":["<class 'torch.Tensor'>\n","before training, test loss is 0.06550328433513641\n","before training, test loss is 0.06550328433513641\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ig1ONeP5t7MS"},"source":["loss가 0.7이다. 100 번 찍어 70번은 틀린다는 뜻이다"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZZ0yDdo5towc","executionInfo":{"status":"ok","timestamp":1619265857420,"user_tz":-540,"elapsed":11334,"user":{"displayName":"이서영","photoUrl":"","userId":"08706917529998634867"}},"outputId":"19b4bb96-f496-4989-f030-a8e1c75973e9"},"source":["for epoch in range(EPOCHS):\n","  model.train()\n","  optimizer.zero_grad()\n","  train_output = model(x_train)\n","  train_loss = criterion(train_output.squeeze(), y_train)\n","  if epoch % 100 == 0:\n","    print('Train loss at {} is {}'.format(epoch, train_loss.item()))\n","  train_loss.backward()\n","  optimizer.step()"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Train loss at 0 is 0.06040669605135918\n","Train loss at 100 is 0.05656857416033745\n","Train loss at 200 is 0.053182344883680344\n","Train loss at 300 is 0.050174396485090256\n","Train loss at 400 is 0.04749162495136261\n","Train loss at 500 is 0.045079492032527924\n","Train loss at 600 is 0.04289936274290085\n","Train loss at 700 is 0.040918800979852676\n","Train loss at 800 is 0.03911212831735611\n","Train loss at 900 is 0.03745710849761963\n","Train loss at 1000 is 0.03593558818101883\n","Train loss at 1100 is 0.03453456610441208\n","Train loss at 1200 is 0.03323996439576149\n","Train loss at 1300 is 0.03203771263360977\n","Train loss at 1400 is 0.03091828152537346\n","Train loss at 1500 is 0.029873177409172058\n","Train loss at 1600 is 0.02889532409608364\n","Train loss at 1700 is 0.027978431433439255\n","Train loss at 1800 is 0.027116501703858376\n","Train loss at 1900 is 0.026304686442017555\n","Train loss at 2000 is 0.025538558140397072\n","Train loss at 2100 is 0.024814359843730927\n","Train loss at 2200 is 0.02412862703204155\n","Train loss at 2300 is 0.023478340357542038\n","Train loss at 2400 is 0.022860761731863022\n","Train loss at 2500 is 0.0222735907882452\n","Train loss at 2600 is 0.021714448928833008\n","Train loss at 2700 is 0.021181419491767883\n","Train loss at 2800 is 0.02067263051867485\n","Train loss at 2900 is 0.020186830312013626\n","Train loss at 3000 is 0.01972416415810585\n","Train loss at 3100 is 0.019281048327684402\n","Train loss at 3200 is 0.018856234848499298\n","Train loss at 3300 is 0.0184486024081707\n","Train loss at 3400 is 0.01805712841451168\n","Train loss at 3500 is 0.017680803313851357\n","Train loss at 3600 is 0.017318816855549812\n","Train loss at 3700 is 0.016970353201031685\n","Train loss at 3800 is 0.016634654253721237\n","Train loss at 3900 is 0.0163113996386528\n","Train loss at 4000 is 0.016002077609300613\n","Train loss at 4100 is 0.015703391283750534\n","Train loss at 4200 is 0.015414796769618988\n","Train loss at 4300 is 0.015135763213038445\n","Train loss at 4400 is 0.014865865930914879\n","Train loss at 4500 is 0.014604644849896431\n","Train loss at 4600 is 0.014351683668792248\n","Train loss at 4700 is 0.01410666387528181\n","Train loss at 4800 is 0.013869315385818481\n","Train loss at 4900 is 0.013639137148857117\n","Train loss at 5000 is 0.013415826484560966\n","Train loss at 5100 is 0.013199074193835258\n","Train loss at 5200 is 0.012989453971385956\n","Train loss at 5300 is 0.012785926461219788\n","Train loss at 5400 is 0.01258809119462967\n","Train loss at 5500 is 0.01239575445652008\n","Train loss at 5600 is 0.012208666652441025\n","Train loss at 5700 is 0.012026626616716385\n","Train loss at 5800 is 0.011849555186927319\n","Train loss at 5900 is 0.01167717669159174\n","Train loss at 6000 is 0.011509308591485023\n","Train loss at 6100 is 0.011345764622092247\n","Train loss at 6200 is 0.011186359450221062\n","Train loss at 6300 is 0.011030962690711021\n","Train loss at 6400 is 0.010879444889724255\n","Train loss at 6500 is 0.010731630958616734\n","Train loss at 6600 is 0.010587401688098907\n","Train loss at 6700 is 0.010446667671203613\n","Train loss at 6800 is 0.010309266857802868\n","Train loss at 6900 is 0.010175098665058613\n","Train loss at 7000 is 0.010044034570455551\n","Train loss at 7100 is 0.009916013106703758\n","Train loss at 7200 is 0.009790907613933086\n","Train loss at 7300 is 0.009668624959886074\n","Train loss at 7400 is 0.009549105539917946\n","Train loss at 7500 is 0.009432176128029823\n","Train loss at 7600 is 0.009317860938608646\n","Train loss at 7700 is 0.009205992333590984\n","Train loss at 7800 is 0.009096533991396427\n","Train loss at 7900 is 0.008989406749606133\n","Train loss at 8000 is 0.008884538896381855\n","Train loss at 8100 is 0.008781852200627327\n","Train loss at 8200 is 0.008681289851665497\n","Train loss at 8300 is 0.008582809008657932\n","Train loss at 8400 is 0.008486328646540642\n","Train loss at 8500 is 0.008391784504055977\n","Train loss at 8600 is 0.008299140259623528\n","Train loss at 8700 is 0.008208333514630795\n","Train loss at 8800 is 0.008119321428239346\n","Train loss at 8900 is 0.008032050915062428\n","Train loss at 9000 is 0.007946457713842392\n","Train loss at 9100 is 0.007864663377404213\n","Train loss at 9200 is 0.0077844103798270226\n","Train loss at 9300 is 0.007705774158239365\n","Train loss at 9400 is 0.007628639228641987\n","Train loss at 9500 is 0.007552996277809143\n","Train loss at 9600 is 0.00747858639806509\n","Train loss at 9700 is 0.0074056596495211124\n","Train loss at 9800 is 0.007334044668823481\n","Train loss at 9900 is 0.007263668812811375\n","Train loss at 10000 is 0.0071945288218557835\n","Train loss at 10100 is 0.007126736454665661\n","Train loss at 10200 is 0.007060098461806774\n","Train loss at 10300 is 0.006994711700826883\n","Train loss at 10400 is 0.006930468138307333\n","Train loss at 10500 is 0.006867258343845606\n","Train loss at 10600 is 0.006805091165006161\n","Train loss at 10700 is 0.0067439451813697815\n","Train loss at 10800 is 0.0066838255152106285\n","Train loss at 10900 is 0.006624680012464523\n","Train loss at 11000 is 0.006566590629518032\n","Train loss at 11100 is 0.006509301718324423\n","Train loss at 11200 is 0.00645303213968873\n","Train loss at 11300 is 0.0063975900411605835\n","Train loss at 11400 is 0.006343082524836063\n","Train loss at 11500 is 0.006289356853812933\n","Train loss at 11600 is 0.006236487068235874\n","Train loss at 11700 is 0.006184461526572704\n","Train loss at 11800 is 0.006133249960839748\n","Train loss at 11900 is 0.00608279462903738\n","Train loss at 12000 is 0.0060330964624881744\n","Train loss at 12100 is 0.005984132178127766\n","Train loss at 12200 is 0.005935891065746546\n","Train loss at 12300 is 0.005888382904231548\n","Train loss at 12400 is 0.005841564852744341\n","Train loss at 12500 is 0.005795489996671677\n","Train loss at 12600 is 0.005749992094933987\n","Train loss at 12700 is 0.005705181043595076\n","Train loss at 12800 is 0.00566105917096138\n","Train loss at 12900 is 0.00561749842017889\n","Train loss at 13000 is 0.005574597045779228\n","Train loss at 13100 is 0.005532270763069391\n","Train loss at 13200 is 0.00549055403098464\n","Train loss at 13300 is 0.005449359770864248\n","Train loss at 13400 is 0.005408828146755695\n","Train loss at 13500 is 0.005368757992982864\n","Train loss at 13600 is 0.00532927643507719\n","Train loss at 13700 is 0.005290350876748562\n","Train loss at 13800 is 0.005251922644674778\n","Train loss at 13900 is 0.005213956814259291\n","Train loss at 14000 is 0.005176586098968983\n","Train loss at 14100 is 0.005139677785336971\n","Train loss at 14200 is 0.005103272385895252\n","Train loss at 14300 is 0.005067333113402128\n","Train loss at 14400 is 0.005031825043261051\n","Train loss at 14500 is 0.004996804054826498\n","Train loss at 14600 is 0.004962202161550522\n","Train loss at 14700 is 0.004928073845803738\n","Train loss at 14800 is 0.004894345533102751\n","Train loss at 14900 is 0.004861079156398773\n","Train loss at 15000 is 0.004828225821256638\n","Train loss at 15100 is 0.004795772954821587\n","Train loss at 15200 is 0.004763709381222725\n","Train loss at 15300 is 0.004732046741992235\n","Train loss at 15400 is 0.004700720310211182\n","Train loss at 15500 is 0.004669906571507454\n","Train loss at 15600 is 0.0046394020318984985\n","Train loss at 15700 is 0.0046092248521745205\n","Train loss at 15800 is 0.004579401109367609\n","Train loss at 15900 is 0.004550001583993435\n","Train loss at 16000 is 0.0045209238305687904\n","Train loss at 16100 is 0.0044921571388840675\n","Train loss at 16200 is 0.004463774152100086\n","Train loss at 16300 is 0.004435672424733639\n","Train loss at 16400 is 0.004407910164445639\n","Train loss at 16500 is 0.004380506929010153\n","Train loss at 16600 is 0.004353359341621399\n","Train loss at 16700 is 0.004326588474214077\n","Train loss at 16800 is 0.0043000574223697186\n","Train loss at 16900 is 0.004273856990039349\n","Train loss at 17000 is 0.004247942008078098\n","Train loss at 17100 is 0.004222349729388952\n","Train loss at 17200 is 0.004196966532617807\n","Train loss at 17300 is 0.0041719418950378895\n","Train loss at 17400 is 0.004147130995988846\n","Train loss at 17500 is 0.004122627433389425\n","Train loss at 17600 is 0.0040984079241752625\n","Train loss at 17700 is 0.004074400756508112\n","Train loss at 17800 is 0.004050699528306723\n","Train loss at 17900 is 0.004027214366942644\n","Train loss at 18000 is 0.004004007671028376\n","Train loss at 18100 is 0.003981046378612518\n","Train loss at 18200 is 0.003958320710808039\n","Train loss at 18300 is 0.003935813903808594\n","Train loss at 18400 is 0.003913609776645899\n","Train loss at 18500 is 0.0038915842305868864\n","Train loss at 18600 is 0.0038697700947523117\n","Train loss at 18700 is 0.0038481908850371838\n","Train loss at 18800 is 0.0038268608041107655\n","Train loss at 18900 is 0.003805743530392647\n","Train loss at 19000 is 0.0037848528008908033\n","Train loss at 19100 is 0.003764145774766803\n","Train loss at 19200 is 0.003743648063391447\n","Train loss at 19300 is 0.0037233601324260235\n","Train loss at 19400 is 0.0037032761611044407\n","Train loss at 19500 is 0.003683431539684534\n","Train loss at 19600 is 0.0036637592129409313\n","Train loss at 19700 is 0.003644296433776617\n","Train loss at 19800 is 0.0036251558922231197\n","Train loss at 19900 is 0.0036063131410628557\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0EScTgK4uumd"},"source":["=================================================  \n","학습 끝 , 성능시험"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yjAnuUoGupDN","executionInfo":{"status":"ok","timestamp":1619265864174,"user_tz":-540,"elapsed":616,"user":{"displayName":"이서영","photoUrl":"","userId":"08706917529998634867"}},"outputId":"ff06a2bf-bdd5-44a8-acf6-2b757387e176"},"source":["model.eval()\n","test_loss = criterion(torch.squeeze(model(x_test)), y_test)\n","print(\"After training , test loss is {}:\".format(test_loss.item()))"],"execution_count":33,"outputs":[{"output_type":"stream","text":["After training , test loss is 0.004065272863954306:\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oBnMutfAu7OD","executionInfo":{"status":"ok","timestamp":1619265872435,"user_tz":-540,"elapsed":576,"user":{"displayName":"이서영","photoUrl":"","userId":"08706917529998634867"}},"outputId":"c2f47754-8ee6-415c-bfd0-99893faa42b7"},"source":["torch.save(model.state_dict(), '/content/drive/MyDrive/torch_tutorial/3min_torch/3ch_ann/model1.pt') #이거 예외처리 어떻게 해야할까?\n","print('state_dict format of the model : {}'.format(model.state_dict())) "],"execution_count":35,"outputs":[{"output_type":"stream","text":["state_dict format of the model : OrderedDict([('linear_1.weight', tensor([[-0.1547,  0.0160],\n","        [ 3.4390,  1.3650],\n","        [ 1.3345, -1.0129],\n","        [-1.7406, -2.7814],\n","        [ 2.5364, -1.8601]])), ('linear_1.bias', tensor([-0.6498,  0.2899, -0.1218,  0.1245, -0.2553])), ('linear_2.weight', tensor([[ 0.1082, -3.6502,  1.4503, -3.2257,  3.0413]])), ('linear_2.bias', tensor([4.7260]))])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bOwwjsyCv4im"},"source":[""],"execution_count":null,"outputs":[]}]}