{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5.2\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.kernel_approximation import AdditiveChi2Sampler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "'''\n",
    "Parameters\n",
    "'''\n",
    "patch_stride = 16\n",
    "K = 20\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Normalizing\n",
    "'''\n",
    "flattened_train_features = np.concatenate(train_features, axis=0)\n",
    "pca = PCA(n_components=flattened_train_features.shape[-1], whiten=True)\n",
    "pca.fit(flattened_train_features)\n",
    "train_normalized_features = list()\n",
    "index = 0\n",
    "for features in train_features:\n",
    "    features = pca.transform(features)\n",
    "    train_normalized_features.append(features)\n",
    "    index += 1\n",
    "    print(\"Normalize Train Features ... {:4d}/{:4d}\".format(index, len(train_features)))\n",
    "test_normalized_features = list()\n",
    "index = 0\n",
    "for features in test_features:\n",
    "    features = pca.transform(features)\n",
    "    test_normalized_features.append(features)\n",
    "    index += 1\n",
    "    print(\"Normalize Test Features ... {:4d}/{:4d}\".format(index, len(test_features)))\n",
    "\n",
    "'''\n",
    "Make Codebook\n",
    "'''\n",
    "###################################################################################\n",
    "# 아래의 코드의 빈 곳(None 부분)을 채우세요.\n",
    "# None 부분 외의 부분은 가급적 수정 하지 말고, 주어진 형식에 맞추어\n",
    "# None 부분 만을 채워주세요. 임의적으로 전체적인 구조를 수정하셔도 좋지만,\n",
    "# 파이썬 코딩에 익숙 하지 않으시면, 가급적 틀을 유지하시는 것을 권장합니다.\n",
    "# 1) 함수 encode 부분 안의 None 부분을 채우세요.\n",
    "#    distances는 K means 알고리즘을 통해 얻어진 centroids, 즉 codewords(visual words)와\n",
    "#    각 이미지의 특징들 간의 거리 입니다.\n",
    "#    distances 값을 이용하여, features(# of keypoints, feature_dim)를\n",
    "#    인코딩(histogram 혹은 quantization이라고도 함) 하세요.\n",
    "#    인코딩된 결과인 representations은 (K)로 표현되어야 합니다.\n",
    "#    이 때, K는 codewords의 개수입니다.\n",
    "###################################################################################\n",
    "class Codebook:\n",
    "\n",
    "    def __init__(self, K):\n",
    "\n",
    "        self.K = K\n",
    "\n",
    "        self.kmeans = KMeans(n_clusters=K, verbose=True)\n",
    "\n",
    "    def make_code_words(self, features):\n",
    "\n",
    "        self.kmeans.fit(features)\n",
    "\n",
    "    def encode(self, features, shapes):\n",
    "\n",
    "        distances = self.kmeans.transform(features)\n",
    "\n",
    "        # reshaped_features는 Spatial Pyramid Matching 문제에 활용하세요.\n",
    "        reshaped_features = np.reshape(features, (shapes[0], shapes[1], -1))\n",
    "\n",
    "        # Write Your Code Here ########################################################\n",
    "        representations = None\n",
    "        ###############################################################################\n",
    "\n",
    "        if np.array(representations).shape != (self.K, ):\n",
    "            # representations는 반드시 (K) 차원을 가져야 합니다 (Spatial Pyramid Matching 사용 안할 시에만).\n",
    "            print(\"Your code may be wrong\")\n",
    "\n",
    "        return representations\n",
    "\n",
    "print(\"Make Codebook ...\")\n",
    "flattened_normalized_train_features = pca.transform(flattened_train_features)\n",
    "codebook = Codebook(K)\n",
    "codebook.make_code_words(flattened_normalized_train_features)\n",
    "\n",
    "'''\n",
    "Encode Features\n",
    "'''\n",
    "train_encoded_features = list()\n",
    "index = 0\n",
    "for features, shapes in zip(train_normalized_features, train_feature_shapes):\n",
    "    encoded_features = codebook.encode(features, shapes)\n",
    "    train_encoded_features.append(encoded_features)\n",
    "    index += 1\n",
    "    print(\"Encoding Train Features ... {:4d}/{:4d}\".format(index, len(train_normalized_features)))\n",
    "test_encoded_features = list()\n",
    "index = 0\n",
    "for features, shapes in zip(test_normalized_features, test_feature_shapes):\n",
    "    encoded_features = codebook.encode(features, shapes)\n",
    "    test_encoded_features.append(encoded_features)\n",
    "    index += 1\n",
    "    print(\"Encoding Text Features ... {:4d}/{:4d}\".format(index, len(test_normalized_features)))\n",
    "\n",
    "'''\n",
    "Approximate Kernel\n",
    "'''\n",
    "chi2sampler = AdditiveChi2Sampler(sample_steps=2)\n",
    "chi2sampler.fit(train_encoded_features, y_train)\n",
    "train_encoded_features = chi2sampler.transform(train_encoded_features)\n",
    "test_encoded_features = chi2sampler.transform(test_encoded_features)\n",
    "\n",
    "'''\n",
    "Classify Images with SVM\n",
    "'''\n",
    "###################################################################################\n",
    "# 아래의 코드의 빈 곳(None 부분)을 채우세요.\n",
    "# None 부분 외의 부분은 가급적 수정 하지 말고, 주어진 형식에 맞추어\n",
    "# None 부분 만을 채워주세요. 임의적으로 전체적인 구조를 수정하셔도 좋지만,\n",
    "# 파이썬 코딩에 익숙 하지 않으시면, 가급적 틀을 유지하시는 것을 권장합니다.\n",
    "# 1) 아래의 model 부분에 sklearn 패키지를 활용하여, Linear SVM(SVC) 모델을 정의하세요.\n",
    "#    처음에는 SVM의 parameter를 기본으로 설정하여 구동하시길 권장합니다.\n",
    "#    구동 성공 시, SVM의 C 값과 max_iter 파라미터 등을 조정하여 성능 향상을 해보시길 바랍니다.\n",
    "###################################################################################\n",
    "# Write Your Code Here ############################################################\n",
    "model = None\n",
    "###################################################################################\n",
    "\n",
    "print(\"Classify Images ...\")\n",
    "model.fit(train_encoded_features, y_train)\n",
    "train_score = model.score(train_encoded_features, y_train)\n",
    "test_score = model.score(test_encoded_features, y_test)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "'''\n",
    "Print Results\n",
    "'''\n",
    "print()\n",
    "print(\"=\" * 90)\n",
    "print(\"Train  Score: {:.5f}\".format(train_score))\n",
    "print(\"Test   Score: {:.5f}\".format(test_score))\n",
    "print(\"Elapsed Time: {:.2f} secs\".format(elapsed_time))\n",
    "print(\"=\" * 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[문제 1. 특징 추출 – 15 pts]  \n",
    "1-1. 주어진 Keypoint를 통하여, 각각의 이미지마다 특징을 추출하시오.  \n",
    "이 때, OpenCV 패키지를 활용하여, SIFT와 같은 특징을 추출하시오. (자세한 사항은 템플릿 코드를 참고)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 keypoint로 추출한다는걸 잘 모르겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load Dataset\n",
    "'''\n",
    "def scene15():\n",
    "\n",
    "    train_folders = glob.glob(\"SCENE-15/train/*\")\n",
    "    train_folders.sort()\n",
    "    classes = dict()\n",
    "    x_train = list()\n",
    "    y_train = list()\n",
    "    for index, folder in enumerate(train_folders):\n",
    "        label = os.path.basename(folder) #머지\n",
    "        classes[label] = index\n",
    "        paths = glob.glob(os.path.join(folder, \"*\"))\n",
    "        for path in paths:\n",
    "            x_train.append(cv2.imread(path, 0))\n",
    "            y_train.append(index)\n",
    "\n",
    "    x_test = list()\n",
    "    y_test = list()\n",
    "    test_folders = glob.glob(\"SCENE-15/test/*\")\n",
    "    test_folders.sort()\n",
    "    for folder in test_folders:\n",
    "        label = os.path.basename(folder)\n",
    "        index = classes[label]\n",
    "        paths = glob.glob(os.path.join(folder, \"*\"))\n",
    "        for path in paths:\n",
    "            x_test.append(cv2.imread(path, 0))\n",
    "            y_test.append(index)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test, sorted(classes.keys())\n",
    "\n",
    "print(\"Load Dataset ...\")\n",
    "x_train, y_train, x_test, y_test, labels_names = scene15()\n",
    "\n",
    "random_indices = list(range(len(y_train)))\n",
    "random.shuffle(random_indices)\n",
    "x_train = np.array(x_train)[random_indices].tolist()\n",
    "y_train = np.array(y_train)[random_indices].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Extract Patches\n",
    "'''\n",
    "train_key_points = list()\n",
    "train_feature_shapes = list()\n",
    "for image in x_train:\n",
    "    h, w = image.shape\n",
    "    image_key_points = list()\n",
    "    for x in range(0, w, patch_stride):\n",
    "        for y in range(0, h, patch_stride):\n",
    "            image_key_points.append(cv2.KeyPoint(x, y, patch_stride))\n",
    "    train_key_points.append(image_key_points)\n",
    "    train_feature_shapes.append((len(range(0, w, patch_stride)), (len(range(0, h, patch_stride)))))\n",
    "\n",
    "test_key_points = list()\n",
    "test_feature_shapes = list()\n",
    "for image in x_test:\n",
    "    h, w = image.shape\n",
    "    image_key_points = list()\n",
    "    for x in range(0, w, patch_stride):\n",
    "        for y in range(0, h, patch_stride):\n",
    "            image_key_points.append(cv2.KeyPoint(x, y, patch_stride))\n",
    "    test_key_points.append(image_key_points)\n",
    "    test_feature_shapes.append((len(range(0, w, patch_stride)), (len(range(0, h, patch_stride)))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[문제 2. Bag-of-Features 구현 – 30 pts]  \n",
    "2-1. K-means을 통해 구해진 codebook을 통하여, 각각의 이미지의 특징을 인코딩(histogram화 혹은  양자화 라고도 함) 하시오.  \n",
    "(자세한 사항은 템플릿 코드를 참고)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Extract Features\n",
    "'''\n",
    "###################################################################################\n",
    "# 아래의 코드의 빈 곳(None 부분)을 채우세요.\n",
    "# None 부분 외의 부분은 가급적 수정 하지 말고, 주어진 형식에 맞추어\n",
    "# None 부분 만을 채워주세요. 임의적으로 전체적인 구조를 수정하셔도 좋지만,\n",
    "# 파이썬 코딩에 익숙 하지 않으시면, 가급적 틀을 유지하시는 것을 권장합니다.\n",
    "# 1) descriptor를 선정하세요. (SIFT, SURF 등) OpenCV의 패키지를 사용하시면 됩니다.\n",
    "# 2) for 반복문 안에서, 1)에서 정의한 descriptor를 통하여 features를 추출하세요.\n",
    "#    features의 차원은 (# of keypoints, feature_dim) 입니다.\n",
    "###################################################################################\n",
    "# Write Your Code Here ############################################################\n",
    "descriptor = None\n",
    "###################################################################################\n",
    "train_features = list()\n",
    "index = 0\n",
    "for image, key_points in zip(x_train, train_key_points):\n",
    "    # Write Your Code Here ########################################################\n",
    "    _, features = None\n",
    "    ###############################################################################\n",
    "    train_features.append(features)\n",
    "    index += 1\n",
    "    print(\"Extract Train Features ... {:4d}/{:4d}\".format(index, len(x_train)))\n",
    "\n",
    "test_features = list()\n",
    "index = 0\n",
    "for image, key_points in zip(x_test, test_key_points):\n",
    "    # Write Your Code Here ########################################################\n",
    "    _, features = None\n",
    "    ###############################################################################\n",
    "    test_features.append(features)\n",
    "    index += 1\n",
    "    print(\"Extract Test Features ... {:4d}/{:4d}\".format(index, len(x_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[문제 3. SVM을 통한 이미지 분류 – 15 pts]  \n",
    "3-1. Bag-of-Features 알고리즘을 통해 얻어진 인코딩된 벡터를 통해, SVM을 학습하시오.  \n",
    "이 때, sklearn과 같은 패키지를 활용하여 SVM 학습을 구현하시면 됩니다. (자세한 사항은 템플릿 코드를 참고)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[문제 4. 파라미터 조정을 통한 성능 개선 – 40 pts]  \n",
    "4-1. 현재 주어진 코드에는 여러 하이퍼 파라미터가 존재합니다.    \n",
    "예를 들어, Keypoint를 만들 때의 간격(patch_stride), codebook의 visual word 개수(K), SVM의 학습 파라미터 (C 값 및 max_iter) 등 이 있습니다.   \n",
    "해당 파라미터들을 수정해가면서 결과를 개선시켜 보시오. (K와 patch_stride 같은 경우, 메모리 부족으로 큰 데이터를 사용하지 못 할 수 있으므로, 절대적인 성능 지표보다, 상대적인 성능 향상을 더 고려할 예정임)  \n",
    "\n",
    "4-2. 앞서 여러 파라미터의 실험 결과를 토대로 개선된 혹은 개선 되지 않은 이유를 보고서에 설명하시오. (예를 들어, 각 파라미터 별로 결과 테이블 정리 및 결과에 대한 이유 등)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[심화 문제 5. 알고리즘 개선 – 가산점 +20 pts]  \n",
    "(본 문제는 풀이를 하지 않으셔도 감점되지 않습니다.)  \n",
    "5-1. Bag-of-Features 알고리즘의 단점 중 하나는 공간의 배열, 위치 관계를 보지 않고 특징을 인코딩한다는 점입니다.   \n",
    "즉, 특정 특징들의 개수 만을 통해서 인코딩을 하기 때문에 물체의 위치, 배열 등의 패턴 차이는 제대로 표현되지 않을 수 있습니다.   \n",
    "이러한 단점을 극복하기 위하여 Spatial Pyramid Matching (공간 분할)을 수행 후, codewords을 통해 인코딩 할 수 있습니다.   \n",
    "앞서 언급된 Spatial Pyramid Matching 기법을 적용하여 성능을 개선 시켜 보시오.  \n",
    "(https://slazebni.cs.illinois.edu/publications/pyramid_chapter.pdf를 참고하시면 도움이 됩니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
